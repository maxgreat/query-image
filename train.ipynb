{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import fastText\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import models\n",
    "from dataset import openimages\n",
    "from utils.loss import HardNegativeContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq=1000):\n",
    "    #amp_handle = amp.init()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.train()\n",
    "    print(\"Start training\")\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps) in enumerate(train_loader):\n",
    "        if i%2 == 1:\n",
    "                print(\"%2.2f\"% (i/len(train_loader)*100), '\\%', end='\\r')\n",
    "        input_imgs, target = imgs.cuda(), caps.cuda()\n",
    "        \n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_imgs = model(input_imgs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_imgs, target)\n",
    "        \n",
    "        #with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg, batch_time.avg, data_time.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    imgs_enc = list()\n",
    "    caps_enc = list()\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "\n",
    "        input_imgs, input_caps = imgs.cuda(), caps.cuda()\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_imgs = model(input_imgs)\n",
    "            loss = criterion(output_imgs, input_caps)\n",
    "\n",
    "        imgs_enc.append(output_imgs.cpu().data.numpy())\n",
    "        caps_enc.append(output_caps.cpu().data.numpy())\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(val_loader) - 1):\n",
    "            print('Data: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    recall  = eval_recall(imgs_enc, caps_enc)\n",
    "    print(recall)\n",
    "    return losses.avg, batch_time.avg, data_time.avg, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prepro = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "prepro_val = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(models.ImageProjection().train().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.module.projection.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_embeds(data):\n",
    "    images, targets = zip(*data)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.Tensor(np.stack(targets, 0))\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3072, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HardNegativeContrastiveLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 58.837 (58.837)\tData 32.222 (32.222)\tLoss 5065.3916 (5065.3916)\t\n",
      "Epoch: [0][50/2191]\tTime 1.888 (2.689)\tData 0.115 (0.753)\tLoss 8174.1582 (9939.4797)\t\n",
      "Epoch: [0][100/2191]\tTime 1.354 (2.066)\tData 0.116 (0.443)\tLoss 7127.2090 (8879.8595)\t\n",
      "Epoch: [0][150/2191]\tTime 1.324 (1.865)\tData 0.117 (0.339)\tLoss 9998.9590 (9019.7205)\t\n",
      "Epoch: [0][200/2191]\tTime 1.328 (1.758)\tData 0.115 (0.287)\tLoss 8123.5645 (8971.5343)\t\n",
      "Epoch: [0][250/2191]\tTime 1.327 (1.692)\tData 0.116 (0.255)\tLoss 6510.5483 (8671.2556)\t\n",
      "Epoch: [0][300/2191]\tTime 1.333 (1.649)\tData 0.116 (0.233)\tLoss 6361.2222 (8354.4636)\t\n",
      "Epoch: [0][350/2191]\tTime 1.327 (1.615)\tData 0.116 (0.217)\tLoss 6979.4229 (8109.9479)\t\n",
      "Epoch: [0][400/2191]\tTime 1.858 (1.595)\tData 0.116 (0.205)\tLoss 8735.3262 (8153.7529)\t\n",
      "Epoch: [0][450/2191]\tTime 1.328 (1.577)\tData 0.116 (0.196)\tLoss 8741.9980 (8163.0154)\t\n",
      "Epoch: [0][500/2191]\tTime 1.459 (1.560)\tData 0.247 (0.189)\tLoss 7970.5630 (8180.6867)\t\n",
      "Epoch: [0][550/2191]\tTime 1.331 (1.549)\tData 0.116 (0.184)\tLoss 7093.3530 (8133.0711)\t\n",
      "Epoch: [0][600/2191]\tTime 1.332 (1.539)\tData 0.117 (0.179)\tLoss 10098.0303 (8117.1455)\t\n",
      "Epoch: [0][650/2191]\tTime 1.326 (1.530)\tData 0.116 (0.175)\tLoss 7781.2217 (8113.1772)\t\n",
      "Epoch: [0][700/2191]\tTime 1.330 (1.522)\tData 0.116 (0.172)\tLoss 7592.8354 (8129.1951)\t\n",
      "Epoch: [0][750/2191]\tTime 1.786 (1.516)\tData 0.116 (0.168)\tLoss 9610.7158 (8074.2622)\t\n",
      "Epoch: [0][800/2191]\tTime 1.331 (1.510)\tData 0.117 (0.166)\tLoss 7892.0767 (8134.2885)\t\n",
      "Epoch: [0][850/2191]\tTime 1.325 (1.505)\tData 0.116 (0.163)\tLoss 8235.4072 (8146.2536)\t\n",
      "Epoch: [0][900/2191]\tTime 1.361 (1.500)\tData 0.117 (0.161)\tLoss 9740.2344 (8091.7376)\t\n",
      "Epoch: [0][950/2191]\tTime 1.330 (1.495)\tData 0.117 (0.159)\tLoss 7965.3130 (8039.7251)\t\n",
      "Epoch: [0][1000/2191]\tTime 1.330 (1.492)\tData 0.117 (0.157)\tLoss 7266.1841 (8023.7087)\t\n",
      "Epoch: [0][1050/2191]\tTime 1.325 (1.490)\tData 0.118 (0.156)\tLoss 7685.0366 (8015.7088)\t\n",
      "Epoch: [0][1100/2191]\tTime 1.936 (1.488)\tData 0.116 (0.154)\tLoss 6690.6826 (7988.1899)\t\n",
      "Epoch: [0][1150/2191]\tTime 1.325 (1.485)\tData 0.115 (0.153)\tLoss 10163.8955 (7940.3929)\t\n",
      "Epoch: [0][1200/2191]\tTime 1.326 (1.482)\tData 0.116 (0.152)\tLoss 7333.4111 (7896.9628)\t\n",
      "Epoch: [0][1250/2191]\tTime 1.325 (1.479)\tData 0.116 (0.151)\tLoss 6177.1816 (7866.9857)\t\n",
      "Epoch: [0][1300/2191]\tTime 1.329 (1.477)\tData 0.120 (0.150)\tLoss 7335.1323 (7873.3829)\t\n",
      "Epoch: [0][1350/2191]\tTime 1.328 (1.475)\tData 0.116 (0.149)\tLoss 10366.2510 (7932.3870)\t\n",
      "Epoch: [0][1400/2191]\tTime 1.327 (1.473)\tData 0.115 (0.148)\tLoss 9487.0684 (8005.5425)\t\n",
      "Epoch: [0][1450/2191]\tTime 1.817 (1.472)\tData 0.115 (0.147)\tLoss 5454.8760 (7998.6466)\t\n",
      "Epoch: [0][1500/2191]\tTime 1.330 (1.472)\tData 0.116 (0.146)\tLoss 5598.6709 (7921.4340)\t\n",
      "Epoch: [0][1550/2191]\tTime 1.330 (1.470)\tData 0.116 (0.145)\tLoss 5261.9014 (7844.0253)\t\n",
      "Epoch: [0][1600/2191]\tTime 1.328 (1.468)\tData 0.116 (0.145)\tLoss 7652.7363 (7812.2137)\t\n",
      "Epoch: [0][1650/2191]\tTime 1.333 (1.466)\tData 0.119 (0.144)\tLoss 8616.8340 (7822.2409)\t\n",
      "Epoch: [0][1700/2191]\tTime 1.332 (1.465)\tData 0.116 (0.143)\tLoss 7353.2617 (7817.1196)\t\n",
      "Epoch: [0][1750/2191]\tTime 1.331 (1.463)\tData 0.116 (0.143)\tLoss 9606.9248 (7812.6407)\t\n",
      "Epoch: [0][1800/2191]\tTime 1.780 (1.462)\tData 0.116 (0.142)\tLoss 6855.3496 (7812.2320)\t\n",
      "Epoch: [0][1850/2191]\tTime 1.326 (1.461)\tData 0.115 (0.142)\tLoss 8153.3965 (7793.2683)\t\n",
      "Epoch: [0][1900/2191]\tTime 1.329 (1.460)\tData 0.116 (0.141)\tLoss 7648.8442 (7796.1466)\t\n",
      "Epoch: [0][1950/2191]\tTime 1.329 (1.459)\tData 0.115 (0.141)\tLoss 6071.6274 (7783.1381)\t\n",
      "Epoch: [0][2000/2191]\tTime 1.329 (1.458)\tData 0.116 (0.140)\tLoss 8214.2217 (7812.4349)\t\n",
      "Epoch: [0][2050/2191]\tTime 1.326 (1.457)\tData 0.116 (0.140)\tLoss 6318.2900 (7789.2213)\t\n",
      "Epoch: [0][2100/2191]\tTime 1.330 (1.456)\tData 0.117 (0.139)\tLoss 7038.3633 (7758.9125)\t\n",
      "Epoch: [0][2150/2191]\tTime 1.752 (1.455)\tData 0.116 (0.139)\tLoss 8031.9453 (7752.9867)\t\n",
      "Epoch: [0][2190/2191]\tTime 1.320 (1.453)\tData 0.114 (0.138)\tLoss 5919.3242 (7745.9767)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7745.976734546155, 1.4532104864995374, 0.1383018260783444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 21.584 (21.584)\tData 20.291 (20.291)\tLoss 6896.0942 (6896.0942)\t\n",
      "Epoch: [0][50/2191]\tTime 1.672 (2.120)\tData 0.117 (0.745)\tLoss 4490.7168 (5408.1094)\t\n",
      "Epoch: [0][100/2191]\tTime 1.332 (1.780)\tData 0.119 (0.440)\tLoss 4052.2847 (4848.7612)\t\n",
      "Epoch: [0][150/2191]\tTime 1.326 (1.660)\tData 0.116 (0.336)\tLoss 3058.9360 (4495.5497)\t\n",
      "Epoch: [0][200/2191]\tTime 1.331 (1.602)\tData 0.116 (0.283)\tLoss 2993.4958 (4163.4350)\t\n",
      "Epoch: [0][250/2191]\tTime 1.330 (1.565)\tData 0.117 (0.251)\tLoss 2312.2651 (3845.6544)\t\n",
      "Epoch: [0][300/2191]\tTime 1.348 (1.540)\tData 0.116 (0.229)\tLoss 2224.4983 (3577.2567)\t\n",
      "Epoch: [0][350/2191]\tTime 1.423 (1.522)\tData 0.115 (0.213)\tLoss 2083.6863 (3367.7276)\t\n",
      "Epoch: [0][400/2191]\tTime 1.754 (1.510)\tData 0.116 (0.203)\tLoss 2368.5754 (3219.6241)\t\n",
      "Epoch: [0][450/2191]\tTime 1.339 (1.500)\tData 0.120 (0.193)\tLoss 2379.7559 (3117.2281)\t\n",
      "Epoch: [0][500/2191]\tTime 1.328 (1.492)\tData 0.116 (0.186)\tLoss 3292.6516 (3059.0133)\t\n",
      "Epoch: [0][550/2191]\tTime 1.326 (1.484)\tData 0.116 (0.181)\tLoss 5615.8877 (3206.6953)\t\n",
      "Epoch: [0][600/2191]\tTime 1.332 (1.479)\tData 0.117 (0.177)\tLoss 10130.1875 (3501.6341)\t\n",
      "Epoch: [0][650/2191]\tTime 1.327 (1.474)\tData 0.116 (0.172)\tLoss 5765.2178 (3752.8872)\t\n",
      "Epoch: [0][700/2191]\tTime 1.326 (1.470)\tData 0.116 (0.169)\tLoss 5197.8242 (3927.1136)\t\n",
      "Epoch: [0][750/2191]\tTime 1.648 (1.467)\tData 0.116 (0.166)\tLoss 4629.5488 (4022.2784)\t\n",
      "Epoch: [0][800/2191]\tTime 1.332 (1.464)\tData 0.116 (0.163)\tLoss 5496.8696 (4040.6998)\t\n",
      "Epoch: [0][850/2191]\tTime 1.326 (1.461)\tData 0.115 (0.161)\tLoss 4127.2266 (4061.8649)\t\n",
      "Epoch: [0][900/2191]\tTime 1.332 (1.459)\tData 0.118 (0.159)\tLoss 4689.7773 (4111.7801)\t\n",
      "Epoch: [0][950/2191]\tTime 1.327 (1.456)\tData 0.117 (0.157)\tLoss 3339.5996 (4108.8571)\t\n",
      "Epoch: [0][1000/2191]\tTime 1.440 (1.454)\tData 0.230 (0.155)\tLoss 3360.6841 (4103.7546)\t\n",
      "Epoch: [0][1050/2191]\tTime 1.497 (1.452)\tData 0.119 (0.154)\tLoss 3535.4827 (4080.7738)\t\n",
      "Epoch: [0][1100/2191]\tTime 1.871 (1.451)\tData 0.115 (0.152)\tLoss 3493.0063 (4064.2616)\t\n",
      "Epoch: [0][1150/2191]\tTime 1.328 (1.452)\tData 0.116 (0.151)\tLoss 2509.4917 (4017.2363)\t\n",
      "Epoch: [0][1200/2191]\tTime 1.329 (1.450)\tData 0.116 (0.150)\tLoss 2550.7954 (3959.7180)\t\n",
      "Epoch: [0][1250/2191]\tTime 1.328 (1.448)\tData 0.115 (0.149)\tLoss 2824.0913 (3913.2248)\t\n",
      "Epoch: [0][1300/2191]\tTime 1.330 (1.447)\tData 0.117 (0.148)\tLoss 2944.9697 (3886.1350)\t\n",
      "Epoch: [0][1350/2191]\tTime 1.328 (1.446)\tData 0.117 (0.147)\tLoss 3976.2422 (3901.1202)\t\n",
      "Epoch: [0][1400/2191]\tTime 1.329 (1.445)\tData 0.117 (0.146)\tLoss 4245.9180 (3915.4754)\t\n",
      "Epoch: [0][1450/2191]\tTime 1.627 (1.444)\tData 0.116 (0.145)\tLoss 5807.8345 (3961.1995)\t\n",
      "Epoch: [0][1500/2191]\tTime 1.330 (1.443)\tData 0.118 (0.145)\tLoss 5172.8208 (3999.5448)\t\n",
      "Epoch: [0][1550/2191]\tTime 1.326 (1.442)\tData 0.115 (0.144)\tLoss 4178.9028 (4014.7268)\t\n",
      "Epoch: [0][1600/2191]\tTime 1.332 (1.441)\tData 0.116 (0.143)\tLoss 2986.3052 (3996.1604)\t\n",
      "Epoch: [0][1650/2191]\tTime 1.334 (1.440)\tData 0.120 (0.143)\tLoss 3197.8267 (3968.8770)\t\n",
      "Epoch: [0][1700/2191]\tTime 1.328 (1.439)\tData 0.117 (0.142)\tLoss 3431.8765 (3960.7155)\t\n",
      "Epoch: [0][1750/2191]\tTime 1.327 (1.438)\tData 0.118 (0.141)\tLoss 6647.5581 (3983.4155)\t\n",
      "Epoch: [0][1800/2191]\tTime 1.795 (1.437)\tData 0.116 (0.141)\tLoss 3556.6626 (3988.3962)\t\n",
      "Epoch: [0][1850/2191]\tTime 1.327 (1.436)\tData 0.118 (0.140)\tLoss 4111.8223 (3989.9083)\t\n",
      "Epoch: [0][1900/2191]\tTime 1.326 (1.436)\tData 0.116 (0.140)\tLoss 3497.5498 (3992.7759)\t\n",
      "Epoch: [0][1950/2191]\tTime 1.391 (1.435)\tData 0.116 (0.139)\tLoss 3406.4653 (3983.5757)\t\n",
      "Epoch: [0][2000/2191]\tTime 1.326 (1.435)\tData 0.116 (0.139)\tLoss 2997.6611 (3954.3728)\t\n",
      "Epoch: [0][2050/2191]\tTime 1.326 (1.434)\tData 0.116 (0.139)\tLoss 2847.7644 (3924.8066)\t\n",
      "Epoch: [0][2100/2191]\tTime 1.329 (1.434)\tData 0.116 (0.138)\tLoss 3158.9941 (3896.4973)\t\n",
      "Epoch: [0][2150/2191]\tTime 1.885 (1.434)\tData 0.117 (0.138)\tLoss 3373.8035 (3885.2718)\t\n",
      "Epoch: [0][2190/2191]\tTime 1.319 (1.432)\tData 0.114 (0.137)\tLoss 4295.3047 (3886.8747)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3886.87468471205, 1.4323339348022168, 0.13734619381328741)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Keep the first layer of resnet frozen\n",
    "for i in range(0, 6):\n",
    "    for param in m.module.base_layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [8][0/10208]\tTime 15.876 (15.876)\tData 14.522 (14.522)\tLoss 249.2530 (249.2530)\t\n",
      "Epoch: [8][100/10208]\tTime 0.724 (0.927)\tData 0.026 (0.171)\tLoss 226.3943 (239.8907)\t\n",
      "Epoch: [8][200/10208]\tTime 0.724 (0.868)\tData 0.026 (0.099)\tLoss 228.6726 (235.6185)\t\n",
      "Epoch: [8][300/10208]\tTime 0.725 (0.838)\tData 0.026 (0.075)\tLoss 230.6595 (233.0092)\t\n",
      "Epoch: [8][400/10208]\tTime 0.725 (0.822)\tData 0.026 (0.063)\tLoss 225.4995 (231.3337)\t\n",
      "Epoch: [8][500/10208]\tTime 0.945 (0.813)\tData 0.026 (0.056)\tLoss 217.3611 (229.5482)\t\n",
      "Epoch: [8][600/10208]\tTime 0.730 (0.809)\tData 0.026 (0.051)\tLoss 215.5688 (228.3176)\t\n",
      "Epoch: [8][700/10208]\tTime 0.731 (0.803)\tData 0.026 (0.047)\tLoss 227.7986 (227.4418)\t\n",
      "Epoch: [8][800/10208]\tTime 0.763 (0.801)\tData 0.025 (0.045)\tLoss 213.1459 (226.4875)\t\n",
      "Epoch: [8][900/10208]\tTime 0.735 (0.798)\tData 0.026 (0.043)\tLoss 219.0038 (225.6315)\t\n",
      "Epoch: [8][1000/10208]\tTime 0.828 (0.797)\tData 0.027 (0.041)\tLoss 214.3507 (224.8640)\t\n",
      "Epoch: [8][1100/10208]\tTime 0.764 (0.795)\tData 0.026 (0.040)\tLoss 216.9480 (224.1786)\t\n",
      "Epoch: [8][1200/10208]\tTime 0.730 (0.794)\tData 0.026 (0.038)\tLoss 214.9810 (223.5560)\t\n",
      "Epoch: [8][1300/10208]\tTime 0.731 (0.793)\tData 0.026 (0.038)\tLoss 215.0019 (223.0380)\t\n",
      "Epoch: [8][1400/10208]\tTime 0.723 (0.792)\tData 0.026 (0.037)\tLoss 214.1169 (222.5656)\t\n",
      "Epoch: [8][1500/10208]\tTime 0.732 (0.791)\tData 0.031 (0.036)\tLoss 213.9513 (222.0694)\t\n",
      "Epoch: [8][1600/10208]\tTime 0.721 (0.791)\tData 0.025 (0.036)\tLoss 214.2951 (221.6406)\t\n",
      "Epoch: [8][1700/10208]\tTime 0.719 (0.789)\tData 0.025 (0.035)\tLoss 213.2403 (221.1817)\t\n",
      "Epoch: [8][1800/10208]\tTime 0.741 (0.789)\tData 0.025 (0.035)\tLoss 211.6469 (220.7740)\t\n",
      "Epoch: [8][1900/10208]\tTime 0.726 (0.790)\tData 0.026 (0.034)\tLoss 212.4401 (220.3683)\t\n",
      "Epoch: [8][2000/10208]\tTime 0.724 (0.789)\tData 0.026 (0.034)\tLoss 210.8373 (220.0111)\t\n",
      "Epoch: [8][2100/10208]\tTime 0.775 (0.789)\tData 0.026 (0.033)\tLoss 207.4935 (219.6337)\t\n",
      "Epoch: [8][2200/10208]\tTime 0.722 (0.788)\tData 0.026 (0.033)\tLoss 226.6856 (219.2375)\t\n",
      "Epoch: [8][2300/10208]\tTime 1.026 (0.788)\tData 0.026 (0.033)\tLoss 216.6130 (218.8646)\t\n",
      "Epoch: [8][2400/10208]\tTime 0.732 (0.787)\tData 0.026 (0.032)\tLoss 206.9584 (218.4892)\t\n",
      "Epoch: [8][2500/10208]\tTime 0.719 (0.787)\tData 0.026 (0.032)\tLoss 208.6935 (218.1409)\t\n",
      "Epoch: [8][2600/10208]\tTime 0.728 (0.787)\tData 0.026 (0.032)\tLoss 215.2119 (217.8056)\t\n",
      "Epoch: [8][2700/10208]\tTime 0.722 (0.787)\tData 0.026 (0.032)\tLoss 215.3140 (217.4571)\t\n",
      "Epoch: [8][2800/10208]\tTime 0.958 (0.786)\tData 0.026 (0.032)\tLoss 205.1694 (217.1159)\t\n",
      "Epoch: [8][2900/10208]\tTime 0.726 (0.786)\tData 0.026 (0.031)\tLoss 204.4731 (216.8068)\t\n",
      "Epoch: [8][3000/10208]\tTime 0.743 (0.786)\tData 0.026 (0.031)\tLoss 203.3296 (216.4730)\t\n",
      "Epoch: [8][3100/10208]\tTime 0.741 (0.786)\tData 0.026 (0.031)\tLoss 208.0750 (216.1520)\t\n",
      "Epoch: [8][3200/10208]\tTime 0.725 (0.786)\tData 0.026 (0.031)\tLoss 203.6534 (215.8418)\t\n",
      "Epoch: [8][3300/10208]\tTime 1.075 (0.785)\tData 0.025 (0.031)\tLoss 204.4516 (215.5240)\t\n",
      "Epoch: [8][3400/10208]\tTime 0.742 (0.785)\tData 0.026 (0.031)\tLoss 202.6559 (215.2260)\t\n",
      "Epoch: [8][3500/10208]\tTime 0.721 (0.785)\tData 0.026 (0.030)\tLoss 205.6062 (214.9209)\t\n",
      "Epoch: [8][3600/10208]\tTime 0.735 (0.785)\tData 0.026 (0.030)\tLoss 203.6159 (214.6293)\t\n",
      "Epoch: [8][3700/10208]\tTime 0.740 (0.785)\tData 0.026 (0.030)\tLoss 204.2769 (214.3432)\t\n",
      "Epoch: [8][3800/10208]\tTime 0.998 (0.785)\tData 0.026 (0.030)\tLoss 203.6842 (214.0739)\t\n",
      "Epoch: [8][3900/10208]\tTime 0.739 (0.786)\tData 0.025 (0.030)\tLoss 200.8877 (213.7986)\t\n",
      "Epoch: [8][4000/10208]\tTime 0.719 (0.786)\tData 0.026 (0.030)\tLoss 202.2376 (213.5388)\t\n",
      "Epoch: [8][4100/10208]\tTime 0.721 (0.786)\tData 0.026 (0.030)\tLoss 202.1030 (213.2834)\t\n",
      "Epoch: [8][4200/10208]\tTime 0.741 (0.785)\tData 0.026 (0.030)\tLoss 199.0893 (213.0399)\t\n",
      "Epoch: [8][4300/10208]\tTime 0.948 (0.785)\tData 0.026 (0.030)\tLoss 202.6512 (212.7943)\t\n",
      "Epoch: [8][4400/10208]\tTime 0.745 (0.785)\tData 0.025 (0.030)\tLoss 204.2480 (212.5468)\t\n",
      "Epoch: [8][4500/10208]\tTime 0.724 (0.785)\tData 0.026 (0.030)\tLoss 199.0702 (212.3100)\t\n",
      "Epoch: [8][4600/10208]\tTime 0.726 (0.785)\tData 0.025 (0.029)\tLoss 198.6762 (212.0734)\t\n",
      "Epoch: [8][4700/10208]\tTime 0.738 (0.785)\tData 0.026 (0.029)\tLoss 201.5613 (211.8396)\t\n",
      "Epoch: [8][4800/10208]\tTime 0.728 (0.785)\tData 0.026 (0.029)\tLoss 199.9654 (211.6088)\t\n",
      "Epoch: [8][4900/10208]\tTime 0.768 (0.785)\tData 0.026 (0.029)\tLoss 202.9591 (211.3728)\t\n",
      "Epoch: [8][5000/10208]\tTime 0.723 (0.785)\tData 0.026 (0.029)\tLoss 199.9518 (211.1494)\t\n",
      "Epoch: [8][5100/10208]\tTime 0.718 (0.785)\tData 0.025 (0.029)\tLoss 195.8548 (210.9264)\t\n",
      "Epoch: [8][5200/10208]\tTime 0.729 (0.785)\tData 0.027 (0.029)\tLoss 199.8792 (210.7144)\t\n",
      "Epoch: [8][5300/10208]\tTime 0.735 (0.785)\tData 0.026 (0.029)\tLoss 201.1843 (210.5080)\t\n",
      "Epoch: [8][5400/10208]\tTime 0.743 (0.785)\tData 0.026 (0.029)\tLoss 197.9231 (210.2965)\t\n",
      "Epoch: [8][5500/10208]\tTime 0.743 (0.784)\tData 0.026 (0.029)\tLoss 200.9580 (210.0926)\t\n",
      "53.99 \\%\r"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
