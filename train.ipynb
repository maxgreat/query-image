{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import fastText\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import models\n",
    "from dataset import openimages\n",
    "from utils.loss import HardNegativeContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq=1000):\n",
    "    #amp_handle = amp.init()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.train()\n",
    "    print(\"Start training\")\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps) in enumerate(train_loader):\n",
    "        if i%2 == 1:\n",
    "                print(\"%2.2f\"% (i/len(train_loader)*100), '\\%', end='\\r')\n",
    "        input_imgs, target = imgs.cuda(), caps.cuda()\n",
    "        \n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_imgs = model(input_imgs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_imgs, target)\n",
    "        \n",
    "        #with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg, batch_time.avg, data_time.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    imgs_enc = list()\n",
    "    caps_enc = list()\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "\n",
    "        input_imgs, input_caps = imgs.cuda(), caps.cuda()\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_imgs = model(input_imgs)\n",
    "            loss = criterion(output_imgs, input_caps)\n",
    "\n",
    "        imgs_enc.append(output_imgs.cpu().data.numpy())\n",
    "        caps_enc.append(output_caps.cpu().data.numpy())\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(val_loader) - 1):\n",
    "            print('Data: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    recall  = eval_recall(imgs_enc, caps_enc)\n",
    "    print(recall)\n",
    "    return losses.avg, batch_time.avg, data_time.avg, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prepro = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "prepro_val = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(models.ImageProjection().train().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.module.projection.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_embeds(data):\n",
    "    images, targets = zip(*data)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.Tensor(np.stack(targets, 0))\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3072, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HardNegativeContrastiveLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/1495]\tTime 67.059 (67.059)\tData 38.126 (38.126)\tLoss 7374.1025 (7374.1025)\t\n",
      "Epoch: [0][50/1495]\tTime 2.722 (3.584)\tData 0.292 (0.952)\tLoss 12772.0068 (13539.2018)\t\n",
      "Epoch: [0][100/1495]\tTime 1.931 (2.838)\tData 0.176 (0.571)\tLoss 17728.2402 (14067.6403)\t\n",
      "Epoch: [0][150/1495]\tTime 2.087 (2.575)\tData 0.174 (0.445)\tLoss 14348.8164 (14358.8691)\t\n",
      "Epoch: [0][200/1495]\tTime 1.925 (2.445)\tData 0.170 (0.379)\tLoss 11056.8965 (13816.1928)\t\n",
      "Epoch: [0][250/1495]\tTime 2.100 (2.369)\tData 0.348 (0.345)\tLoss 9937.4941 (13376.6453)\t\n",
      "Epoch: [0][300/1495]\tTime 1.930 (2.318)\tData 0.171 (0.321)\tLoss 10488.4102 (12912.4191)\t\n",
      "Epoch: [0][350/1495]\tTime 2.162 (2.284)\tData 0.287 (0.303)\tLoss 10742.7305 (12510.6637)\t\n",
      "Epoch: [0][400/1495]\tTime 2.402 (2.259)\tData 0.170 (0.290)\tLoss 9458.6875 (12158.2033)\t\n",
      "Epoch: [0][450/1495]\tTime 1.922 (2.236)\tData 0.171 (0.278)\tLoss 12704.2910 (11858.6617)\t\n",
      "Epoch: [0][500/1495]\tTime 2.200 (2.220)\tData 0.397 (0.270)\tLoss 10670.8564 (11839.6704)\t\n",
      "Epoch: [0][550/1495]\tTime 1.920 (2.206)\tData 0.171 (0.264)\tLoss 13459.1523 (11942.6616)\t\n",
      "Epoch: [0][600/1495]\tTime 1.934 (2.192)\tData 0.174 (0.257)\tLoss 14378.3047 (12047.5123)\t\n",
      "Epoch: [0][650/1495]\tTime 1.929 (2.181)\tData 0.171 (0.252)\tLoss 10316.8799 (12055.9433)\t\n",
      "Epoch: [0][700/1495]\tTime 2.039 (2.172)\tData 0.281 (0.247)\tLoss 12480.9785 (11989.6099)\t\n",
      "Epoch: [0][750/1495]\tTime 2.526 (2.166)\tData 0.315 (0.244)\tLoss 9571.7285 (11881.9920)\t\n",
      "Epoch: [0][800/1495]\tTime 1.921 (2.158)\tData 0.171 (0.241)\tLoss 8334.0254 (11748.1377)\t\n",
      "Epoch: [0][850/1495]\tTime 1.927 (2.152)\tData 0.173 (0.238)\tLoss 11648.8643 (11616.0341)\t\n",
      "Epoch: [0][900/1495]\tTime 1.922 (2.145)\tData 0.172 (0.235)\tLoss 9856.6309 (11640.4977)\t\n",
      "Epoch: [0][950/1495]\tTime 1.918 (2.141)\tData 0.171 (0.233)\tLoss 7911.2129 (11500.1560)\t\n",
      "Epoch: [0][1000/1495]\tTime 2.177 (2.135)\tData 0.429 (0.231)\tLoss 11871.0410 (11451.5689)\t\n",
      "Epoch: [0][1050/1495]\tTime 1.918 (2.132)\tData 0.171 (0.229)\tLoss 12311.1611 (11535.8714)\t\n",
      "Epoch: [0][1100/1495]\tTime 2.703 (2.128)\tData 0.175 (0.227)\tLoss 14748.6396 (11670.3339)\t\n",
      "Epoch: [0][1150/1495]\tTime 1.919 (2.125)\tData 0.173 (0.225)\tLoss 11322.7295 (11758.3167)\t\n",
      "Epoch: [0][1200/1495]\tTime 2.109 (2.122)\tData 0.170 (0.224)\tLoss 11447.4180 (11716.7022)\t\n",
      "Epoch: [0][1250/1495]\tTime 2.039 (2.119)\tData 0.171 (0.222)\tLoss 12130.7617 (11735.7166)\t\n",
      "Epoch: [0][1300/1495]\tTime 1.929 (2.115)\tData 0.173 (0.221)\tLoss 10836.2031 (11774.6174)\t\n",
      "Epoch: [0][1350/1495]\tTime 1.928 (2.113)\tData 0.171 (0.219)\tLoss 10389.3438 (11782.9575)\t\n",
      "Epoch: [0][1400/1495]\tTime 1.920 (2.110)\tData 0.171 (0.218)\tLoss 13907.6426 (11743.3140)\t\n",
      "Epoch: [0][1450/1495]\tTime 2.427 (2.108)\tData 0.253 (0.217)\tLoss 9589.6426 (11697.5997)\t\n",
      "Epoch: [0][1494/1495]\tTime 1.914 (2.104)\tData 0.169 (0.216)\tLoss 10869.9756 (11653.1758)\t\n",
      "Start training\n",
      "Epoch: [1][0/1495]\tTime 50.941 (50.941)\tData 49.129 (49.129)\tLoss 11125.7949 (11125.7949)\t\n",
      "Epoch: [1][50/1495]\tTime 1.927 (3.013)\tData 0.173 (1.158)\tLoss 9699.4053 (10169.4036)\t\n",
      "Epoch: [1][100/1495]\tTime 1.982 (2.536)\tData 0.173 (0.679)\tLoss 11721.7188 (10626.5168)\t\n",
      "Epoch: [1][150/1495]\tTime 1.924 (2.383)\tData 0.172 (0.517)\tLoss 8709.2090 (10730.4835)\t\n",
      "Epoch: [1][200/1495]\tTime 2.485 (2.310)\tData 0.265 (0.436)\tLoss 10390.5449 (10327.0353)\t\n",
      "Epoch: [1][250/1495]\tTime 1.924 (2.254)\tData 0.172 (0.387)\tLoss 10222.6133 (10234.2984)\t\n",
      "Epoch: [1][300/1495]\tTime 2.101 (2.222)\tData 0.348 (0.356)\tLoss 11562.0439 (10333.2620)\t\n",
      "Epoch: [1][350/1495]\tTime 1.925 (2.195)\tData 0.171 (0.331)\tLoss 11780.7031 (10724.7199)\t\n",
      "Epoch: [1][400/1495]\tTime 1.919 (2.177)\tData 0.170 (0.314)\tLoss 11653.7363 (10925.3324)\t\n",
      "Epoch: [1][450/1495]\tTime 1.996 (2.164)\tData 0.173 (0.300)\tLoss 9718.2686 (10943.3629)\t\n",
      "Epoch: [1][500/1495]\tTime 2.094 (2.153)\tData 0.344 (0.289)\tLoss 8418.3789 (10841.6006)\t\n",
      "Epoch: [1][550/1495]\tTime 2.351 (2.143)\tData 0.170 (0.280)\tLoss 8388.3867 (10718.0121)\t\n",
      "Epoch: [1][600/1495]\tTime 1.921 (2.134)\tData 0.172 (0.272)\tLoss 9123.4746 (10542.7520)\t\n",
      "Epoch: [1][650/1495]\tTime 2.011 (2.127)\tData 0.258 (0.266)\tLoss 8960.8584 (10548.2979)\t\n",
      "Epoch: [1][700/1495]\tTime 1.927 (2.124)\tData 0.173 (0.261)\tLoss 10337.8525 (10674.8052)\t\n",
      "Epoch: [1][750/1495]\tTime 1.946 (2.118)\tData 0.172 (0.256)\tLoss 11077.9336 (10760.6274)\t\n",
      "Epoch: [1][800/1495]\tTime 1.924 (2.113)\tData 0.170 (0.251)\tLoss 10747.1797 (10795.1313)\t\n",
      "Epoch: [1][850/1495]\tTime 2.149 (2.108)\tData 0.171 (0.247)\tLoss 14510.5957 (10820.8946)\t\n",
      "Epoch: [1][900/1495]\tTime 2.387 (2.105)\tData 0.170 (0.243)\tLoss 9335.2656 (10840.0212)\t\n",
      "Epoch: [1][950/1495]\tTime 1.919 (2.104)\tData 0.171 (0.240)\tLoss 12479.5986 (10865.5770)\t\n",
      "Epoch: [1][1000/1495]\tTime 1.922 (2.101)\tData 0.171 (0.238)\tLoss 10719.5684 (11002.8114)\t\n",
      "Epoch: [1][1050/1495]\tTime 1.927 (2.098)\tData 0.170 (0.236)\tLoss 11229.5215 (11040.8370)\t\n",
      "Epoch: [1][1100/1495]\tTime 2.081 (2.095)\tData 0.171 (0.233)\tLoss 11144.5791 (11100.2255)\t\n",
      "Epoch: [1][1150/1495]\tTime 1.929 (2.093)\tData 0.174 (0.231)\tLoss 9039.6562 (11120.2452)\t\n",
      "Epoch: [1][1200/1495]\tTime 1.923 (2.092)\tData 0.172 (0.230)\tLoss 8604.3721 (11028.3204)\t\n",
      "Epoch: [1][1250/1495]\tTime 2.401 (2.090)\tData 0.173 (0.228)\tLoss 9889.8271 (10943.9323)\t\n",
      "Epoch: [1][1300/1495]\tTime 1.920 (2.088)\tData 0.170 (0.227)\tLoss 11830.5420 (10947.6233)\t\n",
      "Epoch: [1][1350/1495]\tTime 1.934 (2.086)\tData 0.171 (0.225)\tLoss 8211.2812 (10885.1805)\t\n",
      "Epoch: [1][1400/1495]\tTime 1.928 (2.084)\tData 0.173 (0.224)\tLoss 11401.3398 (10877.3841)\t\n",
      "Epoch: [1][1450/1495]\tTime 1.930 (2.083)\tData 0.172 (0.222)\tLoss 10691.6182 (10865.6503)\t\n",
      "Epoch: [1][1494/1495]\tTime 1.919 (2.081)\tData 0.168 (0.221)\tLoss 10128.4346 (10873.9146)\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [2][0/1495]\tTime 51.399 (51.399)\tData 49.598 (49.598)\tLoss 2897.5864 (2897.5864)\t\n",
      "Epoch: [2][50/1495]\tTime 2.044 (3.032)\tData 0.170 (1.167)\tLoss 3546.5110 (3190.0439)\t\n",
      "Epoch: [2][100/1495]\tTime 1.921 (2.544)\tData 0.170 (0.682)\tLoss 5747.5391 (3783.3799)\t\n",
      "Epoch: [2][150/1495]\tTime 2.500 (2.393)\tData 0.287 (0.518)\tLoss 5154.7490 (4246.2801)\t\n",
      "Epoch: [2][200/1495]\tTime 2.065 (2.310)\tData 0.171 (0.436)\tLoss 3955.3203 (4320.9193)\t\n",
      "Epoch: [2][250/1495]\tTime 1.943 (2.260)\tData 0.171 (0.385)\tLoss 5116.1045 (4462.7477)\t\n",
      "Epoch: [2][300/1495]\tTime 1.925 (2.230)\tData 0.172 (0.352)\tLoss 3654.9590 (4431.6050)\t\n",
      "Epoch: [2][350/1495]\tTime 2.220 (2.206)\tData 0.173 (0.328)\tLoss 3426.4272 (4308.5145)\t\n",
      "Epoch: [2][400/1495]\tTime 1.919 (2.185)\tData 0.171 (0.310)\tLoss 2850.0166 (4164.0453)\t\n",
      "Epoch: [2][450/1495]\tTime 2.144 (2.174)\tData 0.173 (0.296)\tLoss 2675.8628 (4002.5395)\t\n",
      "Epoch: [2][500/1495]\tTime 2.383 (2.162)\tData 0.171 (0.286)\tLoss 2553.7883 (3872.6730)\t\n",
      "Epoch: [2][550/1495]\tTime 1.936 (2.152)\tData 0.172 (0.278)\tLoss 2370.6108 (3751.8429)\t\n",
      "Epoch: [2][600/1495]\tTime 1.924 (2.143)\tData 0.171 (0.270)\tLoss 2458.8320 (3654.0497)\t\n",
      "Epoch: [2][650/1495]\tTime 1.928 (2.137)\tData 0.174 (0.263)\tLoss 2556.7871 (3568.1181)\t\n",
      "Epoch: [2][700/1495]\tTime 2.104 (2.131)\tData 0.171 (0.257)\tLoss 2746.9807 (3508.5580)\t\n",
      "Epoch: [2][750/1495]\tTime 1.949 (2.125)\tData 0.172 (0.252)\tLoss 3569.5901 (3492.4325)\t\n",
      "Epoch: [2][800/1495]\tTime 1.925 (2.120)\tData 0.172 (0.249)\tLoss 3150.0811 (3493.8222)\t\n",
      "Epoch: [2][850/1495]\tTime 2.438 (2.119)\tData 0.171 (0.245)\tLoss 3351.8799 (3486.7348)\t\n",
      "Epoch: [2][900/1495]\tTime 1.924 (2.116)\tData 0.173 (0.242)\tLoss 2872.2590 (3458.3796)\t\n",
      "Epoch: [2][950/1495]\tTime 1.920 (2.112)\tData 0.170 (0.239)\tLoss 2712.0376 (3429.6025)\t\n",
      "Epoch: [2][1000/1495]\tTime 1.926 (2.110)\tData 0.174 (0.236)\tLoss 2522.3164 (3390.0401)\t\n",
      "Epoch: [2][1050/1495]\tTime 2.136 (2.107)\tData 0.172 (0.234)\tLoss 2404.8940 (3344.9002)\t\n",
      "Epoch: [2][1100/1495]\tTime 2.152 (2.104)\tData 0.171 (0.232)\tLoss 2520.0239 (3303.6828)\t\n",
      "Epoch: [2][1150/1495]\tTime 1.922 (2.101)\tData 0.172 (0.230)\tLoss 2727.1868 (3275.5878)\t\n",
      "Epoch: [2][1200/1495]\tTime 2.361 (2.100)\tData 0.169 (0.228)\tLoss 2450.9375 (3244.0130)\t\n",
      "Epoch: [2][1250/1495]\tTime 1.928 (2.099)\tData 0.177 (0.227)\tLoss 3146.3079 (3218.6604)\t\n",
      "Epoch: [2][1300/1495]\tTime 1.927 (2.096)\tData 0.171 (0.225)\tLoss 4667.3350 (3241.8255)\t\n",
      "Epoch: [2][1350/1495]\tTime 1.989 (2.094)\tData 0.237 (0.223)\tLoss 6672.3413 (3311.6891)\t\n",
      "Epoch: [2][1400/1495]\tTime 1.924 (2.092)\tData 0.171 (0.223)\tLoss 5695.2061 (3400.5645)\t\n",
      "Epoch: [2][1450/1495]\tTime 2.223 (2.091)\tData 0.174 (0.222)\tLoss 4836.5640 (3454.7913)\t\n",
      "Epoch: [2][1494/1495]\tTime 2.201 (2.088)\tData 0.168 (0.220)\tLoss 4143.3120 (3474.2665)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3474.2665076622598, 2.0876847224092003, 0.22014132152034288)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Keep the first layer of resnet frozen\n",
    "for i in range(0, 6):\n",
    "    for param in m.module.base_layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [5][0/10208]\tTime 13.304 (13.304)\tData 12.050 (12.050)\tLoss 520.9606 (520.9606)\t\n",
      "Epoch: [5][100/10208]\tTime 0.718 (0.890)\tData 0.025 (0.145)\tLoss 250.8136 (324.0566)\t\n",
      "Epoch: [5][200/10208]\tTime 0.937 (0.826)\tData 0.026 (0.086)\tLoss 241.2368 (284.0829)\t\n",
      "Epoch: [5][300/10208]\tTime 0.718 (0.804)\tData 0.025 (0.066)\tLoss 223.3953 (266.4430)\t\n",
      "Epoch: [5][400/10208]\tTime 0.717 (0.794)\tData 0.026 (0.056)\tLoss 223.3347 (255.7287)\t\n",
      "Epoch: [5][500/10208]\tTime 0.717 (0.788)\tData 0.025 (0.050)\tLoss 219.5050 (248.9875)\t\n",
      "Epoch: [5][600/10208]\tTime 0.716 (0.784)\tData 0.026 (0.046)\tLoss 211.9663 (243.6552)\t\n",
      "Epoch: [5][700/10208]\tTime 1.029 (0.781)\tData 0.025 (0.043)\tLoss 211.2588 (239.4960)\t\n",
      "Epoch: [5][800/10208]\tTime 0.717 (0.779)\tData 0.025 (0.041)\tLoss 213.6814 (236.2502)\t\n",
      "Epoch: [5][900/10208]\tTime 0.723 (0.777)\tData 0.026 (0.040)\tLoss 209.8525 (233.5860)\t\n",
      "Epoch: [5][1000/10208]\tTime 0.756 (0.776)\tData 0.026 (0.038)\tLoss 210.1955 (231.2169)\t\n",
      "Epoch: [5][1100/10208]\tTime 0.717 (0.774)\tData 0.025 (0.037)\tLoss 206.4806 (229.3290)\t\n",
      "Epoch: [5][1200/10208]\tTime 0.737 (0.774)\tData 0.025 (0.036)\tLoss 214.3565 (227.6004)\t\n",
      "Epoch: [5][1300/10208]\tTime 0.737 (0.773)\tData 0.045 (0.035)\tLoss 205.7757 (226.1047)\t\n",
      "Epoch: [5][1400/10208]\tTime 0.721 (0.772)\tData 0.026 (0.035)\tLoss 205.1612 (224.8095)\t\n",
      "Epoch: [5][1500/10208]\tTime 0.721 (0.772)\tData 0.026 (0.034)\tLoss 208.8008 (223.6510)\t\n",
      "Epoch: [5][1600/10208]\tTime 0.714 (0.771)\tData 0.025 (0.034)\tLoss 207.0118 (222.6331)\t\n",
      "Epoch: [5][1700/10208]\tTime 0.716 (0.771)\tData 0.025 (0.033)\tLoss 208.6735 (221.7029)\t\n",
      "Epoch: [5][1800/10208]\tTime 0.748 (0.770)\tData 0.026 (0.033)\tLoss 207.0196 (220.8635)\t\n",
      "Epoch: [5][1900/10208]\tTime 0.717 (0.770)\tData 0.026 (0.032)\tLoss 207.4689 (220.0562)\t\n",
      "Epoch: [5][2000/10208]\tTime 0.718 (0.770)\tData 0.025 (0.032)\tLoss 203.1290 (219.3415)\t\n",
      "Epoch: [5][2100/10208]\tTime 0.713 (0.769)\tData 0.025 (0.032)\tLoss 204.7909 (218.6705)\t\n",
      "Epoch: [5][2200/10208]\tTime 0.719 (0.769)\tData 0.026 (0.031)\tLoss 205.4917 (218.0377)\t\n",
      "Epoch: [5][2300/10208]\tTime 0.717 (0.769)\tData 0.026 (0.031)\tLoss 204.5686 (217.4597)\t\n",
      "Epoch: [5][2400/10208]\tTime 0.718 (0.769)\tData 0.026 (0.031)\tLoss 204.7624 (216.9108)\t\n",
      "Epoch: [5][2500/10208]\tTime 1.106 (0.769)\tData 0.025 (0.031)\tLoss 203.0839 (216.4048)\t\n",
      "Epoch: [5][2600/10208]\tTime 0.715 (0.768)\tData 0.025 (0.031)\tLoss 203.6629 (215.9087)\t\n",
      "Epoch: [5][2700/10208]\tTime 0.714 (0.768)\tData 0.025 (0.030)\tLoss 204.0712 (215.4560)\t\n",
      "Epoch: [5][2800/10208]\tTime 0.757 (0.768)\tData 0.026 (0.030)\tLoss 204.7414 (215.0535)\t\n",
      "Epoch: [5][2900/10208]\tTime 0.714 (0.768)\tData 0.026 (0.030)\tLoss 203.7619 (214.6537)\t\n",
      "Epoch: [5][3000/10208]\tTime 1.154 (0.768)\tData 0.025 (0.030)\tLoss 204.3050 (214.2900)\t\n",
      "Epoch: [5][3100/10208]\tTime 0.718 (0.767)\tData 0.026 (0.030)\tLoss 204.9522 (213.9292)\t\n",
      "Epoch: [5][3200/10208]\tTime 0.718 (0.767)\tData 0.026 (0.030)\tLoss 201.9441 (213.5660)\t\n",
      "Epoch: [5][3300/10208]\tTime 0.718 (0.767)\tData 0.026 (0.030)\tLoss 202.4117 (213.2346)\t\n",
      "Epoch: [5][3400/10208]\tTime 0.720 (0.767)\tData 0.025 (0.030)\tLoss 201.5185 (212.9206)\t\n",
      "Epoch: [5][3500/10208]\tTime 1.041 (0.767)\tData 0.025 (0.029)\tLoss 204.6622 (212.6328)\t\n",
      "Epoch: [5][3600/10208]\tTime 0.717 (0.767)\tData 0.025 (0.029)\tLoss 204.7917 (212.3533)\t\n",
      "Epoch: [5][3700/10208]\tTime 0.717 (0.767)\tData 0.025 (0.029)\tLoss 203.9913 (212.0788)\t\n",
      "Epoch: [5][3800/10208]\tTime 0.718 (0.767)\tData 0.025 (0.029)\tLoss 202.2058 (211.8147)\t\n",
      "Epoch: [5][3900/10208]\tTime 0.716 (0.767)\tData 0.025 (0.029)\tLoss 203.5270 (211.5633)\t\n",
      "Epoch: [5][4000/10208]\tTime 1.043 (0.767)\tData 0.025 (0.029)\tLoss 201.0128 (211.3160)\t\n",
      "Epoch: [5][4100/10208]\tTime 0.718 (0.767)\tData 0.025 (0.029)\tLoss 203.9310 (211.1091)\t\n",
      "Epoch: [5][4200/10208]\tTime 0.732 (0.767)\tData 0.025 (0.029)\tLoss 201.8703 (210.9057)\t\n",
      "Epoch: [5][4300/10208]\tTime 0.714 (0.767)\tData 0.025 (0.029)\tLoss 199.3921 (210.6877)\t\n",
      "Epoch: [5][4400/10208]\tTime 0.715 (0.766)\tData 0.025 (0.029)\tLoss 205.3654 (210.4855)\t\n",
      "Epoch: [5][4500/10208]\tTime 0.883 (0.766)\tData 0.026 (0.029)\tLoss 201.2240 (210.2792)\t\n",
      "Epoch: [5][4600/10208]\tTime 0.745 (0.766)\tData 0.025 (0.029)\tLoss 199.3968 (210.0761)\t\n",
      "Epoch: [5][4700/10208]\tTime 0.716 (0.766)\tData 0.025 (0.029)\tLoss 201.5985 (209.8788)\t\n",
      "Epoch: [5][4800/10208]\tTime 0.745 (0.766)\tData 0.025 (0.029)\tLoss 201.0374 (209.6839)\t\n",
      "Epoch: [5][4900/10208]\tTime 0.714 (0.766)\tData 0.025 (0.029)\tLoss 200.8265 (209.4891)\t\n",
      "Epoch: [5][5000/10208]\tTime 0.716 (0.766)\tData 0.025 (0.028)\tLoss 201.2017 (209.3054)\t\n",
      "Epoch: [5][5100/10208]\tTime 0.723 (0.766)\tData 0.026 (0.028)\tLoss 198.2743 (209.1273)\t\n",
      "Epoch: [5][5200/10208]\tTime 0.715 (0.766)\tData 0.025 (0.028)\tLoss 201.9592 (208.9513)\t\n",
      "Epoch: [5][5300/10208]\tTime 0.718 (0.766)\tData 0.025 (0.028)\tLoss 201.4472 (208.7740)\t\n",
      "Epoch: [5][5400/10208]\tTime 0.718 (0.766)\tData 0.025 (0.028)\tLoss 202.6745 (208.6058)\t\n",
      "Epoch: [5][5500/10208]\tTime 0.710 (0.766)\tData 0.025 (0.028)\tLoss 196.6278 (208.4412)\t\n",
      "Epoch: [5][5600/10208]\tTime 0.713 (0.766)\tData 0.025 (0.028)\tLoss 197.4507 (208.2772)\t\n",
      "Epoch: [5][5700/10208]\tTime 0.713 (0.766)\tData 0.025 (0.028)\tLoss 197.5956 (208.1197)\t\n",
      "Epoch: [5][5800/10208]\tTime 1.167 (0.766)\tData 0.025 (0.028)\tLoss 202.2366 (207.9645)\t\n",
      "Epoch: [5][5900/10208]\tTime 0.714 (0.766)\tData 0.025 (0.028)\tLoss 199.8741 (207.8118)\t\n",
      "Epoch: [5][6000/10208]\tTime 0.717 (0.766)\tData 0.025 (0.028)\tLoss 197.7437 (207.6696)\t\n",
      "Epoch: [5][6100/10208]\tTime 0.742 (0.766)\tData 0.050 (0.028)\tLoss 200.9156 (207.5283)\t\n",
      "Epoch: [5][6200/10208]\tTime 0.714 (0.766)\tData 0.025 (0.028)\tLoss 199.0725 (207.3887)\t\n",
      "Epoch: [5][6300/10208]\tTime 1.021 (0.766)\tData 0.025 (0.028)\tLoss 198.2660 (207.2524)\t\n",
      "Epoch: [5][6400/10208]\tTime 0.717 (0.766)\tData 0.025 (0.028)\tLoss 199.9164 (207.1164)\t\n",
      "Epoch: [5][6500/10208]\tTime 0.717 (0.765)\tData 0.026 (0.028)\tLoss 200.2500 (206.9833)\t\n",
      "Epoch: [5][6600/10208]\tTime 0.723 (0.765)\tData 0.025 (0.028)\tLoss 197.4803 (206.8561)\t\n",
      "Epoch: [5][6700/10208]\tTime 0.719 (0.765)\tData 0.025 (0.028)\tLoss 200.8631 (206.7252)\t\n",
      "Epoch: [5][6800/10208]\tTime 0.958 (0.765)\tData 0.026 (0.028)\tLoss 200.1584 (206.6003)\t\n",
      "Epoch: [5][6900/10208]\tTime 0.718 (0.765)\tData 0.025 (0.028)\tLoss 198.4145 (206.4764)\t\n",
      "Epoch: [5][7000/10208]\tTime 0.722 (0.765)\tData 0.025 (0.028)\tLoss 198.4096 (206.3567)\t\n",
      "Epoch: [5][7100/10208]\tTime 0.714 (0.765)\tData 0.025 (0.028)\tLoss 196.9668 (206.2449)\t\n",
      "Epoch: [5][7200/10208]\tTime 0.720 (0.765)\tData 0.026 (0.028)\tLoss 196.3137 (206.1253)\t\n",
      "Epoch: [5][7300/10208]\tTime 1.024 (0.765)\tData 0.025 (0.028)\tLoss 197.4990 (206.0100)\t\n",
      "Epoch: [5][7400/10208]\tTime 0.715 (0.765)\tData 0.025 (0.028)\tLoss 196.1823 (205.8942)\t\n",
      "Epoch: [5][7500/10208]\tTime 0.718 (0.765)\tData 0.025 (0.028)\tLoss 198.8572 (205.7834)\t\n",
      "Epoch: [5][7600/10208]\tTime 0.753 (0.765)\tData 0.025 (0.028)\tLoss 199.5155 (205.6685)\t\n",
      "Epoch: [5][7700/10208]\tTime 0.715 (0.765)\tData 0.026 (0.028)\tLoss 198.0782 (205.5620)\t\n",
      "Epoch: [5][7800/10208]\tTime 0.824 (0.765)\tData 0.025 (0.028)\tLoss 198.1719 (205.4464)\t\n",
      "Epoch: [5][7900/10208]\tTime 0.745 (0.765)\tData 0.025 (0.028)\tLoss 196.1756 (205.3395)\t\n",
      "Epoch: [5][8000/10208]\tTime 0.714 (0.765)\tData 0.025 (0.028)\tLoss 196.1761 (205.2324)\t\n",
      "Epoch: [5][8100/10208]\tTime 0.715 (0.765)\tData 0.025 (0.028)\tLoss 197.1438 (205.1266)\t\n",
      "Epoch: [5][8200/10208]\tTime 0.717 (0.765)\tData 0.025 (0.027)\tLoss 197.1351 (205.0266)\t\n",
      "Epoch: [5][8300/10208]\tTime 0.718 (0.765)\tData 0.025 (0.027)\tLoss 198.6675 (204.9264)\t\n",
      "Epoch: [5][8400/10208]\tTime 0.747 (0.765)\tData 0.054 (0.027)\tLoss 195.0434 (204.8232)\t\n",
      "Epoch: [5][8500/10208]\tTime 0.719 (0.764)\tData 0.026 (0.027)\tLoss 195.8847 (204.7224)\t\n",
      "Epoch: [5][8600/10208]\tTime 0.723 (0.764)\tData 0.025 (0.027)\tLoss 196.6229 (204.6260)\t\n",
      "Epoch: [5][8700/10208]\tTime 0.718 (0.764)\tData 0.025 (0.027)\tLoss 196.6585 (204.5269)\t\n",
      "Epoch: [5][8800/10208]\tTime 0.719 (0.764)\tData 0.025 (0.027)\tLoss 195.2753 (204.4294)\t\n",
      "Epoch: [5][8900/10208]\tTime 0.718 (0.764)\tData 0.025 (0.027)\tLoss 194.6020 (204.3359)\t\n",
      "Epoch: [5][9000/10208]\tTime 0.716 (0.764)\tData 0.025 (0.027)\tLoss 197.6668 (204.2419)\t\n",
      "Epoch: [5][9100/10208]\tTime 0.971 (0.764)\tData 0.026 (0.027)\tLoss 194.1482 (204.1460)\t\n",
      "Epoch: [5][9200/10208]\tTime 0.718 (0.764)\tData 0.025 (0.027)\tLoss 196.1606 (204.0557)\t\n",
      "Epoch: [5][9300/10208]\tTime 0.717 (0.764)\tData 0.025 (0.027)\tLoss 196.4304 (203.9659)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][9400/10208]\tTime 0.720 (0.764)\tData 0.026 (0.027)\tLoss 193.9820 (203.8731)\t\n",
      "Epoch: [5][9500/10208]\tTime 0.713 (0.764)\tData 0.025 (0.027)\tLoss 195.3975 (203.7804)\t\n",
      "Epoch: [5][9600/10208]\tTime 1.132 (0.764)\tData 0.026 (0.027)\tLoss 197.2472 (203.6910)\t\n",
      "Epoch: [5][9700/10208]\tTime 0.719 (0.764)\tData 0.025 (0.027)\tLoss 194.8236 (203.6068)\t\n",
      "Epoch: [5][9800/10208]\tTime 0.724 (0.764)\tData 0.026 (0.027)\tLoss 193.7630 (203.5197)\t\n",
      "Epoch: [5][9900/10208]\tTime 0.754 (0.764)\tData 0.025 (0.027)\tLoss 194.5895 (203.4344)\t\n",
      "Epoch: [5][10000/10208]\tTime 0.715 (0.764)\tData 0.025 (0.027)\tLoss 194.6336 (203.3457)\t\n",
      "Epoch: [5][10100/10208]\tTime 0.953 (0.764)\tData 0.025 (0.027)\tLoss 197.3025 (203.2578)\t\n",
      "Epoch: [5][10200/10208]\tTime 0.709 (0.764)\tData 0.025 (0.027)\tLoss 194.4759 (203.1727)\t\n",
      "Epoch: [5][10207/10208]\tTime 0.710 (0.764)\tData 0.025 (0.027)\tLoss 194.9759 (203.1671)\t\n",
      "Start training\n",
      "Epoch: [6][0/10208]\tTime 14.458 (14.458)\tData 13.648 (13.648)\tLoss 194.3483 (194.3483)\t\n",
      "Epoch: [6][100/10208]\tTime 0.968 (0.902)\tData 0.025 (0.161)\tLoss 194.1998 (194.2202)\t\n",
      "Epoch: [6][200/10208]\tTime 0.714 (0.836)\tData 0.025 (0.094)\tLoss 195.5651 (194.5889)\t\n",
      "Epoch: [6][300/10208]\tTime 0.715 (0.812)\tData 0.025 (0.071)\tLoss 194.3218 (194.6150)\t\n",
      "Epoch: [6][400/10208]\tTime 0.715 (0.800)\tData 0.025 (0.060)\tLoss 195.2046 (194.6119)\t\n",
      "Epoch: [6][500/10208]\tTime 0.715 (0.792)\tData 0.025 (0.053)\tLoss 192.8075 (194.5852)\t\n",
      "Epoch: [6][600/10208]\tTime 0.719 (0.788)\tData 0.025 (0.049)\tLoss 192.9041 (194.5215)\t\n",
      "Epoch: [6][700/10208]\tTime 0.718 (0.785)\tData 0.025 (0.045)\tLoss 192.7318 (194.4253)\t\n",
      "Epoch: [6][800/10208]\tTime 0.717 (0.782)\tData 0.026 (0.043)\tLoss 191.6663 (194.3626)\t\n",
      "Epoch: [6][900/10208]\tTime 0.718 (0.780)\tData 0.026 (0.041)\tLoss 194.1959 (194.2872)\t\n",
      "Epoch: [6][1000/10208]\tTime 0.736 (0.779)\tData 0.025 (0.040)\tLoss 192.2273 (194.2021)\t\n",
      "Epoch: [6][1100/10208]\tTime 0.717 (0.778)\tData 0.025 (0.038)\tLoss 193.1407 (194.1655)\t\n",
      "Epoch: [6][1200/10208]\tTime 0.719 (0.776)\tData 0.025 (0.037)\tLoss 193.3880 (194.1064)\t\n",
      "Epoch: [6][1300/10208]\tTime 0.720 (0.775)\tData 0.025 (0.036)\tLoss 193.4106 (194.0477)\t\n",
      "Epoch: [6][1400/10208]\tTime 0.730 (0.775)\tData 0.025 (0.036)\tLoss 192.6249 (193.9936)\t\n",
      "Epoch: [6][1500/10208]\tTime 0.718 (0.774)\tData 0.026 (0.035)\tLoss 195.1529 (193.9307)\t\n",
      "Epoch: [6][1600/10208]\tTime 0.719 (0.773)\tData 0.025 (0.035)\tLoss 195.0601 (193.8776)\t\n",
      "Epoch: [6][1700/10208]\tTime 0.731 (0.773)\tData 0.025 (0.034)\tLoss 192.3581 (193.8235)\t\n",
      "Epoch: [6][1800/10208]\tTime 0.718 (0.773)\tData 0.026 (0.034)\tLoss 192.5688 (193.7953)\t\n",
      "Epoch: [6][1900/10208]\tTime 1.094 (0.772)\tData 0.025 (0.033)\tLoss 194.4095 (193.7726)\t\n",
      "Epoch: [6][2000/10208]\tTime 0.725 (0.772)\tData 0.026 (0.033)\tLoss 192.9049 (193.7340)\t\n",
      "Epoch: [6][2100/10208]\tTime 0.723 (0.771)\tData 0.026 (0.033)\tLoss 191.6928 (193.6811)\t\n",
      "Epoch: [6][2200/10208]\tTime 0.717 (0.771)\tData 0.026 (0.032)\tLoss 192.8872 (193.6498)\t\n",
      "Epoch: [6][2300/10208]\tTime 0.716 (0.771)\tData 0.025 (0.032)\tLoss 194.8969 (193.8807)\t\n",
      "Epoch: [6][2400/10208]\tTime 1.081 (0.770)\tData 0.026 (0.032)\tLoss 191.3715 (193.8906)\t\n",
      "Epoch: [6][2500/10208]\tTime 0.718 (0.771)\tData 0.025 (0.031)\tLoss 193.6102 (193.8513)\t\n",
      "Epoch: [6][2600/10208]\tTime 0.718 (0.771)\tData 0.026 (0.031)\tLoss 191.9839 (193.8082)\t\n",
      "Epoch: [6][2700/10208]\tTime 0.721 (0.771)\tData 0.026 (0.031)\tLoss 192.1672 (193.7556)\t\n",
      "Epoch: [6][2800/10208]\tTime 0.717 (0.771)\tData 0.026 (0.031)\tLoss 191.4077 (193.7089)\t\n",
      "Epoch: [6][2900/10208]\tTime 1.064 (0.771)\tData 0.026 (0.031)\tLoss 189.6510 (193.6573)\t\n",
      "Epoch: [6][3000/10208]\tTime 0.722 (0.771)\tData 0.025 (0.031)\tLoss 192.9838 (193.6019)\t\n",
      "Epoch: [6][3100/10208]\tTime 0.718 (0.770)\tData 0.025 (0.030)\tLoss 190.7691 (193.5532)\t\n",
      "Epoch: [6][3200/10208]\tTime 0.786 (0.770)\tData 0.025 (0.030)\tLoss 192.2148 (193.5032)\t\n",
      "Epoch: [6][3300/10208]\tTime 0.719 (0.770)\tData 0.025 (0.030)\tLoss 191.5642 (193.4629)\t\n",
      "Epoch: [6][3400/10208]\tTime 0.962 (0.770)\tData 0.025 (0.030)\tLoss 191.6252 (193.4225)\t\n",
      "Epoch: [6][3500/10208]\tTime 0.722 (0.770)\tData 0.026 (0.030)\tLoss 195.5744 (193.3753)\t\n",
      "Epoch: [6][3600/10208]\tTime 0.720 (0.770)\tData 0.026 (0.030)\tLoss 191.4174 (193.3275)\t\n",
      "Epoch: [6][3700/10208]\tTime 0.758 (0.769)\tData 0.057 (0.030)\tLoss 192.0269 (193.2846)\t\n",
      "Epoch: [6][3800/10208]\tTime 0.718 (0.769)\tData 0.026 (0.030)\tLoss 191.0840 (193.2355)\t\n",
      "Epoch: [6][3900/10208]\tTime 0.717 (0.769)\tData 0.025 (0.030)\tLoss 191.8490 (193.1932)\t\n",
      "Epoch: [6][4000/10208]\tTime 0.719 (0.769)\tData 0.025 (0.029)\tLoss 191.3582 (193.1475)\t\n",
      "Epoch: [6][4100/10208]\tTime 0.719 (0.769)\tData 0.025 (0.029)\tLoss 190.5078 (193.1005)\t\n",
      "Epoch: [6][4200/10208]\tTime 0.746 (0.769)\tData 0.025 (0.029)\tLoss 191.1722 (193.0543)\t\n",
      "Epoch: [6][4300/10208]\tTime 0.716 (0.769)\tData 0.026 (0.029)\tLoss 190.7377 (193.0042)\t\n",
      "Epoch: [6][4400/10208]\tTime 0.719 (0.769)\tData 0.026 (0.029)\tLoss 190.8262 (192.9589)\t\n",
      "Epoch: [6][4500/10208]\tTime 0.718 (0.769)\tData 0.026 (0.029)\tLoss 191.3338 (192.9138)\t\n",
      "Epoch: [6][4600/10208]\tTime 0.718 (0.768)\tData 0.026 (0.029)\tLoss 190.2865 (192.8696)\t\n",
      "Epoch: [6][4700/10208]\tTime 0.721 (0.768)\tData 0.025 (0.029)\tLoss 189.5327 (192.8229)\t\n",
      "Epoch: [6][4800/10208]\tTime 0.717 (0.768)\tData 0.026 (0.029)\tLoss 190.5515 (192.7768)\t\n",
      "Epoch: [6][4900/10208]\tTime 0.717 (0.768)\tData 0.025 (0.029)\tLoss 188.4445 (192.7296)\t\n",
      "Epoch: [6][5000/10208]\tTime 0.714 (0.768)\tData 0.025 (0.029)\tLoss 192.0354 (192.6853)\t\n",
      "Epoch: [6][5100/10208]\tTime 0.715 (0.768)\tData 0.026 (0.029)\tLoss 191.6856 (192.6483)\t\n",
      "Epoch: [6][5200/10208]\tTime 0.966 (0.768)\tData 0.026 (0.029)\tLoss 192.1199 (192.6113)\t\n",
      "Epoch: [6][5300/10208]\tTime 0.718 (0.768)\tData 0.026 (0.029)\tLoss 192.6347 (192.6041)\t\n",
      "Epoch: [6][5400/10208]\tTime 0.724 (0.768)\tData 0.026 (0.029)\tLoss 191.3087 (192.5925)\t\n",
      "Epoch: [6][5500/10208]\tTime 0.729 (0.768)\tData 0.025 (0.029)\tLoss 189.2690 (192.5622)\t\n",
      "Epoch: [6][5600/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 192.4290 (192.5271)\t\n",
      "Epoch: [6][5700/10208]\tTime 1.051 (0.768)\tData 0.026 (0.028)\tLoss 189.8255 (192.4940)\t\n",
      "Epoch: [6][5800/10208]\tTime 0.717 (0.768)\tData 0.026 (0.028)\tLoss 192.8125 (192.4612)\t\n",
      "Epoch: [6][5900/10208]\tTime 0.715 (0.768)\tData 0.026 (0.028)\tLoss 189.3404 (192.4275)\t\n",
      "Epoch: [6][6000/10208]\tTime 0.714 (0.768)\tData 0.025 (0.028)\tLoss 190.3388 (192.3935)\t\n",
      "Epoch: [6][6100/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 188.9605 (192.3636)\t\n",
      "Epoch: [6][6200/10208]\tTime 1.078 (0.768)\tData 0.025 (0.028)\tLoss 191.3345 (192.3283)\t\n",
      "Epoch: [6][6300/10208]\tTime 0.717 (0.767)\tData 0.025 (0.028)\tLoss 189.7808 (192.2895)\t\n",
      "Epoch: [6][6400/10208]\tTime 0.718 (0.767)\tData 0.025 (0.028)\tLoss 189.6109 (192.2493)\t\n",
      "Epoch: [6][6500/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 189.3373 (192.2101)\t\n",
      "Epoch: [6][6600/10208]\tTime 0.722 (0.767)\tData 0.026 (0.028)\tLoss 188.9841 (192.1766)\t\n",
      "Epoch: [6][6700/10208]\tTime 1.076 (0.767)\tData 0.026 (0.028)\tLoss 188.5346 (192.1377)\t\n",
      "Epoch: [6][6800/10208]\tTime 0.718 (0.767)\tData 0.025 (0.028)\tLoss 188.8742 (192.0975)\t\n",
      "Epoch: [6][6900/10208]\tTime 0.717 (0.767)\tData 0.025 (0.028)\tLoss 190.0104 (192.0597)\t\n",
      "Epoch: [6][7000/10208]\tTime 0.721 (0.767)\tData 0.026 (0.028)\tLoss 188.7004 (192.0221)\t\n",
      "Epoch: [6][7100/10208]\tTime 0.715 (0.767)\tData 0.025 (0.028)\tLoss 188.6754 (191.9837)\t\n",
      "Epoch: [6][7200/10208]\tTime 0.719 (0.767)\tData 0.025 (0.028)\tLoss 190.1070 (191.9438)\t\n",
      "Epoch: [6][7300/10208]\tTime 0.725 (0.767)\tData 0.027 (0.028)\tLoss 189.4462 (191.9038)\t\n",
      "Epoch: [6][7400/10208]\tTime 0.723 (0.767)\tData 0.026 (0.028)\tLoss 187.9239 (191.8665)\t\n",
      "Epoch: [6][7500/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 188.6172 (191.8262)\t\n",
      "Epoch: [6][7600/10208]\tTime 0.723 (0.767)\tData 0.026 (0.028)\tLoss 189.0992 (191.7863)\t\n",
      "Epoch: [6][7700/10208]\tTime 0.721 (0.767)\tData 0.026 (0.028)\tLoss 188.7591 (191.7448)\t\n",
      "Epoch: [6][7800/10208]\tTime 0.724 (0.767)\tData 0.026 (0.028)\tLoss 188.8765 (191.7049)\t\n",
      "Epoch: [6][7900/10208]\tTime 0.719 (0.767)\tData 0.025 (0.028)\tLoss 188.5668 (191.6657)\t\n",
      "Epoch: [6][8000/10208]\tTime 0.721 (0.767)\tData 0.025 (0.028)\tLoss 187.6635 (191.6260)\t\n",
      "Epoch: [6][8100/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 189.8078 (191.5865)\t\n",
      "Epoch: [6][8200/10208]\tTime 0.721 (0.767)\tData 0.025 (0.028)\tLoss 187.3915 (191.5470)\t\n",
      "Epoch: [6][8300/10208]\tTime 0.716 (0.767)\tData 0.025 (0.028)\tLoss 189.1789 (191.5091)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][8400/10208]\tTime 0.720 (0.767)\tData 0.026 (0.028)\tLoss 188.2408 (191.4714)\t\n",
      "Epoch: [6][8500/10208]\tTime 1.069 (0.767)\tData 0.027 (0.028)\tLoss 187.5262 (191.4339)\t\n",
      "Epoch: [6][8600/10208]\tTime 0.717 (0.767)\tData 0.026 (0.028)\tLoss 188.1460 (191.3976)\t\n",
      "Epoch: [6][8700/10208]\tTime 0.722 (0.767)\tData 0.026 (0.028)\tLoss 187.9334 (191.3643)\t\n",
      "Epoch: [6][8800/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 187.2130 (191.3291)\t\n",
      "Epoch: [6][8900/10208]\tTime 0.720 (0.767)\tData 0.026 (0.028)\tLoss 188.0001 (191.2926)\t\n",
      "Epoch: [6][9000/10208]\tTime 0.981 (0.767)\tData 0.026 (0.028)\tLoss 188.5044 (191.2569)\t\n",
      "Epoch: [6][9100/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 188.4612 (191.2190)\t\n",
      "Epoch: [6][9200/10208]\tTime 0.720 (0.767)\tData 0.026 (0.028)\tLoss 188.1525 (191.1826)\t\n",
      "Epoch: [6][9300/10208]\tTime 0.723 (0.767)\tData 0.025 (0.028)\tLoss 187.7855 (191.1456)\t\n",
      "Epoch: [6][9400/10208]\tTime 0.719 (0.767)\tData 0.025 (0.028)\tLoss 190.3804 (191.1062)\t\n",
      "Epoch: [6][9500/10208]\tTime 1.121 (0.767)\tData 0.025 (0.027)\tLoss 186.4310 (191.0651)\t\n",
      "Epoch: [6][9600/10208]\tTime 0.716 (0.767)\tData 0.026 (0.027)\tLoss 187.8963 (191.0252)\t\n",
      "Epoch: [6][9700/10208]\tTime 0.721 (0.767)\tData 0.025 (0.027)\tLoss 187.0287 (190.9874)\t\n",
      "Epoch: [6][9800/10208]\tTime 0.719 (0.767)\tData 0.025 (0.027)\tLoss 188.1737 (190.9514)\t\n",
      "Epoch: [6][9900/10208]\tTime 0.723 (0.767)\tData 0.026 (0.027)\tLoss 187.6636 (190.9143)\t\n",
      "Epoch: [6][10000/10208]\tTime 1.023 (0.767)\tData 0.025 (0.027)\tLoss 187.2150 (190.8765)\t\n",
      "Epoch: [6][10100/10208]\tTime 0.720 (0.767)\tData 0.026 (0.027)\tLoss 187.3894 (190.8393)\t\n",
      "Epoch: [6][10200/10208]\tTime 0.720 (0.767)\tData 0.026 (0.027)\tLoss 186.3691 (190.8020)\t\n",
      "Epoch: [6][10207/10208]\tTime 0.722 (0.767)\tData 0.026 (0.027)\tLoss 187.3278 (190.7992)\t\n",
      "Start training\n",
      "Epoch: [7][0/10208]\tTime 11.785 (11.785)\tData 10.988 (10.988)\tLoss 187.2144 (187.2144)\t\n",
      "Epoch: [7][100/10208]\tTime 0.716 (0.903)\tData 0.026 (0.155)\tLoss 185.8384 (186.8299)\t\n",
      "Epoch: [7][200/10208]\tTime 0.722 (0.834)\tData 0.026 (0.091)\tLoss 186.6383 (186.9332)\t\n",
      "Epoch: [7][300/10208]\tTime 0.716 (0.811)\tData 0.025 (0.069)\tLoss 185.6662 (186.8882)\t\n",
      "Epoch: [7][400/10208]\tTime 0.716 (0.808)\tData 0.025 (0.059)\tLoss 187.3017 (186.8512)\t\n",
      "Epoch: [7][500/10208]\tTime 0.717 (0.798)\tData 0.025 (0.052)\tLoss 186.5925 (186.8004)\t\n",
      "Epoch: [7][600/10208]\tTime 0.720 (0.792)\tData 0.026 (0.048)\tLoss 187.0199 (186.7568)\t\n",
      "Epoch: [7][700/10208]\tTime 0.725 (0.789)\tData 0.026 (0.045)\tLoss 186.2130 (186.7073)\t\n",
      "Epoch: [7][800/10208]\tTime 1.191 (0.787)\tData 0.026 (0.042)\tLoss 185.3022 (186.6571)\t\n",
      "Epoch: [7][900/10208]\tTime 0.716 (0.784)\tData 0.025 (0.040)\tLoss 185.7993 (186.6181)\t\n",
      "Epoch: [7][1000/10208]\tTime 0.721 (0.782)\tData 0.026 (0.039)\tLoss 188.5010 (186.5986)\t\n",
      "Epoch: [7][1100/10208]\tTime 0.718 (0.780)\tData 0.025 (0.038)\tLoss 185.2244 (186.5598)\t\n",
      "Epoch: [7][1200/10208]\tTime 0.727 (0.779)\tData 0.025 (0.037)\tLoss 186.1055 (186.5046)\t\n",
      "Epoch: [7][1300/10208]\tTime 1.055 (0.778)\tData 0.026 (0.036)\tLoss 185.8326 (186.4761)\t\n",
      "Epoch: [7][1400/10208]\tTime 0.720 (0.777)\tData 0.026 (0.035)\tLoss 184.3439 (186.4289)\t\n",
      "Epoch: [7][1500/10208]\tTime 0.722 (0.776)\tData 0.025 (0.035)\tLoss 186.1966 (186.3978)\t\n",
      "Epoch: [7][1600/10208]\tTime 0.720 (0.776)\tData 0.026 (0.034)\tLoss 186.1622 (186.3736)\t\n",
      "Epoch: [7][1700/10208]\tTime 0.718 (0.775)\tData 0.026 (0.034)\tLoss 187.3793 (186.3313)\t\n",
      "Epoch: [7][1800/10208]\tTime 0.963 (0.774)\tData 0.026 (0.033)\tLoss 185.7296 (186.2958)\t\n",
      "Epoch: [7][1900/10208]\tTime 0.718 (0.774)\tData 0.025 (0.033)\tLoss 186.9196 (186.2567)\t\n",
      "Epoch: [7][2000/10208]\tTime 0.719 (0.774)\tData 0.025 (0.033)\tLoss 186.0128 (186.2181)\t\n",
      "Epoch: [7][2100/10208]\tTime 0.779 (0.773)\tData 0.025 (0.032)\tLoss 185.1409 (186.1898)\t\n",
      "Epoch: [7][2200/10208]\tTime 0.718 (0.773)\tData 0.025 (0.032)\tLoss 185.1265 (186.1551)\t\n",
      "Epoch: [7][2300/10208]\tTime 1.128 (0.773)\tData 0.026 (0.032)\tLoss 185.7945 (186.1178)\t\n",
      "Epoch: [7][2400/10208]\tTime 0.721 (0.773)\tData 0.025 (0.032)\tLoss 184.9877 (186.0788)\t\n",
      "Epoch: [7][2500/10208]\tTime 0.724 (0.772)\tData 0.026 (0.031)\tLoss 185.3967 (186.0456)\t\n",
      "Epoch: [7][2600/10208]\tTime 0.718 (0.772)\tData 0.025 (0.031)\tLoss 185.1495 (186.0108)\t\n",
      "Epoch: [7][2700/10208]\tTime 0.719 (0.772)\tData 0.026 (0.031)\tLoss 185.3428 (185.9863)\t\n",
      "Epoch: [7][2800/10208]\tTime 0.881 (0.772)\tData 0.025 (0.031)\tLoss 184.9908 (185.9521)\t\n",
      "Epoch: [7][2900/10208]\tTime 0.722 (0.772)\tData 0.026 (0.031)\tLoss 184.7585 (185.9192)\t\n",
      "Epoch: [7][3000/10208]\tTime 0.721 (0.771)\tData 0.026 (0.030)\tLoss 184.8206 (185.8845)\t\n",
      "Epoch: [7][3100/10208]\tTime 0.719 (0.771)\tData 0.025 (0.030)\tLoss 184.3590 (185.8505)\t\n",
      "Epoch: [7][3200/10208]\tTime 0.718 (0.771)\tData 0.025 (0.030)\tLoss 184.8361 (185.8155)\t\n",
      "Epoch: [7][3300/10208]\tTime 0.723 (0.771)\tData 0.025 (0.030)\tLoss 184.1051 (185.7792)\t\n",
      "Epoch: [7][3400/10208]\tTime 0.721 (0.771)\tData 0.025 (0.030)\tLoss 183.6237 (185.7464)\t\n",
      "Epoch: [7][3500/10208]\tTime 0.715 (0.770)\tData 0.025 (0.030)\tLoss 184.4299 (185.7111)\t\n",
      "Epoch: [7][3600/10208]\tTime 0.717 (0.770)\tData 0.025 (0.030)\tLoss 184.1543 (185.6743)\t\n",
      "Epoch: [7][3700/10208]\tTime 0.717 (0.770)\tData 0.026 (0.030)\tLoss 183.8026 (185.6429)\t\n",
      "Epoch: [7][3800/10208]\tTime 0.720 (0.770)\tData 0.025 (0.030)\tLoss 185.2549 (185.6071)\t\n",
      "Epoch: [7][3900/10208]\tTime 0.741 (0.770)\tData 0.025 (0.029)\tLoss 183.5661 (185.5716)\t\n",
      "Epoch: [7][4000/10208]\tTime 0.716 (0.770)\tData 0.025 (0.029)\tLoss 185.0673 (185.5373)\t\n",
      "Epoch: [7][4100/10208]\tTime 1.058 (0.770)\tData 0.026 (0.029)\tLoss 184.1835 (185.5029)\t\n",
      "Epoch: [7][4200/10208]\tTime 0.720 (0.769)\tData 0.026 (0.029)\tLoss 182.9376 (185.4682)\t\n",
      "Epoch: [7][4300/10208]\tTime 0.719 (0.769)\tData 0.025 (0.029)\tLoss 184.3210 (185.4351)\t\n",
      "Epoch: [7][4400/10208]\tTime 0.719 (0.769)\tData 0.026 (0.029)\tLoss 183.7117 (185.4014)\t\n",
      "Epoch: [7][4500/10208]\tTime 0.720 (0.769)\tData 0.025 (0.029)\tLoss 183.6567 (185.3656)\t\n",
      "Epoch: [7][4600/10208]\tTime 0.952 (0.769)\tData 0.025 (0.029)\tLoss 184.3483 (185.3299)\t\n",
      "Epoch: [7][4700/10208]\tTime 0.716 (0.769)\tData 0.025 (0.029)\tLoss 183.4574 (185.2978)\t\n",
      "Epoch: [7][4800/10208]\tTime 0.718 (0.769)\tData 0.026 (0.029)\tLoss 183.0216 (185.2670)\t\n",
      "Epoch: [7][4900/10208]\tTime 0.741 (0.769)\tData 0.026 (0.029)\tLoss 184.1350 (185.2329)\t\n",
      "Epoch: [7][5000/10208]\tTime 0.719 (0.769)\tData 0.026 (0.029)\tLoss 182.3820 (185.2009)\t\n",
      "Epoch: [7][5100/10208]\tTime 0.977 (0.769)\tData 0.026 (0.029)\tLoss 183.4564 (185.1660)\t\n",
      "Epoch: [7][5200/10208]\tTime 0.716 (0.769)\tData 0.025 (0.029)\tLoss 183.1346 (185.1334)\t\n",
      "Epoch: [7][5300/10208]\tTime 0.718 (0.769)\tData 0.026 (0.029)\tLoss 182.7570 (185.0988)\t\n",
      "Epoch: [7][5400/10208]\tTime 0.745 (0.768)\tData 0.025 (0.028)\tLoss 183.4382 (185.0664)\t\n",
      "Epoch: [7][5500/10208]\tTime 0.715 (0.768)\tData 0.026 (0.028)\tLoss 184.0889 (185.0352)\t\n",
      "Epoch: [7][5600/10208]\tTime 1.210 (0.768)\tData 0.026 (0.028)\tLoss 183.5939 (185.0046)\t\n",
      "Epoch: [7][5700/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 183.2359 (184.9726)\t\n",
      "Epoch: [7][5800/10208]\tTime 0.722 (0.768)\tData 0.026 (0.028)\tLoss 182.1391 (184.9391)\t\n",
      "Epoch: [7][5900/10208]\tTime 0.725 (0.768)\tData 0.025 (0.028)\tLoss 182.4325 (184.9046)\t\n",
      "Epoch: [7][6000/10208]\tTime 0.715 (0.768)\tData 0.025 (0.028)\tLoss 183.3554 (184.8719)\t\n",
      "Epoch: [7][6100/10208]\tTime 0.785 (0.768)\tData 0.026 (0.028)\tLoss 183.6037 (184.8418)\t\n",
      "Epoch: [7][6200/10208]\tTime 0.721 (0.768)\tData 0.025 (0.028)\tLoss 182.4651 (184.8147)\t\n",
      "Epoch: [7][6300/10208]\tTime 0.716 (0.768)\tData 0.025 (0.028)\tLoss 182.8968 (184.7832)\t\n",
      "Epoch: [7][6400/10208]\tTime 0.723 (0.768)\tData 0.025 (0.028)\tLoss 182.9478 (184.7525)\t\n",
      "Epoch: [7][6500/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 183.2917 (184.7210)\t\n",
      "Epoch: [7][6600/10208]\tTime 0.720 (0.768)\tData 0.026 (0.028)\tLoss 182.3351 (184.6901)\t\n",
      "Epoch: [7][6700/10208]\tTime 0.722 (0.768)\tData 0.025 (0.028)\tLoss 185.2408 (184.6750)\t\n",
      "Epoch: [7][6800/10208]\tTime 0.717 (0.768)\tData 0.025 (0.028)\tLoss 183.6168 (184.6716)\t\n",
      "Epoch: [7][6900/10208]\tTime 0.720 (0.768)\tData 0.025 (0.028)\tLoss 183.0354 (184.6498)\t\n",
      "Epoch: [7][7000/10208]\tTime 0.719 (0.768)\tData 0.026 (0.028)\tLoss 182.3447 (184.6229)\t\n",
      "Epoch: [7][7100/10208]\tTime 0.724 (0.768)\tData 0.026 (0.028)\tLoss 183.7179 (184.5939)\t\n",
      "Epoch: [7][7200/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 182.2529 (184.5639)\t\n",
      "Epoch: [7][7300/10208]\tTime 0.722 (0.768)\tData 0.026 (0.028)\tLoss 181.8685 (184.5377)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7][7400/10208]\tTime 1.085 (0.768)\tData 0.025 (0.028)\tLoss 182.0837 (184.5095)\t\n",
      "Epoch: [7][7500/10208]\tTime 0.723 (0.768)\tData 0.026 (0.028)\tLoss 182.6496 (184.4794)\t\n",
      "Epoch: [7][7600/10208]\tTime 0.717 (0.768)\tData 0.026 (0.028)\tLoss 182.0073 (184.4497)\t\n",
      "Epoch: [7][7700/10208]\tTime 0.720 (0.768)\tData 0.026 (0.028)\tLoss 183.6725 (184.4220)\t\n",
      "Epoch: [7][7800/10208]\tTime 0.722 (0.768)\tData 0.026 (0.028)\tLoss 181.9570 (184.3930)\t\n",
      "Epoch: [7][7900/10208]\tTime 1.152 (0.768)\tData 0.025 (0.028)\tLoss 181.2991 (184.3644)\t\n",
      "Epoch: [7][8000/10208]\tTime 0.715 (0.768)\tData 0.025 (0.028)\tLoss 182.9015 (184.3362)\t\n",
      "Epoch: [7][8100/10208]\tTime 0.723 (0.768)\tData 0.026 (0.028)\tLoss 181.6902 (184.3089)\t\n",
      "Epoch: [7][8200/10208]\tTime 0.716 (0.768)\tData 0.026 (0.028)\tLoss 182.5096 (184.2811)\t\n",
      "Epoch: [7][8300/10208]\tTime 0.719 (0.768)\tData 0.025 (0.028)\tLoss 181.6448 (184.2531)\t\n",
      "Epoch: [7][8400/10208]\tTime 0.949 (0.768)\tData 0.026 (0.028)\tLoss 182.5660 (184.2264)\t\n",
      "Epoch: [7][8500/10208]\tTime 0.716 (0.768)\tData 0.025 (0.028)\tLoss 182.0959 (184.1989)\t\n",
      "Epoch: [7][8600/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 180.7433 (184.1730)\t\n",
      "Epoch: [7][8700/10208]\tTime 0.730 (0.768)\tData 0.025 (0.028)\tLoss 183.2737 (184.1457)\t\n",
      "Epoch: [7][8800/10208]\tTime 0.719 (0.767)\tData 0.025 (0.028)\tLoss 181.6773 (184.1190)\t\n",
      "Epoch: [7][8900/10208]\tTime 1.038 (0.767)\tData 0.025 (0.028)\tLoss 181.1893 (184.0923)\t\n",
      "Epoch: [7][9000/10208]\tTime 0.718 (0.767)\tData 0.026 (0.028)\tLoss 181.0760 (184.0666)\t\n",
      "Epoch: [7][9100/10208]\tTime 0.716 (0.767)\tData 0.025 (0.028)\tLoss 181.8129 (184.0410)\t\n",
      "Epoch: [7][9200/10208]\tTime 0.739 (0.767)\tData 0.025 (0.028)\tLoss 182.2190 (184.0150)\t\n",
      "Epoch: [7][9300/10208]\tTime 0.716 (0.767)\tData 0.026 (0.027)\tLoss 181.5620 (183.9888)\t\n",
      "Epoch: [7][9400/10208]\tTime 0.802 (0.767)\tData 0.025 (0.027)\tLoss 182.1191 (183.9659)\t\n",
      "Epoch: [7][9500/10208]\tTime 0.745 (0.767)\tData 0.025 (0.027)\tLoss 180.5630 (183.9401)\t\n",
      "Epoch: [7][9600/10208]\tTime 0.716 (0.767)\tData 0.026 (0.027)\tLoss 181.1217 (183.9145)\t\n",
      "Epoch: [7][9700/10208]\tTime 0.717 (0.767)\tData 0.025 (0.027)\tLoss 182.5964 (183.8940)\t\n",
      "Epoch: [7][9800/10208]\tTime 0.718 (0.767)\tData 0.026 (0.027)\tLoss 181.8736 (183.8768)\t\n",
      "Epoch: [7][9900/10208]\tTime 0.723 (0.767)\tData 0.026 (0.027)\tLoss 181.8531 (183.8540)\t\n",
      "Epoch: [7][10000/10208]\tTime 0.718 (0.767)\tData 0.026 (0.027)\tLoss 181.7260 (183.8328)\t\n",
      "Epoch: [7][10100/10208]\tTime 0.723 (0.767)\tData 0.025 (0.027)\tLoss 181.2259 (183.8106)\t\n",
      "Epoch: [7][10200/10208]\tTime 0.715 (0.767)\tData 0.025 (0.027)\tLoss 181.0344 (183.7880)\t\n",
      "Epoch: [7][10207/10208]\tTime 0.714 (0.767)\tData 0.025 (0.027)\tLoss 181.4033 (183.7864)\t\n",
      "Start training\n",
      "Epoch: [8][0/10208]\tTime 15.908 (15.908)\tData 15.059 (15.059)\tLoss 181.1199 (181.1199)\t\n",
      "Epoch: [8][100/10208]\tTime 0.719 (0.919)\tData 0.025 (0.176)\tLoss 181.1219 (181.3219)\t\n",
      "Epoch: [8][200/10208]\tTime 0.950 (0.845)\tData 0.025 (0.101)\tLoss 180.4360 (181.2490)\t\n",
      "Epoch: [8][300/10208]\tTime 0.718 (0.819)\tData 0.025 (0.076)\tLoss 181.2915 (181.2586)\t\n",
      "Epoch: [8][400/10208]\tTime 0.720 (0.805)\tData 0.026 (0.064)\tLoss 181.1370 (181.2607)\t\n",
      "Epoch: [8][500/10208]\tTime 0.718 (0.798)\tData 0.026 (0.056)\tLoss 180.5965 (181.2761)\t\n",
      "Epoch: [8][600/10208]\tTime 0.718 (0.793)\tData 0.026 (0.051)\tLoss 180.4263 (181.2761)\t\n",
      "Epoch: [8][700/10208]\tTime 1.176 (0.790)\tData 0.026 (0.048)\tLoss 181.1430 (181.2769)\t\n",
      "Epoch: [8][800/10208]\tTime 0.716 (0.786)\tData 0.025 (0.045)\tLoss 181.2262 (181.2660)\t\n",
      "Epoch: [8][900/10208]\tTime 0.715 (0.784)\tData 0.025 (0.043)\tLoss 181.6801 (181.2535)\t\n",
      "Epoch: [8][1000/10208]\tTime 0.718 (0.783)\tData 0.025 (0.041)\tLoss 181.1922 (181.2445)\t\n",
      "Epoch: [8][1100/10208]\tTime 0.718 (0.782)\tData 0.026 (0.040)\tLoss 181.0067 (181.2317)\t\n",
      "Epoch: [8][1200/10208]\tTime 1.116 (0.780)\tData 0.025 (0.039)\tLoss 180.8617 (181.2181)\t\n",
      "Epoch: [8][1300/10208]\tTime 0.722 (0.779)\tData 0.025 (0.038)\tLoss 181.2314 (181.2374)\t\n",
      "Epoch: [8][1400/10208]\tTime 0.720 (0.778)\tData 0.026 (0.037)\tLoss 181.0585 (181.2210)\t\n",
      "Epoch: [8][1500/10208]\tTime 0.726 (0.778)\tData 0.026 (0.036)\tLoss 180.9017 (181.2136)\t\n",
      "Epoch: [8][1600/10208]\tTime 0.717 (0.777)\tData 0.025 (0.036)\tLoss 180.1153 (181.1994)\t\n",
      "Epoch: [8][1700/10208]\tTime 1.101 (0.776)\tData 0.026 (0.035)\tLoss 180.5182 (181.1861)\t\n",
      "Epoch: [8][1800/10208]\tTime 0.729 (0.776)\tData 0.026 (0.035)\tLoss 181.0942 (181.1698)\t\n",
      "Epoch: [8][1900/10208]\tTime 0.716 (0.775)\tData 0.025 (0.034)\tLoss 180.6859 (181.1583)\t\n",
      "Epoch: [8][2000/10208]\tTime 0.730 (0.775)\tData 0.025 (0.034)\tLoss 181.2198 (181.1490)\t\n",
      "Epoch: [8][2100/10208]\tTime 0.719 (0.774)\tData 0.026 (0.033)\tLoss 180.9523 (181.1389)\t\n",
      "Epoch: [8][2200/10208]\tTime 0.717 (0.774)\tData 0.026 (0.033)\tLoss 180.9402 (181.1248)\t\n",
      "Epoch: [8][2300/10208]\tTime 0.723 (0.774)\tData 0.025 (0.033)\tLoss 181.2125 (181.1171)\t\n",
      "Epoch: [8][2400/10208]\tTime 0.717 (0.773)\tData 0.026 (0.032)\tLoss 180.6860 (181.1090)\t\n",
      "Epoch: [8][2500/10208]\tTime 0.716 (0.773)\tData 0.025 (0.032)\tLoss 181.0039 (181.1061)\t\n",
      "Epoch: [8][2600/10208]\tTime 0.716 (0.773)\tData 0.025 (0.032)\tLoss 181.0552 (181.0994)\t\n",
      "Epoch: [8][2700/10208]\tTime 0.723 (0.773)\tData 0.026 (0.032)\tLoss 180.3257 (181.0880)\t\n",
      "Epoch: [8][2800/10208]\tTime 0.717 (0.772)\tData 0.026 (0.032)\tLoss 180.6876 (181.0789)\t\n",
      "Epoch: [8][2900/10208]\tTime 0.721 (0.772)\tData 0.025 (0.031)\tLoss 181.5227 (181.0797)\t\n",
      "Epoch: [8][3000/10208]\tTime 0.725 (0.772)\tData 0.026 (0.031)\tLoss 182.2811 (181.1275)\t\n",
      "Epoch: [8][3100/10208]\tTime 0.718 (0.772)\tData 0.025 (0.031)\tLoss 181.2791 (181.1488)\t\n",
      "Epoch: [8][3200/10208]\tTime 0.715 (0.772)\tData 0.025 (0.031)\tLoss 180.7948 (181.1484)\t\n",
      "Epoch: [8][3300/10208]\tTime 0.724 (0.771)\tData 0.026 (0.031)\tLoss 182.0010 (181.1432)\t\n",
      "Epoch: [8][3400/10208]\tTime 0.717 (0.771)\tData 0.026 (0.031)\tLoss 180.7553 (181.1331)\t\n",
      "Epoch: [8][3500/10208]\tTime 0.968 (0.771)\tData 0.025 (0.030)\tLoss 181.0809 (181.1256)\t\n",
      "Epoch: [8][3600/10208]\tTime 0.717 (0.771)\tData 0.026 (0.030)\tLoss 181.1407 (181.1189)\t\n",
      "Epoch: [8][3700/10208]\tTime 0.720 (0.771)\tData 0.025 (0.030)\tLoss 180.6736 (181.1168)\t\n",
      "Epoch: [8][3800/10208]\tTime 0.714 (0.771)\tData 0.025 (0.030)\tLoss 181.1124 (181.1083)\t\n",
      "Epoch: [8][3900/10208]\tTime 0.720 (0.771)\tData 0.025 (0.030)\tLoss 180.3501 (181.0984)\t\n",
      "Epoch: [8][4000/10208]\tTime 0.964 (0.771)\tData 0.025 (0.030)\tLoss 181.2963 (181.0924)\t\n",
      "Epoch: [8][4100/10208]\tTime 0.721 (0.771)\tData 0.025 (0.030)\tLoss 181.1204 (181.0838)\t\n",
      "Epoch: [8][4200/10208]\tTime 0.716 (0.770)\tData 0.025 (0.030)\tLoss 180.2416 (181.0722)\t\n",
      "Epoch: [8][4300/10208]\tTime 0.742 (0.770)\tData 0.025 (0.030)\tLoss 180.9473 (181.0664)\t\n",
      "Epoch: [8][4400/10208]\tTime 0.717 (0.770)\tData 0.026 (0.030)\tLoss 180.7964 (181.0576)\t\n",
      "Epoch: [8][4500/10208]\tTime 0.946 (0.770)\tData 0.025 (0.029)\tLoss 180.9640 (181.0485)\t\n",
      "Epoch: [8][4600/10208]\tTime 0.721 (0.770)\tData 0.025 (0.029)\tLoss 180.9243 (181.0404)\t\n",
      "Epoch: [8][4700/10208]\tTime 0.720 (0.770)\tData 0.025 (0.029)\tLoss 180.3308 (181.0330)\t\n",
      "Epoch: [8][4800/10208]\tTime 0.720 (0.770)\tData 0.026 (0.029)\tLoss 180.6422 (181.0248)\t\n",
      "Epoch: [8][4900/10208]\tTime 0.720 (0.770)\tData 0.026 (0.029)\tLoss 180.2569 (181.0172)\t\n",
      "Epoch: [8][5000/10208]\tTime 0.996 (0.770)\tData 0.025 (0.029)\tLoss 180.9713 (181.0073)\t\n",
      "Epoch: [8][5100/10208]\tTime 0.724 (0.770)\tData 0.026 (0.029)\tLoss 180.9290 (181.0026)\t\n",
      "Epoch: [8][5200/10208]\tTime 0.719 (0.770)\tData 0.025 (0.029)\tLoss 180.4748 (180.9982)\t\n",
      "Epoch: [8][5300/10208]\tTime 0.721 (0.770)\tData 0.026 (0.029)\tLoss 179.9950 (180.9896)\t\n",
      "Epoch: [8][5400/10208]\tTime 0.724 (0.770)\tData 0.025 (0.029)\tLoss 180.4847 (180.9807)\t\n",
      "Epoch: [8][5500/10208]\tTime 0.719 (0.770)\tData 0.026 (0.029)\tLoss 180.8512 (180.9723)\t\n",
      "Epoch: [8][5600/10208]\tTime 0.722 (0.770)\tData 0.025 (0.029)\tLoss 180.6789 (180.9660)\t\n",
      "Epoch: [8][5700/10208]\tTime 0.722 (0.770)\tData 0.026 (0.029)\tLoss 180.0396 (180.9577)\t\n",
      "Epoch: [8][5800/10208]\tTime 0.723 (0.769)\tData 0.026 (0.029)\tLoss 180.6144 (180.9510)\t\n",
      "Epoch: [8][5900/10208]\tTime 0.723 (0.769)\tData 0.026 (0.029)\tLoss 180.1695 (180.9456)\t\n",
      "Epoch: [8][6000/10208]\tTime 0.718 (0.769)\tData 0.026 (0.029)\tLoss 181.1189 (180.9396)\t\n",
      "Epoch: [8][6100/10208]\tTime 0.718 (0.769)\tData 0.026 (0.029)\tLoss 179.9453 (180.9341)\t\n",
      "Epoch: [8][6200/10208]\tTime 0.719 (0.769)\tData 0.025 (0.029)\tLoss 181.0451 (180.9285)\t\n",
      "Epoch: [8][6300/10208]\tTime 0.726 (0.769)\tData 0.025 (0.029)\tLoss 179.7806 (180.9231)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][6400/10208]\tTime 0.718 (0.769)\tData 0.026 (0.028)\tLoss 180.4082 (180.9177)\t\n",
      "Epoch: [8][6500/10208]\tTime 0.720 (0.769)\tData 0.026 (0.028)\tLoss 180.2464 (180.9119)\t\n",
      "Epoch: [8][6600/10208]\tTime 0.719 (0.769)\tData 0.026 (0.028)\tLoss 181.5696 (180.9061)\t\n",
      "Epoch: [8][6700/10208]\tTime 0.718 (0.769)\tData 0.026 (0.028)\tLoss 181.0537 (180.9014)\t\n",
      "Epoch: [8][6800/10208]\tTime 0.941 (0.769)\tData 0.026 (0.028)\tLoss 181.0194 (180.8995)\t\n",
      "Epoch: [8][6900/10208]\tTime 0.718 (0.769)\tData 0.026 (0.028)\tLoss 180.2021 (180.8946)\t\n",
      "Epoch: [8][7000/10208]\tTime 0.716 (0.769)\tData 0.025 (0.028)\tLoss 180.9061 (180.8905)\t\n",
      "Epoch: [8][7100/10208]\tTime 0.723 (0.769)\tData 0.026 (0.028)\tLoss 182.4232 (180.8921)\t\n",
      "Epoch: [8][7200/10208]\tTime 0.719 (0.769)\tData 0.025 (0.028)\tLoss 180.0021 (180.8927)\t\n",
      "Epoch: [8][7300/10208]\tTime 1.162 (0.769)\tData 0.025 (0.028)\tLoss 180.6150 (180.8893)\t\n",
      "Epoch: [8][7400/10208]\tTime 0.719 (0.769)\tData 0.025 (0.028)\tLoss 180.4927 (180.8836)\t\n",
      "Epoch: [8][7500/10208]\tTime 0.717 (0.769)\tData 0.025 (0.028)\tLoss 180.3742 (180.8785)\t\n",
      "Epoch: [8][7600/10208]\tTime 0.717 (0.769)\tData 0.025 (0.028)\tLoss 180.9467 (180.8754)\t\n",
      "Epoch: [8][7700/10208]\tTime 0.719 (0.769)\tData 0.026 (0.028)\tLoss 180.6128 (180.8725)\t\n",
      "Epoch: [8][7800/10208]\tTime 0.953 (0.769)\tData 0.026 (0.028)\tLoss 180.8811 (180.8706)\t\n",
      "Epoch: [8][7900/10208]\tTime 0.718 (0.769)\tData 0.025 (0.028)\tLoss 180.2449 (180.8660)\t\n",
      "Epoch: [8][8000/10208]\tTime 0.720 (0.769)\tData 0.025 (0.028)\tLoss 180.5516 (180.8618)\t\n",
      "Epoch: [8][8100/10208]\tTime 0.785 (0.768)\tData 0.054 (0.028)\tLoss 181.3368 (180.8571)\t\n",
      "Epoch: [8][8200/10208]\tTime 0.719 (0.768)\tData 0.025 (0.028)\tLoss 181.0544 (180.8524)\t\n",
      "Epoch: [8][8300/10208]\tTime 0.954 (0.768)\tData 0.025 (0.028)\tLoss 180.2714 (180.8495)\t\n",
      "Epoch: [8][8400/10208]\tTime 0.722 (0.768)\tData 0.025 (0.028)\tLoss 180.8150 (180.8472)\t\n",
      "Epoch: [8][8500/10208]\tTime 0.719 (0.768)\tData 0.026 (0.028)\tLoss 181.0383 (180.8425)\t\n",
      "Epoch: [8][8600/10208]\tTime 0.716 (0.768)\tData 0.026 (0.028)\tLoss 179.8849 (180.8395)\t\n",
      "Epoch: [8][8700/10208]\tTime 0.720 (0.768)\tData 0.026 (0.028)\tLoss 180.3331 (180.8366)\t\n",
      "Epoch: [8][8800/10208]\tTime 0.719 (0.768)\tData 0.026 (0.028)\tLoss 180.8101 (180.8313)\t\n",
      "Epoch: [8][8900/10208]\tTime 0.721 (0.768)\tData 0.025 (0.028)\tLoss 180.0205 (180.8270)\t\n",
      "Epoch: [8][9000/10208]\tTime 0.717 (0.768)\tData 0.025 (0.028)\tLoss 180.1156 (180.8221)\t\n",
      "Epoch: [8][9100/10208]\tTime 0.750 (0.768)\tData 0.025 (0.028)\tLoss 179.7731 (180.8176)\t\n",
      "Epoch: [8][9200/10208]\tTime 0.719 (0.768)\tData 0.025 (0.028)\tLoss 179.7365 (180.8131)\t\n",
      "Epoch: [8][9300/10208]\tTime 0.724 (0.768)\tData 0.026 (0.028)\tLoss 180.4197 (180.8081)\t\n",
      "Epoch: [8][9400/10208]\tTime 0.741 (0.768)\tData 0.025 (0.028)\tLoss 180.7509 (180.8036)\t\n",
      "Epoch: [8][9500/10208]\tTime 0.717 (0.768)\tData 0.025 (0.028)\tLoss 180.1344 (180.7985)\t\n",
      "Epoch: [8][9600/10208]\tTime 0.715 (0.768)\tData 0.025 (0.028)\tLoss 180.8279 (180.7925)\t\n",
      "Epoch: [8][9700/10208]\tTime 0.717 (0.768)\tData 0.025 (0.028)\tLoss 180.3180 (180.7872)\t\n",
      "Epoch: [8][9800/10208]\tTime 0.716 (0.768)\tData 0.025 (0.028)\tLoss 180.8547 (180.7829)\t\n",
      "Epoch: [8][9900/10208]\tTime 0.717 (0.768)\tData 0.026 (0.028)\tLoss 179.8189 (180.7795)\t\n",
      "Epoch: [8][10000/10208]\tTime 0.718 (0.768)\tData 0.026 (0.028)\tLoss 182.1206 (180.7762)\t\n",
      "Epoch: [8][10100/10208]\tTime 0.964 (0.768)\tData 0.026 (0.028)\tLoss 180.4771 (180.7723)\t\n",
      "Epoch: [8][10200/10208]\tTime 0.714 (0.768)\tData 0.025 (0.028)\tLoss 180.9640 (180.7699)\t\n",
      "Epoch: [8][10207/10208]\tTime 0.713 (0.767)\tData 0.025 (0.028)\tLoss 180.1406 (180.7699)\t\n",
      "Start training\n",
      "Epoch: [9][0/10208]\tTime 11.621 (11.621)\tData 10.786 (10.786)\tLoss 180.5722 (180.5722)\t\n",
      "Epoch: [9][100/10208]\tTime 1.058 (0.887)\tData 0.026 (0.141)\tLoss 180.5315 (180.6511)\t\n",
      "Epoch: [9][200/10208]\tTime 0.720 (0.826)\tData 0.025 (0.084)\tLoss 180.5064 (180.5650)\t\n",
      "Epoch: [9][300/10208]\tTime 0.720 (0.809)\tData 0.026 (0.065)\tLoss 180.8988 (180.5136)\t\n",
      "Epoch: [9][400/10208]\tTime 0.741 (0.799)\tData 0.028 (0.055)\tLoss 180.4312 (180.4991)\t\n",
      "Epoch: [9][500/10208]\tTime 0.716 (0.792)\tData 0.025 (0.050)\tLoss 180.4022 (180.4755)\t\n",
      "Epoch: [9][600/10208]\tTime 0.975 (0.789)\tData 0.026 (0.046)\tLoss 179.9856 (180.4686)\t\n",
      "Epoch: [9][700/10208]\tTime 0.719 (0.787)\tData 0.025 (0.043)\tLoss 180.6939 (180.4614)\t\n",
      "Epoch: [9][800/10208]\tTime 0.719 (0.784)\tData 0.025 (0.041)\tLoss 179.7080 (180.4566)\t\n",
      "Epoch: [9][900/10208]\tTime 0.719 (0.783)\tData 0.026 (0.039)\tLoss 180.8699 (180.4573)\t\n",
      "Epoch: [9][1000/10208]\tTime 0.720 (0.781)\tData 0.026 (0.038)\tLoss 180.6808 (180.4433)\t\n",
      "Epoch: [9][1100/10208]\tTime 0.867 (0.780)\tData 0.026 (0.037)\tLoss 180.3449 (180.4372)\t\n",
      "Epoch: [9][1200/10208]\tTime 0.717 (0.779)\tData 0.025 (0.036)\tLoss 179.9350 (180.4258)\t\n",
      "Epoch: [9][1300/10208]\tTime 0.719 (0.778)\tData 0.026 (0.035)\tLoss 180.2831 (180.4229)\t\n",
      "Epoch: [9][1400/10208]\tTime 0.727 (0.778)\tData 0.028 (0.035)\tLoss 180.7820 (180.4258)\t\n",
      "Epoch: [9][1500/10208]\tTime 0.738 (0.777)\tData 0.026 (0.034)\tLoss 180.5686 (180.4200)\t\n",
      "Epoch: [9][1600/10208]\tTime 0.719 (0.776)\tData 0.025 (0.034)\tLoss 180.8540 (180.4113)\t\n",
      "Epoch: [9][1700/10208]\tTime 0.718 (0.776)\tData 0.026 (0.033)\tLoss 180.6745 (180.4165)\t\n",
      "Epoch: [9][1800/10208]\tTime 0.725 (0.775)\tData 0.026 (0.033)\tLoss 181.6033 (180.9510)\t\n",
      "Epoch: [9][1900/10208]\tTime 0.722 (0.775)\tData 0.025 (0.032)\tLoss 181.4672 (180.9765)\t\n",
      "Epoch: [9][2000/10208]\tTime 0.723 (0.775)\tData 0.026 (0.032)\tLoss 180.9699 (180.9775)\t\n",
      "Epoch: [9][2100/10208]\tTime 0.723 (0.774)\tData 0.027 (0.032)\tLoss 180.7043 (180.9618)\t\n",
      "Epoch: [9][2200/10208]\tTime 0.721 (0.774)\tData 0.025 (0.032)\tLoss 180.8271 (180.9422)\t\n",
      "Epoch: [9][2300/10208]\tTime 0.718 (0.774)\tData 0.026 (0.031)\tLoss 180.3974 (180.9210)\t\n",
      "Epoch: [9][2400/10208]\tTime 1.065 (0.774)\tData 0.025 (0.031)\tLoss 180.6523 (180.8996)\t\n",
      "Epoch: [9][2500/10208]\tTime 0.730 (0.774)\tData 0.026 (0.031)\tLoss 179.7549 (180.8806)\t\n",
      "Epoch: [9][2600/10208]\tTime 0.715 (0.773)\tData 0.026 (0.031)\tLoss 179.9988 (180.8623)\t\n",
      "Epoch: [9][2700/10208]\tTime 0.722 (0.773)\tData 0.026 (0.031)\tLoss 180.4337 (180.8451)\t\n",
      "Epoch: [9][2800/10208]\tTime 0.722 (0.773)\tData 0.026 (0.030)\tLoss 180.5802 (180.8284)\t\n",
      "Epoch: [9][2900/10208]\tTime 1.093 (0.773)\tData 0.026 (0.030)\tLoss 180.5079 (180.8129)\t\n",
      "Epoch: [9][3000/10208]\tTime 0.722 (0.773)\tData 0.026 (0.030)\tLoss 180.5340 (180.7920)\t\n",
      "Epoch: [9][3100/10208]\tTime 0.716 (0.773)\tData 0.025 (0.030)\tLoss 179.9069 (180.7793)\t\n",
      "Epoch: [9][3200/10208]\tTime 0.752 (0.773)\tData 0.026 (0.030)\tLoss 179.7510 (180.7682)\t\n",
      "Epoch: [9][3300/10208]\tTime 0.720 (0.773)\tData 0.026 (0.030)\tLoss 179.9056 (180.7563)\t\n",
      "Epoch: [9][3400/10208]\tTime 1.060 (0.773)\tData 0.025 (0.030)\tLoss 180.1467 (180.7447)\t\n",
      "Epoch: [9][3500/10208]\tTime 0.716 (0.772)\tData 0.025 (0.030)\tLoss 180.1879 (180.7315)\t\n",
      "Epoch: [9][3600/10208]\tTime 0.719 (0.772)\tData 0.026 (0.030)\tLoss 179.7975 (180.7182)\t\n",
      "Epoch: [9][3700/10208]\tTime 0.720 (0.772)\tData 0.025 (0.029)\tLoss 180.2600 (180.7077)\t\n",
      "Epoch: [9][3800/10208]\tTime 0.742 (0.772)\tData 0.029 (0.029)\tLoss 180.3726 (180.6974)\t\n",
      "Epoch: [9][3900/10208]\tTime 0.950 (0.772)\tData 0.025 (0.029)\tLoss 179.7206 (180.6857)\t\n",
      "Epoch: [9][4000/10208]\tTime 0.718 (0.772)\tData 0.026 (0.029)\tLoss 180.5507 (180.6767)\t\n",
      "Epoch: [9][4100/10208]\tTime 0.721 (0.772)\tData 0.026 (0.029)\tLoss 180.4108 (180.6652)\t\n",
      "Epoch: [9][4200/10208]\tTime 0.721 (0.771)\tData 0.026 (0.029)\tLoss 179.8304 (180.6538)\t\n",
      "Epoch: [9][4300/10208]\tTime 0.720 (0.771)\tData 0.025 (0.029)\tLoss 180.9381 (180.6441)\t\n",
      "Epoch: [9][4400/10208]\tTime 0.855 (0.771)\tData 0.026 (0.029)\tLoss 180.6948 (180.6331)\t\n",
      "Epoch: [9][4500/10208]\tTime 0.749 (0.771)\tData 0.026 (0.029)\tLoss 181.2458 (180.6207)\t\n",
      "Epoch: [9][4600/10208]\tTime 0.716 (0.771)\tData 0.025 (0.029)\tLoss 180.2767 (180.6098)\t\n",
      "Epoch: [9][4700/10208]\tTime 0.734 (0.771)\tData 0.043 (0.029)\tLoss 178.8132 (180.5982)\t\n",
      "Epoch: [9][4800/10208]\tTime 0.719 (0.771)\tData 0.025 (0.029)\tLoss 180.1683 (180.5890)\t\n",
      "Epoch: [9][4900/10208]\tTime 0.721 (0.771)\tData 0.026 (0.029)\tLoss 180.1714 (180.5833)\t\n",
      "Epoch: [9][5000/10208]\tTime 0.718 (0.771)\tData 0.025 (0.029)\tLoss 180.5148 (180.5775)\t\n",
      "Epoch: [9][5100/10208]\tTime 0.719 (0.770)\tData 0.026 (0.029)\tLoss 180.2266 (180.5716)\t\n",
      "Epoch: [9][5200/10208]\tTime 0.722 (0.770)\tData 0.026 (0.028)\tLoss 179.3453 (180.5637)\t\n",
      "Epoch: [9][5300/10208]\tTime 0.720 (0.770)\tData 0.026 (0.028)\tLoss 179.8639 (180.5568)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][5400/10208]\tTime 0.719 (0.770)\tData 0.026 (0.028)\tLoss 180.2778 (180.5521)\t\n",
      "Epoch: [9][5500/10208]\tTime 0.726 (0.770)\tData 0.026 (0.028)\tLoss 180.6453 (180.5453)\t\n",
      "Epoch: [9][5600/10208]\tTime 0.719 (0.770)\tData 0.026 (0.028)\tLoss 180.0227 (180.5379)\t\n",
      "Epoch: [9][5700/10208]\tTime 0.959 (0.770)\tData 0.026 (0.028)\tLoss 180.2872 (180.5318)\t\n",
      "Epoch: [9][5800/10208]\tTime 0.720 (0.770)\tData 0.026 (0.028)\tLoss 180.1253 (180.5261)\t\n",
      "Epoch: [9][5900/10208]\tTime 0.717 (0.770)\tData 0.025 (0.028)\tLoss 180.3584 (180.5197)\t\n",
      "Epoch: [9][6000/10208]\tTime 0.725 (0.770)\tData 0.026 (0.028)\tLoss 180.0548 (180.5138)\t\n",
      "Epoch: [9][6100/10208]\tTime 0.722 (0.770)\tData 0.026 (0.028)\tLoss 180.6653 (180.5081)\t\n",
      "Epoch: [9][6200/10208]\tTime 1.087 (0.770)\tData 0.026 (0.028)\tLoss 179.6538 (180.5022)\t\n",
      "Epoch: [9][6300/10208]\tTime 0.722 (0.770)\tData 0.026 (0.028)\tLoss 180.0162 (180.4962)\t\n",
      "Epoch: [9][6400/10208]\tTime 0.722 (0.770)\tData 0.026 (0.028)\tLoss 180.1648 (180.4921)\t\n",
      "Epoch: [9][6500/10208]\tTime 0.726 (0.770)\tData 0.025 (0.028)\tLoss 180.3094 (180.4892)\t\n",
      "Epoch: [9][6600/10208]\tTime 0.718 (0.770)\tData 0.025 (0.028)\tLoss 180.1871 (180.4834)\t\n",
      "Epoch: [9][6700/10208]\tTime 1.050 (0.770)\tData 0.025 (0.028)\tLoss 180.4312 (180.4785)\t\n",
      "Epoch: [9][6800/10208]\tTime 0.724 (0.770)\tData 0.026 (0.028)\tLoss 179.9020 (180.4734)\t\n",
      "Epoch: [9][6900/10208]\tTime 0.716 (0.770)\tData 0.025 (0.028)\tLoss 180.4017 (180.4704)\t\n",
      "Epoch: [9][7000/10208]\tTime 0.725 (0.770)\tData 0.025 (0.028)\tLoss 180.2889 (180.4661)\t\n",
      "Epoch: [9][7100/10208]\tTime 0.721 (0.770)\tData 0.026 (0.028)\tLoss 179.7487 (180.4622)\t\n",
      "Epoch: [9][7200/10208]\tTime 1.056 (0.770)\tData 0.026 (0.028)\tLoss 180.4613 (180.4591)\t\n",
      "Epoch: [9][7300/10208]\tTime 0.722 (0.770)\tData 0.025 (0.028)\tLoss 180.2015 (180.4544)\t\n",
      "Epoch: [9][7400/10208]\tTime 0.714 (0.770)\tData 0.025 (0.028)\tLoss 180.6090 (180.4514)\t\n",
      "Epoch: [9][7500/10208]\tTime 0.724 (0.770)\tData 0.025 (0.028)\tLoss 181.1603 (180.4512)\t\n",
      "Epoch: [9][7600/10208]\tTime 0.732 (0.770)\tData 0.038 (0.028)\tLoss 180.3313 (180.4515)\t\n",
      "Epoch: [9][7700/10208]\tTime 0.885 (0.770)\tData 0.025 (0.028)\tLoss 184.1046 (180.4922)\t\n",
      "Epoch: [9][7800/10208]\tTime 0.717 (0.770)\tData 0.025 (0.028)\tLoss 181.2003 (180.5241)\t\n",
      "Epoch: [9][7900/10208]\tTime 0.720 (0.770)\tData 0.026 (0.028)\tLoss 181.2337 (180.5306)\t\n",
      "Epoch: [9][8000/10208]\tTime 0.723 (0.770)\tData 0.026 (0.028)\tLoss 180.7722 (180.5333)\t\n",
      "Epoch: [9][8100/10208]\tTime 0.721 (0.770)\tData 0.025 (0.028)\tLoss 180.9817 (180.5343)\t\n",
      "Epoch: [9][8200/10208]\tTime 0.721 (0.770)\tData 0.026 (0.028)\tLoss 179.9154 (180.5336)\t\n",
      "Epoch: [9][8300/10208]\tTime 0.724 (0.770)\tData 0.027 (0.028)\tLoss 180.2536 (180.5314)\t\n",
      "Epoch: [9][8400/10208]\tTime 0.721 (0.770)\tData 0.026 (0.028)\tLoss 180.3368 (180.5286)\t\n",
      "Epoch: [9][8500/10208]\tTime 0.720 (0.769)\tData 0.025 (0.028)\tLoss 180.5347 (180.5266)\t\n",
      "Epoch: [9][8600/10208]\tTime 0.716 (0.770)\tData 0.025 (0.028)\tLoss 179.7864 (180.5232)\t\n",
      "Epoch: [9][8700/10208]\tTime 0.722 (0.769)\tData 0.026 (0.028)\tLoss 181.1488 (180.5203)\t\n",
      "Epoch: [9][8800/10208]\tTime 0.725 (0.769)\tData 0.026 (0.028)\tLoss 180.1074 (180.5177)\t\n",
      "Epoch: [9][8900/10208]\tTime 0.717 (0.769)\tData 0.025 (0.028)\tLoss 180.4427 (180.5143)\t\n",
      "Epoch: [9][9000/10208]\tTime 1.102 (0.769)\tData 0.026 (0.028)\tLoss 180.2796 (180.5108)\t\n",
      "Epoch: [9][9100/10208]\tTime 0.723 (0.769)\tData 0.025 (0.028)\tLoss 180.1251 (180.5079)\t\n",
      "Epoch: [9][9200/10208]\tTime 0.722 (0.769)\tData 0.026 (0.028)\tLoss 179.7305 (180.5043)\t\n",
      "Epoch: [9][9300/10208]\tTime 0.741 (0.769)\tData 0.025 (0.028)\tLoss 179.8996 (180.5009)\t\n",
      "Epoch: [9][9400/10208]\tTime 0.725 (0.769)\tData 0.025 (0.027)\tLoss 179.9917 (180.4970)\t\n",
      "Epoch: [9][9500/10208]\tTime 0.969 (0.769)\tData 0.026 (0.027)\tLoss 179.9454 (180.4936)\t\n",
      "Epoch: [9][9600/10208]\tTime 0.725 (0.769)\tData 0.025 (0.027)\tLoss 180.5480 (180.4914)\t\n",
      "Epoch: [9][9700/10208]\tTime 0.723 (0.769)\tData 0.025 (0.027)\tLoss 180.6138 (180.4882)\t\n",
      "Epoch: [9][9800/10208]\tTime 0.721 (0.769)\tData 0.025 (0.027)\tLoss 180.5140 (180.4848)\t\n",
      "Epoch: [9][9900/10208]\tTime 0.719 (0.769)\tData 0.025 (0.027)\tLoss 181.2876 (180.4817)\t\n",
      "Epoch: [9][10000/10208]\tTime 0.960 (0.769)\tData 0.025 (0.027)\tLoss 181.4847 (180.4790)\t\n",
      "Epoch: [9][10100/10208]\tTime 0.717 (0.769)\tData 0.025 (0.027)\tLoss 179.7202 (180.4758)\t\n",
      "Epoch: [9][10200/10208]\tTime 0.716 (0.769)\tData 0.025 (0.027)\tLoss 180.0004 (180.4722)\t\n",
      "Epoch: [9][10207/10208]\tTime 0.731 (0.769)\tData 0.025 (0.027)\tLoss 180.3005 (180.4720)\t\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.000025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [8][0/8971]\tTime 15.574 (15.574)\tData 14.147 (14.147)\tLoss 205.2969 (205.2969)\t\n",
      "Epoch: [8][200/8971]\tTime 0.775 (0.904)\tData 0.029 (0.108)\tLoss 205.1523 (204.9100)\t\n",
      "Epoch: [8][400/8971]\tTime 0.778 (0.868)\tData 0.029 (0.069)\tLoss 204.8010 (204.8878)\t\n",
      "Epoch: [8][600/8971]\tTime 0.774 (0.853)\tData 0.029 (0.056)\tLoss 205.1207 (204.8705)\t\n",
      "Epoch: [8][800/8971]\tTime 0.773 (0.845)\tData 0.029 (0.049)\tLoss 205.5025 (204.8664)\t\n",
      "Epoch: [8][1000/8971]\tTime 0.790 (0.840)\tData 0.029 (0.045)\tLoss 204.6568 (204.8549)\t\n",
      "Epoch: [8][1200/8971]\tTime 0.774 (0.837)\tData 0.029 (0.043)\tLoss 205.0906 (204.8370)\t\n",
      "Epoch: [8][1400/8971]\tTime 0.793 (0.836)\tData 0.029 (0.041)\tLoss 204.6689 (204.8241)\t\n",
      "Epoch: [8][1600/8971]\tTime 0.770 (0.834)\tData 0.029 (0.039)\tLoss 204.5878 (204.8193)\t\n",
      "Epoch: [8][1800/8971]\tTime 1.214 (0.833)\tData 0.029 (0.038)\tLoss 204.4993 (204.8078)\t\n",
      "Epoch: [8][2000/8971]\tTime 0.774 (0.832)\tData 0.028 (0.037)\tLoss 204.8055 (204.8023)\t\n",
      "Epoch: [8][2200/8971]\tTime 0.773 (0.832)\tData 0.029 (0.037)\tLoss 205.2406 (204.7968)\t\n",
      "Epoch: [8][2400/8971]\tTime 0.775 (0.831)\tData 0.029 (0.036)\tLoss 204.4287 (204.7905)\t\n",
      "Epoch: [8][2600/8971]\tTime 0.769 (0.831)\tData 0.029 (0.036)\tLoss 204.6576 (204.7876)\t\n",
      "Epoch: [8][2800/8971]\tTime 1.012 (0.830)\tData 0.028 (0.035)\tLoss 204.7441 (204.7840)\t\n",
      "Epoch: [8][3000/8971]\tTime 0.770 (0.830)\tData 0.029 (0.035)\tLoss 205.3879 (204.7785)\t\n",
      "Epoch: [8][3200/8971]\tTime 0.775 (0.830)\tData 0.029 (0.034)\tLoss 205.0998 (204.7725)\t\n",
      "Epoch: [8][3400/8971]\tTime 0.771 (0.830)\tData 0.029 (0.034)\tLoss 204.1947 (204.7665)\t\n",
      "Epoch: [8][3600/8971]\tTime 0.791 (0.829)\tData 0.029 (0.034)\tLoss 204.9965 (204.7600)\t\n",
      "Epoch: [8][3800/8971]\tTime 0.824 (0.829)\tData 0.029 (0.034)\tLoss 204.5039 (204.7554)\t\n",
      "Epoch: [8][4000/8971]\tTime 0.781 (0.829)\tData 0.029 (0.034)\tLoss 204.8842 (204.7515)\t\n",
      "Epoch: [8][4200/8971]\tTime 0.809 (0.828)\tData 0.029 (0.033)\tLoss 205.1334 (204.7482)\t\n",
      "Epoch: [8][4400/8971]\tTime 0.773 (0.828)\tData 0.029 (0.033)\tLoss 205.0770 (204.7395)\t\n",
      "Epoch: [8][4600/8971]\tTime 0.772 (0.828)\tData 0.028 (0.033)\tLoss 204.5621 (204.7352)\t\n",
      "Epoch: [8][4800/8971]\tTime 0.774 (0.827)\tData 0.029 (0.033)\tLoss 203.9621 (204.7298)\t\n",
      "Epoch: [8][5000/8971]\tTime 0.778 (0.827)\tData 0.029 (0.033)\tLoss 205.4664 (204.7249)\t\n",
      "Epoch: [8][5200/8971]\tTime 0.772 (0.827)\tData 0.029 (0.033)\tLoss 204.4165 (204.7229)\t\n",
      "Epoch: [8][5400/8971]\tTime 0.774 (0.827)\tData 0.029 (0.032)\tLoss 203.9490 (204.7165)\t\n",
      "Epoch: [8][5600/8971]\tTime 1.038 (0.827)\tData 0.029 (0.032)\tLoss 204.1893 (204.7111)\t\n",
      "Epoch: [8][5800/8971]\tTime 0.772 (0.826)\tData 0.029 (0.032)\tLoss 205.0043 (204.7091)\t\n",
      "Epoch: [8][6000/8971]\tTime 0.771 (0.826)\tData 0.029 (0.032)\tLoss 204.2393 (204.7060)\t\n",
      "Epoch: [8][6200/8971]\tTime 0.771 (0.826)\tData 0.029 (0.032)\tLoss 204.7302 (204.7050)\t\n",
      "Epoch: [8][6400/8971]\tTime 0.793 (0.826)\tData 0.029 (0.032)\tLoss 205.1610 (204.7005)\t\n",
      "Epoch: [8][6600/8971]\tTime 1.294 (0.826)\tData 0.029 (0.032)\tLoss 204.5756 (204.6980)\t\n",
      "Epoch: [8][6800/8971]\tTime 0.775 (0.826)\tData 0.029 (0.032)\tLoss 204.9279 (204.6959)\t\n",
      "Epoch: [8][7000/8971]\tTime 0.775 (0.826)\tData 0.029 (0.032)\tLoss 204.6865 (204.6917)\t\n",
      "Epoch: [8][7200/8971]\tTime 0.777 (0.826)\tData 0.029 (0.032)\tLoss 203.9379 (204.6888)\t\n",
      "Epoch: [8][7400/8971]\tTime 0.771 (0.826)\tData 0.029 (0.032)\tLoss 204.5195 (204.6861)\t\n",
      "Epoch: [8][7600/8971]\tTime 0.773 (0.826)\tData 0.029 (0.032)\tLoss 204.7771 (204.6818)\t\n",
      "Epoch: [8][7800/8971]\tTime 0.805 (0.826)\tData 0.029 (0.032)\tLoss 204.2659 (204.6781)\t\n",
      "Epoch: [8][8000/8971]\tTime 0.775 (0.826)\tData 0.029 (0.031)\tLoss 204.0973 (204.6748)\t\n",
      "Epoch: [8][8200/8971]\tTime 0.768 (0.825)\tData 0.029 (0.031)\tLoss 204.8149 (204.6718)\t\n",
      "Epoch: [8][8400/8971]\tTime 1.211 (0.825)\tData 0.029 (0.031)\tLoss 204.4371 (204.6685)\t\n",
      "Epoch: [8][8600/8971]\tTime 0.772 (0.825)\tData 0.029 (0.031)\tLoss 204.7478 (204.6656)\t\n",
      "Epoch: [8][8800/8971]\tTime 0.776 (0.825)\tData 0.029 (0.031)\tLoss 204.3093 (204.6616)\t\n",
      "Epoch: [8][8970/8971]\tTime 0.774 (0.825)\tData 0.029 (0.031)\tLoss 204.1929 (204.6589)\t\n",
      "Start training\n",
      "Epoch: [9][0/8971]\tTime 15.453 (15.453)\tData 14.497 (14.497)\tLoss 204.3325 (204.3325)\t\n",
      "Epoch: [9][200/8971]\tTime 1.243 (0.910)\tData 0.029 (0.104)\tLoss 205.3067 (204.5334)\t\n",
      "Epoch: [9][400/8971]\tTime 0.772 (0.865)\tData 0.028 (0.067)\tLoss 204.2227 (204.5121)\t\n",
      "Epoch: [9][600/8971]\tTime 0.773 (0.852)\tData 0.029 (0.055)\tLoss 204.9827 (204.4802)\t\n",
      "Epoch: [9][800/8971]\tTime 0.777 (0.845)\tData 0.029 (0.048)\tLoss 204.1584 (204.4679)\t\n",
      "Epoch: [9][1000/8971]\tTime 0.772 (0.841)\tData 0.029 (0.044)\tLoss 204.1195 (204.4787)\t\n",
      "Epoch: [9][1200/8971]\tTime 1.024 (0.837)\tData 0.029 (0.042)\tLoss 204.2636 (204.4777)\t\n",
      "Epoch: [9][1400/8971]\tTime 0.770 (0.835)\tData 0.029 (0.040)\tLoss 204.9561 (204.4731)\t\n",
      "Epoch: [9][1600/8971]\tTime 0.774 (0.834)\tData 0.029 (0.039)\tLoss 204.0638 (204.4751)\t\n",
      "Epoch: [9][1800/8971]\tTime 0.769 (0.833)\tData 0.029 (0.038)\tLoss 204.3301 (204.4694)\t\n",
      "Epoch: [9][2000/8971]\tTime 0.772 (0.832)\tData 0.029 (0.037)\tLoss 204.6919 (204.4657)\t\n",
      "Epoch: [9][2200/8971]\tTime 0.774 (0.831)\tData 0.029 (0.036)\tLoss 205.1110 (204.4643)\t\n",
      "Epoch: [9][2400/8971]\tTime 0.774 (0.830)\tData 0.029 (0.036)\tLoss 204.2437 (204.4661)\t\n",
      "Epoch: [9][2600/8971]\tTime 0.775 (0.830)\tData 0.029 (0.035)\tLoss 205.0291 (204.4626)\t\n",
      "Epoch: [9][2800/8971]\tTime 0.771 (0.830)\tData 0.028 (0.035)\tLoss 204.7587 (204.4633)\t\n",
      "Epoch: [9][3000/8971]\tTime 0.770 (0.829)\tData 0.029 (0.034)\tLoss 204.7171 (204.4668)\t\n",
      "Epoch: [9][3200/8971]\tTime 0.773 (0.829)\tData 0.029 (0.034)\tLoss 204.8570 (204.4677)\t\n",
      "Epoch: [9][3400/8971]\tTime 0.774 (0.828)\tData 0.029 (0.034)\tLoss 204.7101 (204.4641)\t\n",
      "Epoch: [9][3600/8971]\tTime 0.771 (0.828)\tData 0.029 (0.034)\tLoss 204.5541 (204.4641)\t\n",
      "Epoch: [9][3800/8971]\tTime 0.773 (0.828)\tData 0.029 (0.033)\tLoss 203.9497 (204.4647)\t\n",
      "Epoch: [9][4000/8971]\tTime 1.026 (0.828)\tData 0.029 (0.033)\tLoss 204.9250 (204.4648)\t\n",
      "Epoch: [9][4200/8971]\tTime 0.774 (0.828)\tData 0.029 (0.033)\tLoss 203.8961 (204.4633)\t\n",
      "Epoch: [9][4400/8971]\tTime 0.775 (0.828)\tData 0.029 (0.033)\tLoss 204.1967 (204.4648)\t\n",
      "Epoch: [9][4600/8971]\tTime 0.778 (0.828)\tData 0.029 (0.033)\tLoss 203.9806 (204.4660)\t\n",
      "Epoch: [9][4800/8971]\tTime 0.780 (0.828)\tData 0.029 (0.033)\tLoss 204.3442 (204.4611)\t\n",
      "Epoch: [9][5000/8971]\tTime 1.022 (0.828)\tData 0.029 (0.032)\tLoss 205.9226 (204.4584)\t\n",
      "Epoch: [9][5200/8971]\tTime 0.777 (0.828)\tData 0.029 (0.032)\tLoss 204.2292 (204.4571)\t\n",
      "Epoch: [9][5400/8971]\tTime 0.781 (0.828)\tData 0.029 (0.032)\tLoss 205.4055 (204.4517)\t\n",
      "Epoch: [9][5600/8971]\tTime 0.775 (0.828)\tData 0.029 (0.032)\tLoss 205.1908 (204.4494)\t\n",
      "Epoch: [9][5800/8971]\tTime 0.772 (0.828)\tData 0.029 (0.032)\tLoss 204.0681 (204.4472)\t\n",
      "Epoch: [9][6000/8971]\tTime 0.776 (0.828)\tData 0.029 (0.032)\tLoss 205.1414 (204.4472)\t\n",
      "Epoch: [9][6200/8971]\tTime 0.783 (0.828)\tData 0.030 (0.032)\tLoss 203.9245 (204.4450)\t\n",
      "Epoch: [9][6400/8971]\tTime 0.781 (0.829)\tData 0.029 (0.032)\tLoss 204.4332 (204.4427)\t\n",
      "Epoch: [9][6600/8971]\tTime 0.773 (0.829)\tData 0.030 (0.032)\tLoss 204.7556 (204.4398)\t\n",
      "Epoch: [9][6800/8971]\tTime 1.079 (0.829)\tData 0.031 (0.032)\tLoss 203.9916 (204.4406)\t\n",
      "Epoch: [9][7000/8971]\tTime 0.785 (0.829)\tData 0.030 (0.032)\tLoss 204.8492 (204.4405)\t\n",
      "Epoch: [9][7200/8971]\tTime 0.778 (0.830)\tData 0.029 (0.032)\tLoss 204.7006 (204.4389)\t\n",
      "Epoch: [9][7400/8971]\tTime 0.785 (0.830)\tData 0.029 (0.032)\tLoss 205.3138 (204.4369)\t\n",
      "Epoch: [9][7600/8971]\tTime 0.778 (0.830)\tData 0.029 (0.032)\tLoss 203.5088 (204.4358)\t\n",
      "Epoch: [9][7800/8971]\tTime 1.167 (0.830)\tData 0.029 (0.031)\tLoss 204.4872 (204.4361)\t\n",
      "Epoch: [9][8000/8971]\tTime 0.779 (0.830)\tData 0.029 (0.031)\tLoss 204.7343 (204.4338)\t\n",
      "Epoch: [9][8200/8971]\tTime 0.777 (0.830)\tData 0.029 (0.031)\tLoss 203.9907 (204.4321)\t\n",
      "Epoch: [9][8400/8971]\tTime 0.779 (0.830)\tData 0.029 (0.031)\tLoss 204.5673 (204.4303)\t\n",
      "Epoch: [9][8600/8971]\tTime 0.845 (0.830)\tData 0.063 (0.031)\tLoss 204.3015 (204.4297)\t\n",
      "Epoch: [9][8800/8971]\tTime 0.779 (0.830)\tData 0.029 (0.031)\tLoss 203.6735 (204.4292)\t\n",
      "Epoch: [9][8970/8971]\tTime 0.782 (0.830)\tData 0.029 (0.031)\tLoss 204.3113 (204.4274)\t\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,10):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
