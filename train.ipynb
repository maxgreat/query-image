{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import fastText\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import models\n",
    "from dataset import openimages\n",
    "from utils.loss import HardNegativeContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq=1000):\n",
    "    #amp_handle = amp.init()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.train()\n",
    "    print(\"Start training\")\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps) in enumerate(train_loader):\n",
    "        if i%2 == 1:\n",
    "                print(\"%2.2f\"% (i/len(train_loader)*100), '\\%', end='\\r')\n",
    "        input_imgs, target = imgs.cuda(), caps.cuda()\n",
    "        \n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_imgs = model(input_imgs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_imgs, target)\n",
    "        \n",
    "        #with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg, batch_time.avg, data_time.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    imgs_enc = list()\n",
    "    caps_enc = list()\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "\n",
    "        input_imgs, input_caps = imgs.cuda(), caps.cuda()\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_imgs = model(input_imgs)\n",
    "            loss = criterion(output_imgs, input_caps)\n",
    "\n",
    "        imgs_enc.append(output_imgs.cpu().data.numpy())\n",
    "        caps_enc.append(output_caps.cpu().data.numpy())\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(val_loader) - 1):\n",
    "            print('Data: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    recall  = eval_recall(imgs_enc, caps_enc)\n",
    "    print(recall)\n",
    "    return losses.avg, batch_time.avg, data_time.avg, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prepro = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "prepro_val = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(models.ImageProjection().train().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.module.projection.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_embeds(data):\n",
    "    images, targets = zip(*data)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.Tensor(np.stack(targets, 0))\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3072, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HardNegativeContrastiveLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/1495]\tTime 57.686 (57.686)\tData 55.812 (55.812)\tLoss 11156.9834 (11156.9834)\t\n",
      "Epoch: [0][50/1495]\tTime 1.941 (3.176)\tData 0.172 (1.323)\tLoss 14512.1816 (11738.2635)\t\n",
      "Epoch: [0][100/1495]\tTime 1.930 (2.611)\tData 0.180 (0.763)\tLoss 10697.8145 (12910.2606)\t\n",
      "Epoch: [0][150/1495]\tTime 1.927 (2.428)\tData 0.174 (0.572)\tLoss 9919.4033 (12393.1876)\t\n",
      "Epoch: [0][200/1495]\tTime 2.356 (2.334)\tData 0.171 (0.474)\tLoss 9541.3018 (11695.1548)\t\n",
      "Epoch: [0][250/1495]\tTime 1.931 (2.278)\tData 0.174 (0.415)\tLoss 11456.1816 (11713.4279)\t\n",
      "Epoch: [0][300/1495]\tTime 1.930 (2.242)\tData 0.173 (0.378)\tLoss 8610.6426 (11527.3202)\t\n",
      "Epoch: [0][350/1495]\tTime 1.927 (2.212)\tData 0.173 (0.349)\tLoss 10150.8496 (11256.3370)\t\n",
      "Epoch: [0][400/1495]\tTime 1.932 (2.191)\tData 0.173 (0.329)\tLoss 8981.0293 (11009.7895)\t\n",
      "Epoch: [0][450/1495]\tTime 1.928 (2.171)\tData 0.172 (0.312)\tLoss 7935.8086 (10773.1899)\t\n",
      "Epoch: [0][500/1495]\tTime 1.928 (2.158)\tData 0.174 (0.299)\tLoss 11941.0254 (10590.1031)\t\n",
      "Epoch: [0][550/1495]\tTime 2.846 (2.149)\tData 0.173 (0.288)\tLoss 10718.6113 (10699.1796)\t\n",
      "Epoch: [0][600/1495]\tTime 1.932 (2.139)\tData 0.175 (0.280)\tLoss 10039.4668 (10709.5529)\t\n",
      "Epoch: [0][650/1495]\tTime 2.022 (2.130)\tData 0.171 (0.272)\tLoss 12112.8984 (10713.5869)\t\n",
      "Epoch: [0][700/1495]\tTime 1.927 (2.124)\tData 0.171 (0.265)\tLoss 11739.2246 (10755.2663)\t\n",
      "Epoch: [0][750/1495]\tTime 1.956 (2.118)\tData 0.172 (0.259)\tLoss 14559.8281 (10892.0209)\t\n",
      "Epoch: [0][800/1495]\tTime 1.984 (2.112)\tData 0.173 (0.254)\tLoss 12566.6211 (11114.1406)\t\n",
      "Epoch: [0][850/1495]\tTime 1.925 (2.107)\tData 0.171 (0.249)\tLoss 9235.0312 (11107.5885)\t\n",
      "Epoch: [0][900/1495]\tTime 2.956 (2.104)\tData 0.170 (0.245)\tLoss 7317.0693 (11001.8111)\t\n",
      "Epoch: [0][950/1495]\tTime 1.918 (2.104)\tData 0.172 (0.243)\tLoss 8148.6157 (10840.0773)\t\n",
      "Epoch: [0][1000/1495]\tTime 1.926 (2.101)\tData 0.172 (0.240)\tLoss 8788.2979 (10746.9838)\t\n",
      "Epoch: [0][1050/1495]\tTime 1.942 (2.100)\tData 0.171 (0.238)\tLoss 10482.3984 (10740.8930)\t\n",
      "Epoch: [0][1100/1495]\tTime 1.922 (2.098)\tData 0.171 (0.236)\tLoss 13315.4062 (10809.4734)\t\n",
      "Epoch: [0][1150/1495]\tTime 1.924 (2.096)\tData 0.172 (0.233)\tLoss 11145.1357 (10937.3735)\t\n",
      "Epoch: [0][1200/1495]\tTime 1.926 (2.093)\tData 0.175 (0.231)\tLoss 9595.1250 (10917.8117)\t\n",
      "Epoch: [0][1250/1495]\tTime 2.372 (2.091)\tData 0.171 (0.229)\tLoss 12317.5371 (10946.3614)\t\n",
      "Epoch: [0][1300/1495]\tTime 1.941 (2.088)\tData 0.171 (0.227)\tLoss 11649.9639 (10994.7543)\t\n",
      "Epoch: [0][1350/1495]\tTime 1.930 (2.086)\tData 0.171 (0.226)\tLoss 11691.6631 (11028.0493)\t\n",
      "Epoch: [0][1400/1495]\tTime 1.923 (2.083)\tData 0.171 (0.224)\tLoss 13394.8389 (11048.7972)\t\n",
      "Epoch: [0][1450/1495]\tTime 2.133 (2.081)\tData 0.171 (0.223)\tLoss 11011.9854 (11127.7347)\t\n",
      "Epoch: [0][1494/1495]\tTime 1.916 (2.078)\tData 0.169 (0.222)\tLoss 11560.7578 (11155.1306)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11155.130577510974, 2.0784580095157175, 0.2216013138110821)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [4][0/1495]\tTime 61.458 (61.458)\tData 59.626 (59.626)\tLoss 8671.2266 (8671.2266)\t\n",
      "Epoch: [4][50/1495]\tTime 1.913 (3.199)\tData 0.169 (1.360)\tLoss 4107.7988 (5924.8596)\t\n",
      "Epoch: [4][100/1495]\tTime 1.931 (2.637)\tData 0.170 (0.783)\tLoss 3169.9741 (4811.2926)\t\n",
      "Epoch: [4][150/1495]\tTime 2.574 (2.453)\tData 0.169 (0.584)\tLoss 2787.2908 (4196.5531)\t\n",
      "Epoch: [4][200/1495]\tTime 1.940 (2.359)\tData 0.186 (0.485)\tLoss 2699.8037 (3825.2861)\t\n",
      "Epoch: [4][250/1495]\tTime 1.916 (2.297)\tData 0.171 (0.424)\tLoss 2807.6538 (3594.3144)\t\n",
      "Epoch: [4][300/1495]\tTime 2.076 (2.253)\tData 0.300 (0.384)\tLoss 2800.8647 (3443.1368)\t\n",
      "Epoch: [4][350/1495]\tTime 1.920 (2.234)\tData 0.170 (0.356)\tLoss 2857.4600 (3352.7536)\t\n",
      "Epoch: [4][400/1495]\tTime 1.920 (2.210)\tData 0.170 (0.335)\tLoss 3260.1409 (3334.5414)\t\n",
      "Epoch: [4][450/1495]\tTime 2.116 (2.191)\tData 0.364 (0.319)\tLoss 3015.0947 (3299.1341)\t\n",
      "Epoch: [4][500/1495]\tTime 2.449 (2.176)\tData 0.169 (0.305)\tLoss 2735.7253 (3249.4279)\t\n",
      "Epoch: [4][550/1495]\tTime 1.919 (2.164)\tData 0.169 (0.294)\tLoss 2722.9741 (3200.0420)\t\n",
      "Epoch: [4][600/1495]\tTime 1.929 (2.154)\tData 0.170 (0.284)\tLoss 2514.9170 (3161.3983)\t\n",
      "Epoch: [4][650/1495]\tTime 1.921 (2.148)\tData 0.173 (0.276)\tLoss 2792.1660 (3120.2609)\t\n",
      "Epoch: [4][700/1495]\tTime 1.920 (2.142)\tData 0.172 (0.270)\tLoss 3390.3047 (3125.5092)\t\n",
      "Epoch: [4][750/1495]\tTime 1.923 (2.135)\tData 0.173 (0.264)\tLoss 3746.5107 (3183.4511)\t\n",
      "Epoch: [4][800/1495]\tTime 2.070 (2.130)\tData 0.171 (0.259)\tLoss 4560.0566 (3238.0012)\t\n",
      "Epoch: [4][850/1495]\tTime 2.349 (2.124)\tData 0.170 (0.254)\tLoss 4538.6455 (3337.7078)\t\n",
      "Epoch: [4][900/1495]\tTime 1.922 (2.122)\tData 0.169 (0.250)\tLoss 3319.9717 (3398.5513)\t\n",
      "Epoch: [4][950/1495]\tTime 2.193 (2.118)\tData 0.169 (0.247)\tLoss 2611.8262 (3376.5784)\t\n",
      "Epoch: [4][1000/1495]\tTime 1.922 (2.113)\tData 0.170 (0.244)\tLoss 2894.1094 (3337.9779)\t\n",
      "Epoch: [4][1050/1495]\tTime 1.932 (2.110)\tData 0.169 (0.241)\tLoss 2505.7153 (3305.8190)\t\n",
      "Epoch: [4][1100/1495]\tTime 1.918 (2.106)\tData 0.169 (0.238)\tLoss 2476.0239 (3270.0806)\t\n",
      "76.45 \\%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/envs/py36/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8921a3eba3f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a4ce6b0bf87b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, print_freq)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%2.2f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\%'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0minput_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 4, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Keep the first layer of resnet frozen\n",
    "for i in range(0, 6):\n",
    "    for param in m.module.base_layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [8][0/10208]\tTime 15.876 (15.876)\tData 14.522 (14.522)\tLoss 249.2530 (249.2530)\t\n",
      "Epoch: [8][100/10208]\tTime 0.724 (0.927)\tData 0.026 (0.171)\tLoss 226.3943 (239.8907)\t\n",
      "Epoch: [8][200/10208]\tTime 0.724 (0.868)\tData 0.026 (0.099)\tLoss 228.6726 (235.6185)\t\n",
      "Epoch: [8][300/10208]\tTime 0.725 (0.838)\tData 0.026 (0.075)\tLoss 230.6595 (233.0092)\t\n",
      "Epoch: [8][400/10208]\tTime 0.725 (0.822)\tData 0.026 (0.063)\tLoss 225.4995 (231.3337)\t\n",
      "Epoch: [8][500/10208]\tTime 0.945 (0.813)\tData 0.026 (0.056)\tLoss 217.3611 (229.5482)\t\n",
      "Epoch: [8][600/10208]\tTime 0.730 (0.809)\tData 0.026 (0.051)\tLoss 215.5688 (228.3176)\t\n",
      "Epoch: [8][700/10208]\tTime 0.731 (0.803)\tData 0.026 (0.047)\tLoss 227.7986 (227.4418)\t\n",
      "Epoch: [8][800/10208]\tTime 0.763 (0.801)\tData 0.025 (0.045)\tLoss 213.1459 (226.4875)\t\n",
      "Epoch: [8][900/10208]\tTime 0.735 (0.798)\tData 0.026 (0.043)\tLoss 219.0038 (225.6315)\t\n",
      "Epoch: [8][1000/10208]\tTime 0.828 (0.797)\tData 0.027 (0.041)\tLoss 214.3507 (224.8640)\t\n",
      "Epoch: [8][1100/10208]\tTime 0.764 (0.795)\tData 0.026 (0.040)\tLoss 216.9480 (224.1786)\t\n",
      "Epoch: [8][1200/10208]\tTime 0.730 (0.794)\tData 0.026 (0.038)\tLoss 214.9810 (223.5560)\t\n",
      "Epoch: [8][1300/10208]\tTime 0.731 (0.793)\tData 0.026 (0.038)\tLoss 215.0019 (223.0380)\t\n",
      "Epoch: [8][1400/10208]\tTime 0.723 (0.792)\tData 0.026 (0.037)\tLoss 214.1169 (222.5656)\t\n",
      "Epoch: [8][1500/10208]\tTime 0.732 (0.791)\tData 0.031 (0.036)\tLoss 213.9513 (222.0694)\t\n",
      "Epoch: [8][1600/10208]\tTime 0.721 (0.791)\tData 0.025 (0.036)\tLoss 214.2951 (221.6406)\t\n",
      "Epoch: [8][1700/10208]\tTime 0.719 (0.789)\tData 0.025 (0.035)\tLoss 213.2403 (221.1817)\t\n",
      "Epoch: [8][1800/10208]\tTime 0.741 (0.789)\tData 0.025 (0.035)\tLoss 211.6469 (220.7740)\t\n",
      "Epoch: [8][1900/10208]\tTime 0.726 (0.790)\tData 0.026 (0.034)\tLoss 212.4401 (220.3683)\t\n",
      "Epoch: [8][2000/10208]\tTime 0.724 (0.789)\tData 0.026 (0.034)\tLoss 210.8373 (220.0111)\t\n",
      "Epoch: [8][2100/10208]\tTime 0.775 (0.789)\tData 0.026 (0.033)\tLoss 207.4935 (219.6337)\t\n",
      "Epoch: [8][2200/10208]\tTime 0.722 (0.788)\tData 0.026 (0.033)\tLoss 226.6856 (219.2375)\t\n",
      "Epoch: [8][2300/10208]\tTime 1.026 (0.788)\tData 0.026 (0.033)\tLoss 216.6130 (218.8646)\t\n",
      "Epoch: [8][2400/10208]\tTime 0.732 (0.787)\tData 0.026 (0.032)\tLoss 206.9584 (218.4892)\t\n",
      "Epoch: [8][2500/10208]\tTime 0.719 (0.787)\tData 0.026 (0.032)\tLoss 208.6935 (218.1409)\t\n",
      "Epoch: [8][2600/10208]\tTime 0.728 (0.787)\tData 0.026 (0.032)\tLoss 215.2119 (217.8056)\t\n",
      "Epoch: [8][2700/10208]\tTime 0.722 (0.787)\tData 0.026 (0.032)\tLoss 215.3140 (217.4571)\t\n",
      "Epoch: [8][2800/10208]\tTime 0.958 (0.786)\tData 0.026 (0.032)\tLoss 205.1694 (217.1159)\t\n",
      "Epoch: [8][2900/10208]\tTime 0.726 (0.786)\tData 0.026 (0.031)\tLoss 204.4731 (216.8068)\t\n",
      "Epoch: [8][3000/10208]\tTime 0.743 (0.786)\tData 0.026 (0.031)\tLoss 203.3296 (216.4730)\t\n",
      "Epoch: [8][3100/10208]\tTime 0.741 (0.786)\tData 0.026 (0.031)\tLoss 208.0750 (216.1520)\t\n",
      "Epoch: [8][3200/10208]\tTime 0.725 (0.786)\tData 0.026 (0.031)\tLoss 203.6534 (215.8418)\t\n",
      "Epoch: [8][3300/10208]\tTime 1.075 (0.785)\tData 0.025 (0.031)\tLoss 204.4516 (215.5240)\t\n",
      "Epoch: [8][3400/10208]\tTime 0.742 (0.785)\tData 0.026 (0.031)\tLoss 202.6559 (215.2260)\t\n",
      "Epoch: [8][3500/10208]\tTime 0.721 (0.785)\tData 0.026 (0.030)\tLoss 205.6062 (214.9209)\t\n",
      "Epoch: [8][3600/10208]\tTime 0.735 (0.785)\tData 0.026 (0.030)\tLoss 203.6159 (214.6293)\t\n",
      "Epoch: [8][3700/10208]\tTime 0.740 (0.785)\tData 0.026 (0.030)\tLoss 204.2769 (214.3432)\t\n",
      "Epoch: [8][3800/10208]\tTime 0.998 (0.785)\tData 0.026 (0.030)\tLoss 203.6842 (214.0739)\t\n",
      "Epoch: [8][3900/10208]\tTime 0.739 (0.786)\tData 0.025 (0.030)\tLoss 200.8877 (213.7986)\t\n",
      "Epoch: [8][4000/10208]\tTime 0.719 (0.786)\tData 0.026 (0.030)\tLoss 202.2376 (213.5388)\t\n",
      "Epoch: [8][4100/10208]\tTime 0.721 (0.786)\tData 0.026 (0.030)\tLoss 202.1030 (213.2834)\t\n",
      "Epoch: [8][4200/10208]\tTime 0.741 (0.785)\tData 0.026 (0.030)\tLoss 199.0893 (213.0399)\t\n",
      "Epoch: [8][4300/10208]\tTime 0.948 (0.785)\tData 0.026 (0.030)\tLoss 202.6512 (212.7943)\t\n",
      "Epoch: [8][4400/10208]\tTime 0.745 (0.785)\tData 0.025 (0.030)\tLoss 204.2480 (212.5468)\t\n",
      "Epoch: [8][4500/10208]\tTime 0.724 (0.785)\tData 0.026 (0.030)\tLoss 199.0702 (212.3100)\t\n",
      "Epoch: [8][4600/10208]\tTime 0.726 (0.785)\tData 0.025 (0.029)\tLoss 198.6762 (212.0734)\t\n",
      "Epoch: [8][4700/10208]\tTime 0.738 (0.785)\tData 0.026 (0.029)\tLoss 201.5613 (211.8396)\t\n",
      "Epoch: [8][4800/10208]\tTime 0.728 (0.785)\tData 0.026 (0.029)\tLoss 199.9654 (211.6088)\t\n",
      "Epoch: [8][4900/10208]\tTime 0.768 (0.785)\tData 0.026 (0.029)\tLoss 202.9591 (211.3728)\t\n",
      "Epoch: [8][5000/10208]\tTime 0.723 (0.785)\tData 0.026 (0.029)\tLoss 199.9518 (211.1494)\t\n",
      "Epoch: [8][5100/10208]\tTime 0.718 (0.785)\tData 0.025 (0.029)\tLoss 195.8548 (210.9264)\t\n",
      "Epoch: [8][5200/10208]\tTime 0.729 (0.785)\tData 0.027 (0.029)\tLoss 199.8792 (210.7144)\t\n",
      "Epoch: [8][5300/10208]\tTime 0.735 (0.785)\tData 0.026 (0.029)\tLoss 201.1843 (210.5080)\t\n",
      "Epoch: [8][5400/10208]\tTime 0.743 (0.785)\tData 0.026 (0.029)\tLoss 197.9231 (210.2965)\t\n",
      "Epoch: [8][5500/10208]\tTime 0.743 (0.784)\tData 0.026 (0.029)\tLoss 200.9580 (210.0926)\t\n",
      "Epoch: [8][5600/10208]\tTime 1.112 (0.785)\tData 0.025 (0.029)\tLoss 197.1993 (209.8899)\t\n",
      "Epoch: [8][5700/10208]\tTime 0.757 (0.784)\tData 0.026 (0.029)\tLoss 200.4429 (209.6931)\t\n",
      "Epoch: [8][5800/10208]\tTime 0.739 (0.784)\tData 0.026 (0.029)\tLoss 196.4659 (209.5111)\t\n",
      "Epoch: [8][5900/10208]\tTime 0.729 (0.784)\tData 0.026 (0.029)\tLoss 196.7360 (209.3135)\t\n",
      "Epoch: [8][6000/10208]\tTime 0.737 (0.784)\tData 0.026 (0.029)\tLoss 194.4576 (209.1197)\t\n",
      "Epoch: [8][6100/10208]\tTime 1.185 (0.784)\tData 0.025 (0.029)\tLoss 198.8813 (208.9306)\t\n",
      "Epoch: [8][6200/10208]\tTime 0.738 (0.784)\tData 0.027 (0.029)\tLoss 197.5040 (208.7522)\t\n",
      "Epoch: [8][6300/10208]\tTime 0.725 (0.784)\tData 0.026 (0.029)\tLoss 199.9526 (208.5710)\t\n",
      "Epoch: [8][6400/10208]\tTime 0.791 (0.784)\tData 0.026 (0.029)\tLoss 198.5169 (208.3981)\t\n",
      "Epoch: [8][6500/10208]\tTime 0.722 (0.784)\tData 0.025 (0.029)\tLoss 197.3369 (208.2301)\t\n",
      "Epoch: [8][6600/10208]\tTime 1.075 (0.784)\tData 0.026 (0.029)\tLoss 200.0426 (208.0551)\t\n",
      "Epoch: [8][6700/10208]\tTime 0.722 (0.784)\tData 0.025 (0.028)\tLoss 193.7620 (207.8877)\t\n",
      "Epoch: [8][6800/10208]\tTime 0.721 (0.784)\tData 0.026 (0.028)\tLoss 198.2970 (207.7243)\t\n",
      "Epoch: [8][6900/10208]\tTime 0.723 (0.784)\tData 0.026 (0.028)\tLoss 196.0794 (207.5642)\t\n",
      "Epoch: [8][7000/10208]\tTime 0.720 (0.784)\tData 0.026 (0.028)\tLoss 196.3806 (207.4045)\t\n",
      "Epoch: [8][7100/10208]\tTime 0.997 (0.784)\tData 0.026 (0.028)\tLoss 196.0526 (207.2433)\t\n",
      "Epoch: [8][7200/10208]\tTime 0.720 (0.784)\tData 0.025 (0.028)\tLoss 196.6785 (207.0830)\t\n",
      "Epoch: [8][7300/10208]\tTime 0.742 (0.784)\tData 0.026 (0.028)\tLoss 199.0551 (206.9274)\t\n",
      "Epoch: [8][7400/10208]\tTime 0.794 (0.784)\tData 0.025 (0.028)\tLoss 194.5904 (206.7733)\t\n",
      "Epoch: [8][7500/10208]\tTime 0.750 (0.784)\tData 0.025 (0.028)\tLoss 196.7428 (206.6183)\t\n",
      "Epoch: [8][7600/10208]\tTime 1.006 (0.784)\tData 0.025 (0.028)\tLoss 196.4235 (206.4667)\t\n",
      "Epoch: [8][7700/10208]\tTime 0.717 (0.784)\tData 0.025 (0.028)\tLoss 194.4672 (206.3144)\t\n",
      "Epoch: [8][7800/10208]\tTime 0.723 (0.784)\tData 0.025 (0.028)\tLoss 195.2974 (206.1684)\t\n",
      "Epoch: [8][7900/10208]\tTime 0.726 (0.784)\tData 0.026 (0.028)\tLoss 196.0379 (206.0219)\t\n",
      "Epoch: [8][8000/10208]\tTime 0.725 (0.784)\tData 0.026 (0.028)\tLoss 193.4372 (205.8809)\t\n",
      "Epoch: [8][8100/10208]\tTime 0.723 (0.783)\tData 0.026 (0.028)\tLoss 194.7960 (205.7425)\t\n",
      "Epoch: [8][8200/10208]\tTime 0.731 (0.783)\tData 0.025 (0.028)\tLoss 195.0406 (205.5983)\t\n",
      "Epoch: [8][8300/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 192.9784 (205.4587)\t\n",
      "Epoch: [8][8400/10208]\tTime 0.719 (0.783)\tData 0.025 (0.028)\tLoss 192.4614 (205.3225)\t\n",
      "Epoch: [8][8500/10208]\tTime 0.735 (0.783)\tData 0.030 (0.028)\tLoss 193.3683 (205.1923)\t\n",
      "Epoch: [8][8600/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 195.6608 (205.0626)\t\n",
      "Epoch: [8][8700/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 193.5585 (204.9336)\t\n",
      "Epoch: [8][8800/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 195.0495 (204.8023)\t\n",
      "Epoch: [8][8900/10208]\tTime 0.947 (0.783)\tData 0.026 (0.028)\tLoss 193.0100 (204.6713)\t\n",
      "Epoch: [8][9000/10208]\tTime 0.723 (0.783)\tData 0.026 (0.028)\tLoss 190.6499 (204.5414)\t\n",
      "Epoch: [8][9100/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 190.7654 (204.4097)\t\n",
      "Epoch: [8][9200/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 194.2304 (204.2829)\t\n",
      "Epoch: [8][9300/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 192.4631 (204.1625)\t\n",
      "Epoch: [8][9400/10208]\tTime 1.091 (0.783)\tData 0.026 (0.028)\tLoss 192.3820 (204.0396)\t\n",
      "Epoch: [8][9500/10208]\tTime 0.723 (0.783)\tData 0.025 (0.028)\tLoss 191.7169 (203.9180)\t\n",
      "Epoch: [8][9600/10208]\tTime 0.725 (0.783)\tData 0.025 (0.028)\tLoss 193.7698 (203.7985)\t\n",
      "Epoch: [8][9700/10208]\tTime 0.752 (0.782)\tData 0.025 (0.028)\tLoss 190.5399 (203.6787)\t\n",
      "Epoch: [8][9800/10208]\tTime 0.734 (0.782)\tData 0.028 (0.028)\tLoss 190.5349 (203.5628)\t\n",
      "Epoch: [8][9900/10208]\tTime 0.976 (0.782)\tData 0.026 (0.028)\tLoss 192.0345 (203.4484)\t\n",
      "Epoch: [8][10000/10208]\tTime 0.724 (0.782)\tData 0.025 (0.028)\tLoss 192.9536 (203.3327)\t\n",
      "Epoch: [8][10100/10208]\tTime 0.722 (0.782)\tData 0.025 (0.028)\tLoss 193.9974 (203.2246)\t\n",
      "Epoch: [8][10200/10208]\tTime 0.728 (0.782)\tData 0.025 (0.028)\tLoss 192.5016 (203.1189)\t\n",
      "Epoch: [8][10207/10208]\tTime 0.719 (0.782)\tData 0.025 (0.028)\tLoss 193.5979 (203.1113)\t\n",
      "Start training\n",
      "Epoch: [9][0/10208]\tTime 14.806 (14.806)\tData 14.031 (14.031)\tLoss 191.3703 (191.3703)\t\n",
      "Epoch: [9][100/10208]\tTime 0.752 (0.914)\tData 0.026 (0.165)\tLoss 197.3606 (191.3204)\t\n",
      "Epoch: [9][200/10208]\tTime 0.724 (0.846)\tData 0.026 (0.096)\tLoss 189.6293 (191.4722)\t\n",
      "Epoch: [9][300/10208]\tTime 0.722 (0.821)\tData 0.025 (0.073)\tLoss 195.5923 (192.0064)\t\n",
      "Epoch: [9][400/10208]\tTime 0.724 (0.812)\tData 0.026 (0.061)\tLoss 192.1631 (192.4756)\t\n",
      "Epoch: [9][500/10208]\tTime 0.728 (0.805)\tData 0.025 (0.054)\tLoss 191.9819 (192.7251)\t\n",
      "Epoch: [9][600/10208]\tTime 0.747 (0.801)\tData 0.026 (0.049)\tLoss 192.3547 (192.8084)\t\n",
      "Epoch: [9][700/10208]\tTime 0.726 (0.797)\tData 0.026 (0.046)\tLoss 191.5167 (192.7563)\t\n",
      "Epoch: [9][800/10208]\tTime 0.716 (0.796)\tData 0.025 (0.044)\tLoss 192.0018 (192.7055)\t\n",
      "Epoch: [9][900/10208]\tTime 0.721 (0.793)\tData 0.026 (0.042)\tLoss 193.6330 (192.6947)\t\n",
      "Epoch: [9][1000/10208]\tTime 0.719 (0.792)\tData 0.025 (0.040)\tLoss 193.2007 (192.7520)\t\n",
      "Epoch: [9][1100/10208]\tTime 0.735 (0.790)\tData 0.025 (0.039)\tLoss 191.2812 (192.7475)\t\n",
      "Epoch: [9][1200/10208]\tTime 1.104 (0.790)\tData 0.025 (0.038)\tLoss 190.9961 (192.7149)\t\n",
      "Epoch: [9][1300/10208]\tTime 0.729 (0.789)\tData 0.025 (0.037)\tLoss 195.4513 (192.6988)\t\n",
      "Epoch: [9][1400/10208]\tTime 0.724 (0.788)\tData 0.026 (0.036)\tLoss 192.2104 (192.7220)\t\n",
      "Epoch: [9][1500/10208]\tTime 0.728 (0.787)\tData 0.025 (0.036)\tLoss 190.2453 (192.6897)\t\n",
      "Epoch: [9][1600/10208]\tTime 0.736 (0.787)\tData 0.026 (0.035)\tLoss 193.7014 (192.6801)\t\n",
      "Epoch: [9][1700/10208]\tTime 1.103 (0.786)\tData 0.025 (0.034)\tLoss 192.1089 (192.6517)\t\n",
      "Epoch: [9][1800/10208]\tTime 0.747 (0.786)\tData 0.026 (0.034)\tLoss 191.6646 (192.6103)\t\n",
      "Epoch: [9][1900/10208]\tTime 0.717 (0.785)\tData 0.025 (0.034)\tLoss 192.7479 (192.5670)\t\n",
      "Epoch: [9][2000/10208]\tTime 0.729 (0.785)\tData 0.025 (0.033)\tLoss 190.3953 (192.5027)\t\n",
      "Epoch: [9][2100/10208]\tTime 0.741 (0.785)\tData 0.026 (0.033)\tLoss 188.4005 (192.4505)\t\n",
      "Epoch: [9][2200/10208]\tTime 0.965 (0.785)\tData 0.025 (0.033)\tLoss 190.8894 (192.4095)\t\n",
      "Epoch: [9][2300/10208]\tTime 0.728 (0.784)\tData 0.025 (0.032)\tLoss 190.2460 (192.3379)\t\n",
      "Epoch: [9][2400/10208]\tTime 0.726 (0.784)\tData 0.026 (0.032)\tLoss 190.4787 (192.2769)\t\n",
      "Epoch: [9][2500/10208]\tTime 0.751 (0.784)\tData 0.026 (0.032)\tLoss 189.9164 (192.2108)\t\n",
      "Epoch: [9][2600/10208]\tTime 0.724 (0.784)\tData 0.025 (0.032)\tLoss 190.7844 (192.1410)\t\n",
      "Epoch: [9][2700/10208]\tTime 1.165 (0.784)\tData 0.026 (0.031)\tLoss 188.3305 (192.0728)\t\n",
      "Epoch: [9][2800/10208]\tTime 0.718 (0.783)\tData 0.026 (0.031)\tLoss 189.0480 (192.0081)\t\n",
      "Epoch: [9][2900/10208]\tTime 0.719 (0.783)\tData 0.026 (0.031)\tLoss 190.1492 (191.9414)\t\n",
      "Epoch: [9][3000/10208]\tTime 0.718 (0.783)\tData 0.026 (0.031)\tLoss 191.0855 (191.8937)\t\n",
      "Epoch: [9][3100/10208]\tTime 0.716 (0.783)\tData 0.025 (0.031)\tLoss 191.8468 (191.8282)\t\n",
      "Epoch: [9][3200/10208]\tTime 0.803 (0.783)\tData 0.026 (0.031)\tLoss 189.2101 (191.7652)\t\n",
      "Epoch: [9][3300/10208]\tTime 0.747 (0.783)\tData 0.025 (0.030)\tLoss 188.6721 (191.6947)\t\n",
      "Epoch: [9][3400/10208]\tTime 0.725 (0.782)\tData 0.025 (0.030)\tLoss 189.7319 (191.6282)\t\n",
      "Epoch: [9][3500/10208]\tTime 0.720 (0.782)\tData 0.025 (0.030)\tLoss 190.8549 (191.5757)\t\n",
      "Epoch: [9][3600/10208]\tTime 0.731 (0.782)\tData 0.026 (0.030)\tLoss 192.0099 (191.5080)\t\n",
      "Epoch: [9][3700/10208]\tTime 0.723 (0.782)\tData 0.025 (0.030)\tLoss 188.7705 (191.4393)\t\n",
      "Epoch: [9][3800/10208]\tTime 0.751 (0.781)\tData 0.026 (0.030)\tLoss 187.8372 (191.3817)\t\n",
      "Epoch: [9][3900/10208]\tTime 0.726 (0.781)\tData 0.026 (0.030)\tLoss 189.9795 (191.3220)\t\n",
      "Epoch: [9][4000/10208]\tTime 0.780 (0.781)\tData 0.047 (0.030)\tLoss 190.1209 (191.2614)\t\n",
      "Epoch: [9][4100/10208]\tTime 0.719 (0.781)\tData 0.025 (0.030)\tLoss 190.5730 (191.1972)\t\n",
      "Epoch: [9][4200/10208]\tTime 0.755 (0.781)\tData 0.026 (0.030)\tLoss 193.1637 (191.1391)\t\n",
      "Epoch: [9][4300/10208]\tTime 0.723 (0.781)\tData 0.025 (0.029)\tLoss 190.0203 (191.0863)\t\n",
      "Epoch: [9][4400/10208]\tTime 0.729 (0.781)\tData 0.026 (0.029)\tLoss 187.2817 (191.0246)\t\n",
      "Epoch: [9][4500/10208]\tTime 1.418 (0.781)\tData 0.027 (0.029)\tLoss 190.9694 (190.9629)\t\n",
      "Epoch: [9][4600/10208]\tTime 0.736 (0.781)\tData 0.026 (0.029)\tLoss 188.7581 (190.9031)\t\n",
      "Epoch: [9][4700/10208]\tTime 0.728 (0.781)\tData 0.026 (0.029)\tLoss 187.0585 (190.8490)\t\n",
      "Epoch: [9][4800/10208]\tTime 0.719 (0.781)\tData 0.025 (0.029)\tLoss 189.8124 (190.8048)\t\n",
      "Epoch: [9][4900/10208]\tTime 0.721 (0.780)\tData 0.025 (0.029)\tLoss 188.1334 (190.7546)\t\n",
      "Epoch: [9][5000/10208]\tTime 1.167 (0.780)\tData 0.026 (0.029)\tLoss 188.3632 (190.7120)\t\n",
      "Epoch: [9][5100/10208]\tTime 0.744 (0.780)\tData 0.026 (0.029)\tLoss 187.9663 (190.6637)\t\n",
      "Epoch: [9][5200/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 186.6773 (190.6248)\t\n",
      "Epoch: [9][5300/10208]\tTime 0.717 (0.780)\tData 0.025 (0.029)\tLoss 187.5900 (190.5728)\t\n",
      "Epoch: [9][5400/10208]\tTime 0.722 (0.780)\tData 0.025 (0.029)\tLoss 190.7677 (190.5214)\t\n",
      "Epoch: [9][5500/10208]\tTime 0.992 (0.780)\tData 0.025 (0.029)\tLoss 187.7137 (190.4771)\t\n",
      "Epoch: [9][5600/10208]\tTime 0.727 (0.779)\tData 0.025 (0.029)\tLoss 187.7787 (190.4302)\t\n",
      "Epoch: [9][5700/10208]\tTime 0.722 (0.779)\tData 0.025 (0.029)\tLoss 188.3557 (190.3819)\t\n",
      "Epoch: [9][5800/10208]\tTime 0.801 (0.779)\tData 0.057 (0.029)\tLoss 188.3476 (190.3347)\t\n",
      "Epoch: [9][5900/10208]\tTime 0.725 (0.779)\tData 0.025 (0.029)\tLoss 188.6592 (190.2871)\t\n",
      "Epoch: [9][6000/10208]\tTime 1.095 (0.779)\tData 0.032 (0.029)\tLoss 187.7624 (190.2402)\t\n",
      "Epoch: [9][6100/10208]\tTime 0.718 (0.779)\tData 0.025 (0.029)\tLoss 188.3970 (190.1914)\t\n",
      "Epoch: [9][6200/10208]\tTime 0.721 (0.779)\tData 0.025 (0.028)\tLoss 185.7036 (190.1466)\t\n",
      "Epoch: [9][6300/10208]\tTime 0.754 (0.779)\tData 0.057 (0.028)\tLoss 187.1297 (190.1000)\t\n",
      "Epoch: [9][6400/10208]\tTime 0.731 (0.779)\tData 0.026 (0.028)\tLoss 189.3005 (190.0574)\t\n",
      "Epoch: [9][6500/10208]\tTime 0.894 (0.778)\tData 0.025 (0.028)\tLoss 187.0931 (190.0087)\t\n",
      "Epoch: [9][6600/10208]\tTime 0.742 (0.778)\tData 0.044 (0.028)\tLoss 187.1138 (189.9613)\t\n",
      "Epoch: [9][6700/10208]\tTime 0.722 (0.778)\tData 0.026 (0.028)\tLoss 187.8537 (189.9127)\t\n",
      "Epoch: [9][6800/10208]\tTime 0.724 (0.778)\tData 0.026 (0.028)\tLoss 185.6829 (189.8663)\t\n",
      "Epoch: [9][6900/10208]\tTime 0.723 (0.778)\tData 0.025 (0.028)\tLoss 186.6569 (189.8200)\t\n",
      "Epoch: [9][7000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 185.2814 (189.7750)\t\n",
      "Epoch: [9][7100/10208]\tTime 0.726 (0.778)\tData 0.025 (0.028)\tLoss 183.1530 (189.7302)\t\n",
      "Epoch: [9][7200/10208]\tTime 0.723 (0.778)\tData 0.025 (0.028)\tLoss 188.5643 (189.6838)\t\n",
      "Epoch: [9][7300/10208]\tTime 0.727 (0.778)\tData 0.027 (0.028)\tLoss 186.7599 (189.6357)\t\n",
      "Epoch: [9][7400/10208]\tTime 0.741 (0.778)\tData 0.025 (0.028)\tLoss 187.2076 (189.5865)\t\n",
      "Epoch: [9][7500/10208]\tTime 0.725 (0.778)\tData 0.026 (0.028)\tLoss 185.8221 (189.5370)\t\n",
      "Epoch: [9][7600/10208]\tTime 0.726 (0.778)\tData 0.026 (0.028)\tLoss 186.4512 (189.4895)\t\n",
      "Epoch: [9][7700/10208]\tTime 0.717 (0.778)\tData 0.026 (0.028)\tLoss 185.1730 (189.4391)\t\n",
      "Epoch: [9][7800/10208]\tTime 1.095 (0.778)\tData 0.026 (0.028)\tLoss 186.5482 (189.3890)\t\n",
      "Epoch: [9][7900/10208]\tTime 0.727 (0.778)\tData 0.026 (0.028)\tLoss 184.2109 (189.3411)\t\n",
      "Epoch: [9][8000/10208]\tTime 0.721 (0.778)\tData 0.026 (0.028)\tLoss 183.5361 (189.2937)\t\n",
      "Epoch: [9][8100/10208]\tTime 0.741 (0.778)\tData 0.025 (0.028)\tLoss 184.2634 (189.2430)\t\n",
      "Epoch: [9][8200/10208]\tTime 0.725 (0.778)\tData 0.025 (0.028)\tLoss 183.2551 (189.1973)\t\n",
      "Epoch: [9][8300/10208]\tTime 1.058 (0.778)\tData 0.025 (0.028)\tLoss 185.1745 (189.1476)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][8400/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 186.1743 (189.0974)\t\n",
      "Epoch: [9][8500/10208]\tTime 0.737 (0.778)\tData 0.025 (0.028)\tLoss 185.1117 (189.0482)\t\n",
      "Epoch: [9][8600/10208]\tTime 0.739 (0.778)\tData 0.025 (0.028)\tLoss 183.8793 (189.0015)\t\n",
      "Epoch: [9][8700/10208]\tTime 0.757 (0.778)\tData 0.026 (0.028)\tLoss 186.3570 (188.9567)\t\n",
      "Epoch: [9][8800/10208]\tTime 1.146 (0.778)\tData 0.026 (0.028)\tLoss 184.0963 (188.9085)\t\n",
      "Epoch: [9][8900/10208]\tTime 0.730 (0.778)\tData 0.025 (0.028)\tLoss 187.3147 (188.8627)\t\n",
      "Epoch: [9][9000/10208]\tTime 0.758 (0.778)\tData 0.026 (0.028)\tLoss 184.9234 (188.8192)\t\n",
      "Epoch: [9][9100/10208]\tTime 0.776 (0.778)\tData 0.050 (0.028)\tLoss 185.4924 (188.7735)\t\n",
      "Epoch: [9][9200/10208]\tTime 0.747 (0.778)\tData 0.025 (0.028)\tLoss 184.0836 (188.7268)\t\n",
      "Epoch: [9][9300/10208]\tTime 1.078 (0.778)\tData 0.025 (0.028)\tLoss 183.1010 (188.6787)\t\n",
      "Epoch: [9][9400/10208]\tTime 0.727 (0.778)\tData 0.026 (0.028)\tLoss 182.8998 (188.6328)\t\n",
      "Epoch: [9][9500/10208]\tTime 0.722 (0.778)\tData 0.025 (0.028)\tLoss 185.6563 (188.5859)\t\n",
      "Epoch: [9][9600/10208]\tTime 0.762 (0.778)\tData 0.025 (0.028)\tLoss 184.2025 (188.5407)\t\n",
      "Epoch: [9][9700/10208]\tTime 0.729 (0.778)\tData 0.025 (0.028)\tLoss 183.3493 (188.4933)\t\n",
      "Epoch: [9][9800/10208]\tTime 0.889 (0.778)\tData 0.026 (0.028)\tLoss 184.4734 (188.4455)\t\n",
      "Epoch: [9][9900/10208]\tTime 0.719 (0.778)\tData 0.026 (0.028)\tLoss 183.9424 (188.3998)\t\n",
      "Epoch: [9][10000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 185.2249 (188.3562)\t\n",
      "Epoch: [9][10100/10208]\tTime 0.740 (0.778)\tData 0.025 (0.028)\tLoss 184.9535 (188.3111)\t\n",
      "Epoch: [9][10200/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 183.5963 (188.2687)\t\n",
      "Epoch: [9][10207/10208]\tTime 0.722 (0.778)\tData 0.025 (0.028)\tLoss 181.9144 (188.2650)\t\n",
      "Start training\n",
      "Epoch: [10][0/10208]\tTime 13.177 (13.177)\tData 12.249 (12.249)\tLoss 181.1674 (181.1674)\t\n",
      "Epoch: [10][100/10208]\tTime 0.730 (0.921)\tData 0.025 (0.165)\tLoss 184.0956 (183.6157)\t\n",
      "Epoch: [10][200/10208]\tTime 0.725 (0.851)\tData 0.026 (0.096)\tLoss 183.6035 (183.5457)\t\n",
      "Epoch: [10][300/10208]\tTime 0.729 (0.826)\tData 0.025 (0.073)\tLoss 181.6922 (183.5554)\t\n",
      "Epoch: [10][400/10208]\tTime 0.725 (0.813)\tData 0.026 (0.061)\tLoss 181.7043 (183.5550)\t\n",
      "Epoch: [10][500/10208]\tTime 0.733 (0.807)\tData 0.026 (0.054)\tLoss 184.1122 (183.5313)\t\n",
      "Epoch: [10][600/10208]\tTime 0.961 (0.803)\tData 0.025 (0.050)\tLoss 183.5566 (183.5123)\t\n",
      "Epoch: [10][700/10208]\tTime 0.715 (0.799)\tData 0.026 (0.046)\tLoss 181.3202 (183.4931)\t\n",
      "Epoch: [10][800/10208]\tTime 0.754 (0.796)\tData 0.026 (0.044)\tLoss 183.0740 (183.4806)\t\n",
      "Epoch: [10][900/10208]\tTime 0.718 (0.795)\tData 0.025 (0.042)\tLoss 182.4442 (183.4615)\t\n",
      "Epoch: [10][1000/10208]\tTime 0.733 (0.794)\tData 0.026 (0.040)\tLoss 183.7027 (183.4211)\t\n",
      "Epoch: [10][1100/10208]\tTime 1.123 (0.792)\tData 0.026 (0.039)\tLoss 184.2478 (183.3769)\t\n",
      "Epoch: [10][1200/10208]\tTime 0.728 (0.791)\tData 0.026 (0.038)\tLoss 183.1911 (183.3269)\t\n",
      "Epoch: [10][1300/10208]\tTime 0.736 (0.789)\tData 0.026 (0.037)\tLoss 183.6220 (183.3069)\t\n",
      "Epoch: [10][1400/10208]\tTime 0.763 (0.790)\tData 0.026 (0.036)\tLoss 184.1052 (183.2612)\t\n",
      "Epoch: [10][1500/10208]\tTime 0.726 (0.789)\tData 0.026 (0.036)\tLoss 182.5737 (183.2397)\t\n",
      "Epoch: [10][1600/10208]\tTime 1.110 (0.788)\tData 0.026 (0.035)\tLoss 180.1198 (183.1972)\t\n",
      "Epoch: [10][1700/10208]\tTime 0.739 (0.788)\tData 0.025 (0.035)\tLoss 182.7039 (183.1662)\t\n",
      "Epoch: [10][1800/10208]\tTime 0.726 (0.787)\tData 0.026 (0.034)\tLoss 180.9950 (183.1268)\t\n",
      "Epoch: [10][1900/10208]\tTime 0.730 (0.787)\tData 0.026 (0.034)\tLoss 182.8964 (183.1073)\t\n",
      "Epoch: [10][2000/10208]\tTime 0.735 (0.787)\tData 0.026 (0.033)\tLoss 182.1076 (183.0721)\t\n",
      "Epoch: [10][2100/10208]\tTime 1.128 (0.787)\tData 0.025 (0.033)\tLoss 183.5224 (183.0378)\t\n",
      "Epoch: [10][2200/10208]\tTime 0.719 (0.787)\tData 0.025 (0.033)\tLoss 182.4821 (183.0090)\t\n",
      "Epoch: [10][2300/10208]\tTime 0.726 (0.787)\tData 0.025 (0.032)\tLoss 183.0321 (182.9844)\t\n",
      "Epoch: [10][2400/10208]\tTime 0.730 (0.786)\tData 0.025 (0.032)\tLoss 182.7594 (182.9550)\t\n",
      "Epoch: [10][2500/10208]\tTime 0.726 (0.786)\tData 0.026 (0.032)\tLoss 181.7401 (182.9271)\t\n",
      "Epoch: [10][2600/10208]\tTime 0.841 (0.786)\tData 0.026 (0.032)\tLoss 181.4953 (182.8972)\t\n",
      "Epoch: [10][2700/10208]\tTime 0.736 (0.785)\tData 0.026 (0.032)\tLoss 179.8018 (182.8680)\t\n",
      "Epoch: [10][2800/10208]\tTime 0.729 (0.785)\tData 0.026 (0.031)\tLoss 182.9146 (182.8355)\t\n",
      "Epoch: [10][2900/10208]\tTime 0.726 (0.784)\tData 0.026 (0.031)\tLoss 182.7044 (182.8020)\t\n",
      "Epoch: [10][3000/10208]\tTime 0.726 (0.784)\tData 0.025 (0.031)\tLoss 182.2262 (182.7653)\t\n",
      "Epoch: [10][3100/10208]\tTime 0.801 (0.784)\tData 0.026 (0.031)\tLoss 182.9261 (182.7286)\t\n",
      "Epoch: [10][3200/10208]\tTime 0.726 (0.783)\tData 0.026 (0.031)\tLoss 182.7259 (182.6912)\t\n",
      "Epoch: [10][3300/10208]\tTime 0.727 (0.783)\tData 0.026 (0.031)\tLoss 181.5580 (182.6573)\t\n",
      "Epoch: [10][3400/10208]\tTime 0.716 (0.783)\tData 0.025 (0.030)\tLoss 181.0339 (182.6220)\t\n",
      "Epoch: [10][3500/10208]\tTime 0.717 (0.782)\tData 0.026 (0.030)\tLoss 182.0908 (182.5803)\t\n",
      "Epoch: [10][3600/10208]\tTime 0.731 (0.782)\tData 0.026 (0.030)\tLoss 182.6575 (182.5480)\t\n",
      "Epoch: [10][3700/10208]\tTime 0.725 (0.782)\tData 0.026 (0.030)\tLoss 180.6142 (182.5072)\t\n",
      "Epoch: [10][3800/10208]\tTime 0.748 (0.781)\tData 0.026 (0.030)\tLoss 181.5370 (182.4714)\t\n",
      "Epoch: [10][3900/10208]\tTime 1.186 (0.781)\tData 0.026 (0.030)\tLoss 179.2042 (182.4356)\t\n",
      "Epoch: [10][4000/10208]\tTime 0.739 (0.781)\tData 0.026 (0.030)\tLoss 180.6732 (182.3988)\t\n",
      "Epoch: [10][4100/10208]\tTime 0.737 (0.781)\tData 0.026 (0.030)\tLoss 179.7942 (182.3627)\t\n",
      "Epoch: [10][4200/10208]\tTime 0.746 (0.781)\tData 0.026 (0.030)\tLoss 180.5851 (182.3233)\t\n",
      "Epoch: [10][4300/10208]\tTime 0.728 (0.781)\tData 0.026 (0.030)\tLoss 180.2126 (182.2864)\t\n",
      "Epoch: [10][4400/10208]\tTime 1.053 (0.781)\tData 0.026 (0.029)\tLoss 182.6833 (182.2514)\t\n",
      "Epoch: [10][4500/10208]\tTime 0.720 (0.780)\tData 0.025 (0.029)\tLoss 180.7846 (182.2193)\t\n",
      "Epoch: [10][4600/10208]\tTime 0.724 (0.780)\tData 0.026 (0.029)\tLoss 179.9304 (182.1824)\t\n",
      "Epoch: [10][4700/10208]\tTime 0.725 (0.780)\tData 0.026 (0.029)\tLoss 180.0168 (182.1450)\t\n",
      "Epoch: [10][4800/10208]\tTime 0.722 (0.780)\tData 0.026 (0.029)\tLoss 181.8445 (182.1073)\t\n",
      "Epoch: [10][4900/10208]\tTime 1.123 (0.780)\tData 0.026 (0.029)\tLoss 178.5078 (182.0734)\t\n",
      "Epoch: [10][5000/10208]\tTime 0.731 (0.780)\tData 0.026 (0.029)\tLoss 180.4199 (182.0392)\t\n",
      "Epoch: [10][5100/10208]\tTime 0.744 (0.780)\tData 0.026 (0.029)\tLoss 178.9027 (182.0042)\t\n",
      "Epoch: [10][5200/10208]\tTime 0.722 (0.780)\tData 0.026 (0.029)\tLoss 180.0319 (181.9679)\t\n",
      "Epoch: [10][5300/10208]\tTime 0.732 (0.780)\tData 0.026 (0.029)\tLoss 177.4579 (181.9346)\t\n",
      "Epoch: [10][5400/10208]\tTime 1.080 (0.780)\tData 0.026 (0.029)\tLoss 179.1831 (181.8997)\t\n",
      "Epoch: [10][5500/10208]\tTime 0.748 (0.780)\tData 0.026 (0.029)\tLoss 180.7704 (181.8640)\t\n",
      "Epoch: [10][5600/10208]\tTime 0.724 (0.779)\tData 0.026 (0.029)\tLoss 179.0858 (181.8294)\t\n",
      "Epoch: [10][5700/10208]\tTime 0.745 (0.779)\tData 0.026 (0.029)\tLoss 179.0836 (181.7949)\t\n",
      "Epoch: [10][5800/10208]\tTime 0.734 (0.779)\tData 0.026 (0.029)\tLoss 182.2687 (181.7612)\t\n",
      "Epoch: [10][5900/10208]\tTime 0.787 (0.779)\tData 0.026 (0.029)\tLoss 179.0274 (181.7285)\t\n",
      "Epoch: [10][6000/10208]\tTime 0.747 (0.779)\tData 0.026 (0.029)\tLoss 180.3345 (181.6946)\t\n",
      "Epoch: [10][6100/10208]\tTime 0.720 (0.779)\tData 0.026 (0.029)\tLoss 180.8109 (181.6642)\t\n",
      "Epoch: [10][6200/10208]\tTime 0.734 (0.779)\tData 0.026 (0.029)\tLoss 176.6908 (181.6326)\t\n",
      "Epoch: [10][6300/10208]\tTime 0.726 (0.779)\tData 0.026 (0.028)\tLoss 179.2183 (181.6002)\t\n",
      "Epoch: [10][6400/10208]\tTime 0.741 (0.779)\tData 0.026 (0.028)\tLoss 179.4719 (181.5703)\t\n",
      "Epoch: [10][6500/10208]\tTime 0.741 (0.779)\tData 0.033 (0.028)\tLoss 179.7327 (181.5372)\t\n",
      "Epoch: [10][6600/10208]\tTime 0.734 (0.779)\tData 0.025 (0.028)\tLoss 178.7526 (181.5047)\t\n",
      "Epoch: [10][6700/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 179.6098 (181.4786)\t\n",
      "Epoch: [10][6800/10208]\tTime 0.732 (0.779)\tData 0.026 (0.028)\tLoss 179.7640 (181.4520)\t\n",
      "Epoch: [10][6900/10208]\tTime 0.751 (0.779)\tData 0.026 (0.028)\tLoss 178.4709 (181.4255)\t\n",
      "Epoch: [10][7000/10208]\tTime 0.720 (0.779)\tData 0.026 (0.028)\tLoss 179.7753 (181.3951)\t\n",
      "Epoch: [10][7100/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 179.4198 (181.3661)\t\n",
      "Epoch: [10][7200/10208]\tTime 1.054 (0.779)\tData 0.026 (0.028)\tLoss 179.2332 (181.3390)\t\n",
      "Epoch: [10][7300/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 178.4638 (181.3088)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][7400/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 179.0836 (181.2811)\t\n",
      "Epoch: [10][7500/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 181.0837 (181.2523)\t\n",
      "Epoch: [10][7600/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 177.7071 (181.2237)\t\n",
      "Epoch: [10][7700/10208]\tTime 1.115 (0.779)\tData 0.026 (0.028)\tLoss 177.9585 (181.1977)\t\n",
      "Epoch: [10][7800/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 177.7560 (181.1708)\t\n",
      "Epoch: [10][7900/10208]\tTime 0.722 (0.779)\tData 0.027 (0.028)\tLoss 176.2551 (181.1457)\t\n",
      "Epoch: [10][8000/10208]\tTime 0.730 (0.779)\tData 0.025 (0.028)\tLoss 179.4148 (181.1177)\t\n",
      "Epoch: [10][8100/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 181.2314 (181.0873)\t\n",
      "Epoch: [10][8200/10208]\tTime 1.095 (0.779)\tData 0.030 (0.028)\tLoss 178.5480 (181.0590)\t\n",
      "Epoch: [10][8300/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 178.9069 (181.0326)\t\n",
      "Epoch: [10][8400/10208]\tTime 0.740 (0.779)\tData 0.026 (0.028)\tLoss 181.1436 (181.0055)\t\n",
      "Epoch: [10][8500/10208]\tTime 0.736 (0.779)\tData 0.026 (0.028)\tLoss 177.9182 (180.9779)\t\n",
      "Epoch: [10][8600/10208]\tTime 0.734 (0.779)\tData 0.025 (0.028)\tLoss 179.2167 (180.9532)\t\n",
      "Epoch: [10][8700/10208]\tTime 1.001 (0.779)\tData 0.026 (0.028)\tLoss 178.0180 (180.9288)\t\n",
      "Epoch: [10][8800/10208]\tTime 0.783 (0.779)\tData 0.026 (0.028)\tLoss 179.7997 (180.9036)\t\n",
      "Epoch: [10][8900/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 178.4758 (180.8756)\t\n",
      "Epoch: [10][9000/10208]\tTime 0.768 (0.779)\tData 0.026 (0.028)\tLoss 179.1135 (180.8512)\t\n",
      "Epoch: [10][9100/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 176.3337 (180.8295)\t\n",
      "Epoch: [10][9200/10208]\tTime 0.829 (0.779)\tData 0.026 (0.028)\tLoss 179.0314 (180.8047)\t\n",
      "Epoch: [10][9300/10208]\tTime 0.766 (0.779)\tData 0.026 (0.028)\tLoss 176.4290 (180.7806)\t\n",
      "Epoch: [10][9400/10208]\tTime 0.719 (0.779)\tData 0.026 (0.028)\tLoss 180.8043 (180.7563)\t\n",
      "Epoch: [10][9500/10208]\tTime 0.729 (0.779)\tData 0.026 (0.028)\tLoss 179.7935 (180.7331)\t\n",
      "Epoch: [10][9600/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 177.4514 (180.7129)\t\n",
      "Epoch: [10][9700/10208]\tTime 0.714 (0.779)\tData 0.025 (0.028)\tLoss 179.0110 (180.6890)\t\n",
      "Epoch: [10][9800/10208]\tTime 0.745 (0.779)\tData 0.026 (0.028)\tLoss 176.7977 (180.6673)\t\n",
      "Epoch: [10][9900/10208]\tTime 0.735 (0.779)\tData 0.026 (0.028)\tLoss 178.3997 (180.6445)\t\n",
      "Epoch: [10][10000/10208]\tTime 0.737 (0.779)\tData 0.025 (0.028)\tLoss 178.7107 (180.6224)\t\n",
      "Epoch: [10][10100/10208]\tTime 0.726 (0.779)\tData 0.026 (0.028)\tLoss 179.0269 (180.6033)\t\n",
      "Epoch: [10][10200/10208]\tTime 0.731 (0.778)\tData 0.025 (0.028)\tLoss 179.6954 (180.5846)\t\n",
      "Epoch: [10][10207/10208]\tTime 0.725 (0.778)\tData 0.028 (0.028)\tLoss 180.0465 (180.5831)\t\n",
      "Start training\n",
      "Epoch: [11][0/10208]\tTime 14.143 (14.143)\tData 12.906 (12.906)\tLoss 177.3957 (177.3957)\t\n",
      "Epoch: [11][100/10208]\tTime 0.717 (0.972)\tData 0.026 (0.203)\tLoss 177.6429 (178.4888)\t\n",
      "Epoch: [11][200/10208]\tTime 0.720 (0.873)\tData 0.025 (0.115)\tLoss 179.0472 (178.4501)\t\n",
      "Epoch: [11][300/10208]\tTime 0.755 (0.843)\tData 0.026 (0.086)\tLoss 178.3889 (178.3673)\t\n",
      "Epoch: [11][400/10208]\tTime 0.730 (0.825)\tData 0.026 (0.071)\tLoss 177.2247 (178.3527)\t\n",
      "Epoch: [11][500/10208]\tTime 1.085 (0.815)\tData 0.026 (0.062)\tLoss 178.3912 (178.3285)\t\n",
      "Epoch: [11][600/10208]\tTime 0.730 (0.807)\tData 0.026 (0.056)\tLoss 177.2269 (178.3055)\t\n",
      "Epoch: [11][700/10208]\tTime 0.722 (0.803)\tData 0.025 (0.052)\tLoss 177.0680 (178.3010)\t\n",
      "Epoch: [11][800/10208]\tTime 0.772 (0.800)\tData 0.026 (0.048)\tLoss 178.6147 (178.3193)\t\n",
      "Epoch: [11][900/10208]\tTime 0.728 (0.797)\tData 0.026 (0.046)\tLoss 178.4197 (178.2795)\t\n",
      "Epoch: [11][1000/10208]\tTime 1.203 (0.795)\tData 0.025 (0.044)\tLoss 179.5814 (178.2646)\t\n",
      "Epoch: [11][1100/10208]\tTime 0.715 (0.793)\tData 0.025 (0.042)\tLoss 176.3120 (178.2681)\t\n",
      "Epoch: [11][1200/10208]\tTime 0.728 (0.791)\tData 0.025 (0.041)\tLoss 177.0054 (178.2604)\t\n",
      "Epoch: [11][1300/10208]\tTime 0.735 (0.790)\tData 0.026 (0.040)\tLoss 178.4621 (178.2543)\t\n",
      "Epoch: [11][1400/10208]\tTime 0.723 (0.789)\tData 0.026 (0.039)\tLoss 179.3091 (178.2548)\t\n",
      "Epoch: [11][1500/10208]\tTime 0.784 (0.789)\tData 0.025 (0.038)\tLoss 180.5613 (178.2461)\t\n",
      "Epoch: [11][1600/10208]\tTime 0.720 (0.788)\tData 0.026 (0.037)\tLoss 177.1686 (178.2256)\t\n",
      "Epoch: [11][1700/10208]\tTime 0.741 (0.787)\tData 0.026 (0.037)\tLoss 177.9539 (178.2113)\t\n",
      "Epoch: [11][1800/10208]\tTime 0.723 (0.786)\tData 0.026 (0.036)\tLoss 179.4633 (178.2117)\t\n",
      "Epoch: [11][1900/10208]\tTime 0.726 (0.786)\tData 0.025 (0.036)\tLoss 177.8961 (178.2221)\t\n",
      "Epoch: [11][2000/10208]\tTime 0.724 (0.785)\tData 0.026 (0.035)\tLoss 180.7272 (178.2135)\t\n",
      "Epoch: [11][2100/10208]\tTime 0.755 (0.785)\tData 0.026 (0.035)\tLoss 176.2382 (178.2077)\t\n",
      "Epoch: [11][2200/10208]\tTime 0.724 (0.784)\tData 0.025 (0.034)\tLoss 178.1056 (178.1992)\t\n",
      "Epoch: [11][2300/10208]\tTime 0.724 (0.784)\tData 0.026 (0.034)\tLoss 178.4286 (178.2008)\t\n",
      "Epoch: [11][2400/10208]\tTime 0.722 (0.784)\tData 0.025 (0.034)\tLoss 177.5340 (178.2002)\t\n",
      "Epoch: [11][2500/10208]\tTime 0.722 (0.783)\tData 0.026 (0.033)\tLoss 177.1775 (178.1937)\t\n",
      "Epoch: [11][2600/10208]\tTime 0.750 (0.783)\tData 0.055 (0.033)\tLoss 176.6911 (178.1825)\t\n",
      "Epoch: [11][2700/10208]\tTime 0.720 (0.783)\tData 0.026 (0.033)\tLoss 179.1633 (178.1886)\t\n",
      "Epoch: [11][2800/10208]\tTime 1.096 (0.783)\tData 0.026 (0.033)\tLoss 179.7262 (178.1806)\t\n",
      "Epoch: [11][2900/10208]\tTime 0.720 (0.783)\tData 0.025 (0.032)\tLoss 179.1172 (178.1788)\t\n",
      "Epoch: [11][3000/10208]\tTime 0.722 (0.782)\tData 0.025 (0.032)\tLoss 177.8023 (178.1670)\t\n",
      "Epoch: [11][3100/10208]\tTime 0.749 (0.782)\tData 0.026 (0.032)\tLoss 176.3862 (178.1551)\t\n",
      "Epoch: [11][3200/10208]\tTime 0.720 (0.782)\tData 0.025 (0.032)\tLoss 178.9493 (178.1478)\t\n",
      "Epoch: [11][3300/10208]\tTime 1.073 (0.782)\tData 0.026 (0.032)\tLoss 176.8415 (178.1381)\t\n",
      "Epoch: [11][3400/10208]\tTime 0.723 (0.782)\tData 0.026 (0.032)\tLoss 175.3427 (178.1374)\t\n",
      "Epoch: [11][3500/10208]\tTime 0.722 (0.782)\tData 0.025 (0.031)\tLoss 178.8408 (178.1350)\t\n",
      "Epoch: [11][3600/10208]\tTime 0.738 (0.782)\tData 0.026 (0.031)\tLoss 177.9599 (178.1300)\t\n",
      "Epoch: [11][3700/10208]\tTime 0.728 (0.782)\tData 0.025 (0.031)\tLoss 179.2062 (178.1239)\t\n",
      "Epoch: [11][3800/10208]\tTime 1.087 (0.781)\tData 0.026 (0.031)\tLoss 177.5734 (178.1166)\t\n",
      "Epoch: [11][3900/10208]\tTime 0.719 (0.781)\tData 0.025 (0.031)\tLoss 176.6380 (178.1096)\t\n",
      "Epoch: [11][4000/10208]\tTime 0.717 (0.781)\tData 0.025 (0.031)\tLoss 175.9109 (178.1033)\t\n",
      "Epoch: [11][4100/10208]\tTime 0.755 (0.781)\tData 0.025 (0.031)\tLoss 178.2328 (178.1012)\t\n",
      "Epoch: [11][4200/10208]\tTime 0.738 (0.781)\tData 0.026 (0.031)\tLoss 176.2520 (178.0944)\t\n",
      "Epoch: [11][4300/10208]\tTime 1.133 (0.781)\tData 0.025 (0.030)\tLoss 177.7106 (178.0796)\t\n",
      "Epoch: [11][4400/10208]\tTime 0.721 (0.781)\tData 0.025 (0.030)\tLoss 179.1619 (178.0775)\t\n",
      "Epoch: [11][4500/10208]\tTime 0.714 (0.781)\tData 0.025 (0.030)\tLoss 175.0047 (178.0713)\t\n",
      "Epoch: [11][4600/10208]\tTime 0.731 (0.781)\tData 0.026 (0.030)\tLoss 177.7371 (178.0679)\t\n",
      "Epoch: [11][4700/10208]\tTime 0.722 (0.780)\tData 0.025 (0.030)\tLoss 178.7379 (178.0604)\t\n",
      "Epoch: [11][4800/10208]\tTime 0.864 (0.780)\tData 0.026 (0.030)\tLoss 176.9563 (178.0609)\t\n",
      "Epoch: [11][4900/10208]\tTime 0.719 (0.780)\tData 0.026 (0.030)\tLoss 181.6282 (178.0588)\t\n",
      "Epoch: [11][5000/10208]\tTime 0.724 (0.780)\tData 0.026 (0.030)\tLoss 176.3625 (178.0524)\t\n",
      "Epoch: [11][5100/10208]\tTime 0.733 (0.780)\tData 0.025 (0.030)\tLoss 177.0044 (178.0440)\t\n",
      "Epoch: [11][5200/10208]\tTime 0.725 (0.780)\tData 0.025 (0.030)\tLoss 181.9641 (178.0416)\t\n",
      "Epoch: [11][5300/10208]\tTime 0.727 (0.780)\tData 0.026 (0.030)\tLoss 176.1372 (178.0376)\t\n",
      "Epoch: [11][5400/10208]\tTime 0.738 (0.780)\tData 0.025 (0.030)\tLoss 178.3992 (178.0384)\t\n",
      "Epoch: [11][5500/10208]\tTime 0.719 (0.780)\tData 0.026 (0.030)\tLoss 174.7311 (178.0339)\t\n",
      "Epoch: [11][5600/10208]\tTime 0.749 (0.780)\tData 0.025 (0.029)\tLoss 178.4245 (178.0264)\t\n",
      "Epoch: [11][5700/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 179.3984 (178.0210)\t\n",
      "Epoch: [11][5800/10208]\tTime 0.750 (0.780)\tData 0.025 (0.029)\tLoss 179.1574 (178.0186)\t\n",
      "Epoch: [11][5900/10208]\tTime 0.731 (0.780)\tData 0.026 (0.029)\tLoss 178.7827 (178.0109)\t\n",
      "Epoch: [11][6000/10208]\tTime 0.738 (0.780)\tData 0.025 (0.029)\tLoss 178.1980 (178.0066)\t\n",
      "Epoch: [11][6100/10208]\tTime 1.003 (0.780)\tData 0.025 (0.029)\tLoss 174.8147 (177.9988)\t\n",
      "Epoch: [11][6200/10208]\tTime 0.718 (0.780)\tData 0.025 (0.029)\tLoss 177.1895 (177.9933)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][6300/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 177.9902 (177.9877)\t\n",
      "Epoch: [11][6400/10208]\tTime 0.758 (0.780)\tData 0.025 (0.029)\tLoss 178.8732 (177.9820)\t\n",
      "Epoch: [11][6500/10208]\tTime 0.725 (0.780)\tData 0.026 (0.029)\tLoss 175.0977 (177.9756)\t\n",
      "Epoch: [11][6600/10208]\tTime 1.238 (0.780)\tData 0.025 (0.029)\tLoss 179.1657 (177.9703)\t\n",
      "Epoch: [11][6700/10208]\tTime 0.724 (0.780)\tData 0.025 (0.029)\tLoss 178.7919 (177.9649)\t\n",
      "Epoch: [11][6800/10208]\tTime 0.721 (0.779)\tData 0.026 (0.029)\tLoss 177.0470 (177.9617)\t\n",
      "Epoch: [11][6900/10208]\tTime 0.728 (0.780)\tData 0.026 (0.029)\tLoss 177.3727 (177.9559)\t\n",
      "Epoch: [11][7000/10208]\tTime 0.723 (0.779)\tData 0.025 (0.029)\tLoss 181.3313 (177.9536)\t\n",
      "Epoch: [11][7100/10208]\tTime 1.149 (0.779)\tData 0.026 (0.029)\tLoss 179.8049 (177.9482)\t\n",
      "Epoch: [11][7200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.029)\tLoss 179.0040 (177.9407)\t\n",
      "Epoch: [11][7300/10208]\tTime 0.721 (0.779)\tData 0.025 (0.029)\tLoss 176.4835 (177.9369)\t\n",
      "Epoch: [11][7400/10208]\tTime 0.783 (0.779)\tData 0.026 (0.029)\tLoss 177.4356 (177.9315)\t\n",
      "Epoch: [11][7500/10208]\tTime 0.715 (0.779)\tData 0.025 (0.029)\tLoss 177.8332 (177.9263)\t\n",
      "Epoch: [11][7600/10208]\tTime 1.029 (0.779)\tData 0.026 (0.029)\tLoss 177.3530 (177.9234)\t\n",
      "Epoch: [11][7700/10208]\tTime 0.724 (0.779)\tData 0.026 (0.029)\tLoss 178.0682 (177.9196)\t\n",
      "Epoch: [11][7800/10208]\tTime 0.717 (0.779)\tData 0.025 (0.029)\tLoss 174.7979 (177.9166)\t\n",
      "Epoch: [11][7900/10208]\tTime 0.739 (0.779)\tData 0.026 (0.028)\tLoss 177.3286 (177.9122)\t\n",
      "Epoch: [11][8000/10208]\tTime 0.731 (0.779)\tData 0.026 (0.028)\tLoss 179.4130 (177.9052)\t\n",
      "Epoch: [11][8100/10208]\tTime 0.758 (0.779)\tData 0.025 (0.028)\tLoss 181.4639 (177.9018)\t\n",
      "Epoch: [11][8200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 180.0743 (177.8965)\t\n",
      "Epoch: [11][8300/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 176.6648 (177.8909)\t\n",
      "Epoch: [11][8400/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 177.0685 (177.8853)\t\n",
      "Epoch: [11][8500/10208]\tTime 0.721 (0.779)\tData 0.026 (0.028)\tLoss 176.7854 (177.8802)\t\n",
      "Epoch: [11][8600/10208]\tTime 0.725 (0.779)\tData 0.025 (0.028)\tLoss 178.1489 (177.8772)\t\n",
      "Epoch: [11][8700/10208]\tTime 0.737 (0.779)\tData 0.026 (0.028)\tLoss 176.6179 (177.8733)\t\n",
      "Epoch: [11][8800/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 179.6938 (177.8708)\t\n",
      "Epoch: [11][8900/10208]\tTime 0.725 (0.779)\tData 0.025 (0.028)\tLoss 177.9869 (177.8700)\t\n",
      "Epoch: [11][9000/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 177.2191 (177.8643)\t\n",
      "Epoch: [11][9100/10208]\tTime 0.730 (0.778)\tData 0.025 (0.028)\tLoss 177.7699 (177.8599)\t\n",
      "Epoch: [11][9200/10208]\tTime 0.745 (0.778)\tData 0.027 (0.028)\tLoss 178.5836 (177.8562)\t\n",
      "Epoch: [11][9300/10208]\tTime 0.746 (0.778)\tData 0.026 (0.028)\tLoss 178.8197 (177.8518)\t\n",
      "Epoch: [11][9400/10208]\tTime 1.198 (0.778)\tData 0.026 (0.028)\tLoss 175.8962 (177.8474)\t\n",
      "Epoch: [11][9500/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 178.7277 (177.8450)\t\n",
      "Epoch: [11][9600/10208]\tTime 0.729 (0.778)\tData 0.026 (0.028)\tLoss 177.1797 (177.8429)\t\n",
      "Epoch: [11][9700/10208]\tTime 0.754 (0.778)\tData 0.026 (0.028)\tLoss 177.1552 (177.8417)\t\n",
      "Epoch: [11][9800/10208]\tTime 0.725 (0.778)\tData 0.026 (0.028)\tLoss 178.8535 (177.8385)\t\n",
      "Epoch: [11][9900/10208]\tTime 1.053 (0.778)\tData 0.026 (0.028)\tLoss 176.1941 (177.8350)\t\n",
      "Epoch: [11][10000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 177.6458 (177.8297)\t\n",
      "Epoch: [11][10100/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 177.2932 (177.8267)\t\n",
      "Epoch: [11][10200/10208]\tTime 0.731 (0.778)\tData 0.026 (0.028)\tLoss 177.4220 (177.8246)\t\n",
      "Epoch: [11][10207/10208]\tTime 0.716 (0.778)\tData 0.025 (0.028)\tLoss 176.3455 (177.8242)\t\n",
      "Start training\n",
      "Epoch: [12][0/10208]\tTime 16.642 (16.642)\tData 15.784 (15.784)\tLoss 176.1775 (176.1775)\t\n",
      "Epoch: [12][100/10208]\tTime 0.724 (0.940)\tData 0.026 (0.182)\tLoss 176.8107 (177.1997)\t\n",
      "Epoch: [12][200/10208]\tTime 0.804 (0.858)\tData 0.025 (0.105)\tLoss 176.6131 (177.0994)\t\n",
      "Epoch: [12][300/10208]\tTime 0.729 (0.829)\tData 0.026 (0.079)\tLoss 177.4353 (177.1525)\t\n",
      "Epoch: [12][400/10208]\tTime 1.242 (0.816)\tData 0.026 (0.066)\tLoss 177.5895 (177.2298)\t\n",
      "Epoch: [12][500/10208]\tTime 0.726 (0.808)\tData 0.025 (0.058)\tLoss 175.8879 (177.2147)\t\n",
      "Epoch: [12][600/10208]\tTime 0.736 (0.802)\tData 0.026 (0.053)\tLoss 174.4875 (177.1789)\t\n",
      "Epoch: [12][700/10208]\tTime 0.725 (0.798)\tData 0.025 (0.049)\tLoss 177.0463 (177.1858)\t\n",
      "Epoch: [12][800/10208]\tTime 0.726 (0.795)\tData 0.026 (0.046)\tLoss 177.0124 (177.1984)\t\n",
      "Epoch: [12][900/10208]\tTime 0.728 (0.794)\tData 0.025 (0.044)\tLoss 177.4775 (177.1903)\t\n",
      "Epoch: [12][1000/10208]\tTime 0.728 (0.792)\tData 0.026 (0.042)\tLoss 178.3105 (177.1934)\t\n",
      "Epoch: [12][1100/10208]\tTime 0.725 (0.790)\tData 0.025 (0.041)\tLoss 177.6661 (177.2058)\t\n",
      "Epoch: [12][1200/10208]\tTime 0.719 (0.789)\tData 0.025 (0.039)\tLoss 175.9021 (177.1994)\t\n",
      "Epoch: [12][1300/10208]\tTime 0.744 (0.789)\tData 0.025 (0.038)\tLoss 177.6297 (177.2006)\t\n",
      "Epoch: [12][1400/10208]\tTime 0.724 (0.788)\tData 0.026 (0.038)\tLoss 176.9998 (177.1897)\t\n",
      "Epoch: [12][1500/10208]\tTime 0.718 (0.787)\tData 0.026 (0.037)\tLoss 175.0891 (177.1903)\t\n",
      "Epoch: [12][1600/10208]\tTime 0.718 (0.786)\tData 0.025 (0.036)\tLoss 178.4246 (177.1820)\t\n",
      "Epoch: [12][1700/10208]\tTime 0.721 (0.786)\tData 0.025 (0.036)\tLoss 179.3082 (177.1748)\t\n",
      "Epoch: [12][1800/10208]\tTime 0.719 (0.786)\tData 0.025 (0.035)\tLoss 178.3895 (177.1860)\t\n",
      "Epoch: [12][1900/10208]\tTime 0.720 (0.785)\tData 0.026 (0.035)\tLoss 178.1146 (177.1730)\t\n",
      "Epoch: [12][2000/10208]\tTime 0.723 (0.785)\tData 0.026 (0.034)\tLoss 177.7157 (177.1783)\t\n",
      "Epoch: [12][2100/10208]\tTime 0.725 (0.784)\tData 0.025 (0.034)\tLoss 176.5471 (177.1822)\t\n",
      "Epoch: [12][2200/10208]\tTime 0.994 (0.784)\tData 0.026 (0.034)\tLoss 179.1093 (177.1773)\t\n",
      "Epoch: [12][2300/10208]\tTime 0.713 (0.784)\tData 0.025 (0.033)\tLoss 178.0879 (177.1717)\t\n",
      "Epoch: [12][2400/10208]\tTime 0.741 (0.783)\tData 0.025 (0.033)\tLoss 176.4159 (177.1671)\t\n",
      "Epoch: [12][2500/10208]\tTime 0.727 (0.783)\tData 0.026 (0.033)\tLoss 175.3392 (177.1676)\t\n",
      "Epoch: [12][2600/10208]\tTime 0.724 (0.783)\tData 0.026 (0.032)\tLoss 177.3682 (177.1692)\t\n",
      "Epoch: [12][2700/10208]\tTime 1.104 (0.783)\tData 0.026 (0.032)\tLoss 177.1241 (177.1730)\t\n",
      "Epoch: [12][2800/10208]\tTime 0.739 (0.782)\tData 0.025 (0.032)\tLoss 176.6089 (177.1689)\t\n",
      "Epoch: [12][2900/10208]\tTime 0.724 (0.782)\tData 0.026 (0.032)\tLoss 179.8631 (177.1626)\t\n",
      "Epoch: [12][3000/10208]\tTime 0.766 (0.782)\tData 0.026 (0.032)\tLoss 176.0494 (177.1628)\t\n",
      "Epoch: [12][3100/10208]\tTime 0.724 (0.782)\tData 0.026 (0.031)\tLoss 177.6678 (177.1550)\t\n",
      "Epoch: [12][3200/10208]\tTime 1.117 (0.782)\tData 0.025 (0.031)\tLoss 178.4796 (177.1484)\t\n",
      "Epoch: [12][3300/10208]\tTime 0.742 (0.782)\tData 0.025 (0.031)\tLoss 177.7986 (177.1422)\t\n",
      "Epoch: [12][3400/10208]\tTime 0.734 (0.782)\tData 0.025 (0.031)\tLoss 179.3295 (177.1428)\t\n",
      "Epoch: [12][3500/10208]\tTime 0.717 (0.782)\tData 0.025 (0.031)\tLoss 178.1232 (177.1325)\t\n",
      "Epoch: [12][3600/10208]\tTime 0.714 (0.782)\tData 0.026 (0.031)\tLoss 176.2278 (177.1331)\t\n",
      "Epoch: [12][3700/10208]\tTime 1.083 (0.782)\tData 0.026 (0.031)\tLoss 174.5928 (177.1304)\t\n",
      "Epoch: [12][3800/10208]\tTime 0.757 (0.782)\tData 0.025 (0.030)\tLoss 173.7665 (177.1179)\t\n",
      "Epoch: [12][3900/10208]\tTime 0.722 (0.781)\tData 0.026 (0.030)\tLoss 176.4837 (177.1186)\t\n",
      "Epoch: [12][4000/10208]\tTime 0.796 (0.781)\tData 0.026 (0.030)\tLoss 174.6463 (177.1175)\t\n",
      "Epoch: [12][4100/10208]\tTime 0.726 (0.781)\tData 0.026 (0.030)\tLoss 178.1025 (177.1119)\t\n",
      "Epoch: [12][4200/10208]\tTime 0.734 (0.781)\tData 0.026 (0.030)\tLoss 176.3253 (177.1128)\t\n",
      "Epoch: [12][4300/10208]\tTime 0.732 (0.781)\tData 0.026 (0.030)\tLoss 175.3808 (177.1119)\t\n",
      "Epoch: [12][4400/10208]\tTime 0.717 (0.781)\tData 0.025 (0.030)\tLoss 176.9144 (177.1107)\t\n",
      "Epoch: [12][4500/10208]\tTime 0.735 (0.780)\tData 0.026 (0.030)\tLoss 177.7232 (177.1023)\t\n",
      "Epoch: [12][4600/10208]\tTime 0.730 (0.780)\tData 0.025 (0.030)\tLoss 178.5244 (177.1058)\t\n",
      "Epoch: [12][4700/10208]\tTime 0.744 (0.780)\tData 0.025 (0.030)\tLoss 177.1851 (177.1088)\t\n",
      "Epoch: [12][4800/10208]\tTime 0.731 (0.780)\tData 0.026 (0.030)\tLoss 180.0346 (177.1082)\t\n",
      "Epoch: [12][4900/10208]\tTime 0.737 (0.780)\tData 0.025 (0.029)\tLoss 175.8465 (177.1045)\t\n",
      "Epoch: [12][5000/10208]\tTime 0.727 (0.780)\tData 0.025 (0.029)\tLoss 176.7862 (177.1094)\t\n",
      "Epoch: [12][5100/10208]\tTime 0.723 (0.780)\tData 0.025 (0.029)\tLoss 178.5712 (177.1086)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][5200/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 175.7195 (177.1066)\t\n",
      "Epoch: [12][5300/10208]\tTime 0.730 (0.780)\tData 0.026 (0.029)\tLoss 177.7201 (177.1062)\t\n",
      "Epoch: [12][5400/10208]\tTime 0.725 (0.780)\tData 0.025 (0.029)\tLoss 178.3834 (177.1069)\t\n",
      "Epoch: [12][5500/10208]\tTime 1.104 (0.780)\tData 0.026 (0.029)\tLoss 177.8806 (177.1075)\t\n",
      "Epoch: [12][5600/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 175.8921 (177.1048)\t\n",
      "Epoch: [12][5700/10208]\tTime 0.717 (0.780)\tData 0.026 (0.029)\tLoss 174.6758 (177.0996)\t\n",
      "Epoch: [12][5800/10208]\tTime 0.728 (0.780)\tData 0.026 (0.029)\tLoss 176.9340 (177.0971)\t\n",
      "Epoch: [12][5900/10208]\tTime 0.761 (0.780)\tData 0.026 (0.029)\tLoss 176.7609 (177.0936)\t\n",
      "Epoch: [12][6000/10208]\tTime 1.108 (0.780)\tData 0.026 (0.029)\tLoss 176.2689 (177.0906)\t\n",
      "Epoch: [12][6100/10208]\tTime 0.738 (0.780)\tData 0.026 (0.029)\tLoss 177.6653 (177.0885)\t\n",
      "Epoch: [12][6200/10208]\tTime 0.724 (0.780)\tData 0.026 (0.029)\tLoss 178.6955 (177.0817)\t\n",
      "Epoch: [12][6300/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 176.1335 (177.0808)\t\n",
      "Epoch: [12][6400/10208]\tTime 0.726 (0.780)\tData 0.026 (0.029)\tLoss 175.9761 (177.0828)\t\n",
      "Epoch: [12][6500/10208]\tTime 1.236 (0.780)\tData 0.025 (0.029)\tLoss 177.5702 (177.0834)\t\n",
      "Epoch: [12][6600/10208]\tTime 0.745 (0.779)\tData 0.026 (0.029)\tLoss 179.5081 (177.0832)\t\n",
      "Epoch: [12][6700/10208]\tTime 0.724 (0.779)\tData 0.025 (0.029)\tLoss 174.9330 (177.0793)\t\n",
      "Epoch: [12][6800/10208]\tTime 0.757 (0.779)\tData 0.055 (0.029)\tLoss 177.6154 (177.0754)\t\n",
      "Epoch: [12][6900/10208]\tTime 0.725 (0.779)\tData 0.026 (0.029)\tLoss 177.5286 (177.0758)\t\n",
      "Epoch: [12][7000/10208]\tTime 1.045 (0.779)\tData 0.025 (0.028)\tLoss 177.9499 (177.0748)\t\n",
      "Epoch: [12][7100/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 177.1022 (177.0725)\t\n",
      "Epoch: [12][7200/10208]\tTime 0.743 (0.779)\tData 0.026 (0.028)\tLoss 177.7712 (177.0755)\t\n",
      "Epoch: [12][7300/10208]\tTime 0.749 (0.779)\tData 0.025 (0.028)\tLoss 175.3375 (177.0744)\t\n",
      "Epoch: [12][7400/10208]\tTime 0.735 (0.779)\tData 0.025 (0.028)\tLoss 177.7493 (177.0694)\t\n",
      "Epoch: [12][7500/10208]\tTime 0.743 (0.779)\tData 0.026 (0.028)\tLoss 176.0572 (177.0673)\t\n",
      "Epoch: [12][7600/10208]\tTime 0.744 (0.779)\tData 0.026 (0.028)\tLoss 176.0353 (177.0666)\t\n",
      "Epoch: [12][7700/10208]\tTime 0.726 (0.779)\tData 0.025 (0.028)\tLoss 178.5662 (177.0674)\t\n",
      "Epoch: [12][7800/10208]\tTime 0.765 (0.779)\tData 0.025 (0.028)\tLoss 175.9695 (177.0669)\t\n",
      "Epoch: [12][7900/10208]\tTime 0.716 (0.779)\tData 0.025 (0.028)\tLoss 179.3540 (177.0663)\t\n",
      "Epoch: [12][8000/10208]\tTime 0.720 (0.779)\tData 0.025 (0.028)\tLoss 173.9558 (177.0623)\t\n",
      "Epoch: [12][8100/10208]\tTime 0.727 (0.779)\tData 0.026 (0.028)\tLoss 175.1781 (177.0609)\t\n",
      "Epoch: [12][8200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 176.8918 (177.0559)\t\n",
      "Epoch: [12][8300/10208]\tTime 0.735 (0.779)\tData 0.028 (0.028)\tLoss 176.9554 (177.0522)\t\n",
      "Epoch: [12][8400/10208]\tTime 0.738 (0.779)\tData 0.026 (0.028)\tLoss 180.2310 (177.0527)\t\n",
      "Epoch: [12][8500/10208]\tTime 0.717 (0.779)\tData 0.026 (0.028)\tLoss 177.7447 (177.0497)\t\n",
      "Epoch: [12][8600/10208]\tTime 0.718 (0.779)\tData 0.025 (0.028)\tLoss 177.7164 (177.0504)\t\n",
      "Epoch: [12][8700/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 177.1464 (177.0472)\t\n",
      "Epoch: [12][8800/10208]\tTime 1.198 (0.779)\tData 0.026 (0.028)\tLoss 175.6965 (177.0473)\t\n",
      "Epoch: [12][8900/10208]\tTime 0.729 (0.779)\tData 0.025 (0.028)\tLoss 177.1092 (177.0459)\t\n",
      "Epoch: [12][9000/10208]\tTime 0.730 (0.779)\tData 0.025 (0.028)\tLoss 175.4188 (177.0442)\t\n",
      "Epoch: [12][9100/10208]\tTime 0.723 (0.779)\tData 0.025 (0.028)\tLoss 177.9956 (177.0437)\t\n",
      "Epoch: [12][9200/10208]\tTime 0.714 (0.779)\tData 0.025 (0.028)\tLoss 176.3535 (177.0438)\t\n",
      "Epoch: [12][9300/10208]\tTime 1.129 (0.779)\tData 0.025 (0.028)\tLoss 176.0349 (177.0425)\t\n",
      "Epoch: [12][9400/10208]\tTime 0.746 (0.779)\tData 0.025 (0.028)\tLoss 176.7353 (177.0413)\t\n",
      "Epoch: [12][9500/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 177.5867 (177.0404)\t\n",
      "Epoch: [12][9600/10208]\tTime 0.717 (0.779)\tData 0.025 (0.028)\tLoss 177.3074 (177.0393)\t\n",
      "Epoch: [12][9700/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 174.7474 (177.0346)\t\n",
      "Epoch: [12][9800/10208]\tTime 1.173 (0.779)\tData 0.026 (0.028)\tLoss 177.6812 (177.0348)\t\n",
      "Epoch: [12][9900/10208]\tTime 0.719 (0.779)\tData 0.025 (0.028)\tLoss 174.8907 (177.0343)\t\n",
      "Epoch: [12][10000/10208]\tTime 0.718 (0.779)\tData 0.025 (0.028)\tLoss 175.5930 (177.0311)\t\n",
      "Epoch: [12][10100/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 176.2129 (177.0309)\t\n",
      "Epoch: [12][10200/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 178.2044 (177.0288)\t\n",
      "Epoch: [12][10207/10208]\tTime 0.723 (0.779)\tData 0.025 (0.028)\tLoss 178.0735 (177.0289)\t\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.000025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 73.50 MiB (GPU 3; 15.75 GiB total capacity; 14.25 GiB already allocated; 61.94 MiB free; 265.65 MiB cached) (malloc at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THC/THCCachingAllocator.cpp:231)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x45 (0x7fe1d82abcf5 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1239bc1 (0x7fe184f71bc1 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #2: <unknown function> + 0x123a53a (0x7fe184f7253a in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, at::TensorOptions const&) + 0x2d6 (0x7fe1865dcdb6 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #4: at::CUDAFloatType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x161 (0x7fe184e90311 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #5: torch::autograd::VariableType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x179 (0x7fe1c854e209 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #6: at::TypeDefault::copy(at::Tensor const&, bool, c10::optional<c10::Device>) const + 0x122 (0x7fe1bda5b532 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #7: <unknown function> + 0x719737 (0x7fe1bd881737 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #8: at::native::to(at::Tensor const&, at::TensorOptions const&, bool, bool) + 0x295 (0x7fe1bd8832e5 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #9: at::TypeDefault::to(at::Tensor const&, at::TensorOptions const&, bool, bool) const + 0x17 (0x7fe1bda21ce7 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #10: torch::autograd::VariableType::to(at::Tensor const&, at::TensorOptions const&, bool, bool) const + 0x17a (0x7fe1c84f6bba in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #11: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<at::cuda::CUDAStream>, std::allocator<c10::optional<at::cuda::CUDAStream> > > > const&) + 0x491 (0x7fe1c934af71 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #12: <unknown function> + 0x4f0c51 (0x7fe1c9350c51 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #13: <unknown function> + 0x111826 (0x7fe1c8f71826 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #14: _PyCFunction_FastCallDict + 0x154 (0x56509c1ebb94 in /opt/conda/envs/py36/bin/python)\nframe #15: <unknown function> + 0x19e67c (0x56509c27b67c in /opt/conda/envs/py36/bin/python)\nframe #16: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #17: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #18: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #19: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #21: PyEval_EvalCodeEx + 0x329 (0x56509c276459 in /opt/conda/envs/py36/bin/python)\nframe #22: <unknown function> + 0x19a264 (0x56509c277264 in /opt/conda/envs/py36/bin/python)\nframe #23: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #24: THPFunction_apply(_object*, _object*) + 0x579 (0x7fe1c916c1d9 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #25: _PyCFunction_FastCallDict + 0x91 (0x56509c1ebad1 in /opt/conda/envs/py36/bin/python)\nframe #26: <unknown function> + 0x19e67c (0x56509c27b67c in /opt/conda/envs/py36/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #28: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #29: _PyFunction_FastCallDict + 0x1bb (0x56509c275e1b in /opt/conda/envs/py36/bin/python)\nframe #30: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #31: <unknown function> + 0x12a552 (0x56509c207552 in /opt/conda/envs/py36/bin/python)\nframe #32: PyIter_Next + 0xe (0x56509c230c9e in /opt/conda/envs/py36/bin/python)\nframe #33: PySequence_Tuple + 0xf9 (0x56509c235ad9 in /opt/conda/envs/py36/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x563a (0x56509c2a2ffa in /opt/conda/envs/py36/bin/python)\nframe #35: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #36: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #37: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #38: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #39: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #40: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #41: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #43: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #44: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #45: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #46: _PyEval_EvalFrameDefault + 0x10ba (0x56509c29ea7a in /opt/conda/envs/py36/bin/python)\nframe #47: <unknown function> + 0x19870b (0x56509c27570b in /opt/conda/envs/py36/bin/python)\nframe #48: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #49: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #50: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #51: _PyFunction_FastCallDict + 0x3db (0x56509c27603b in /opt/conda/envs/py36/bin/python)\nframe #52: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #53: _PyObject_Call_Prepend + 0x63 (0x56509c1f0a03 in /opt/conda/envs/py36/bin/python)\nframe #54: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x1ab0 (0x56509c29f470 in /opt/conda/envs/py36/bin/python)\nframe #56: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #57: _PyFunction_FastCallDict + 0x1bb (0x56509c275e1b in /opt/conda/envs/py36/bin/python)\nframe #58: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #59: _PyObject_Call_Prepend + 0x63 (0x56509c1f0a03 in /opt/conda/envs/py36/bin/python)\nframe #60: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #61: <unknown function> + 0x16b9b7 (0x56509c2489b7 in /opt/conda/envs/py36/bin/python)\nframe #62: _PyObject_FastCallDict + 0x8b (0x56509c1ebd7b in /opt/conda/envs/py36/bin/python)\nframe #63: <unknown function> + 0x19e7ce (0x56509c27b7ce in /opt/conda/envs/py36/bin/python)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b4a35cece2f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopti\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a4ce6b0bf87b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, print_freq)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/py36/lib/python3.6/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 73.50 MiB (GPU 3; 15.75 GiB total capacity; 14.25 GiB already allocated; 61.94 MiB free; 265.65 MiB cached) (malloc at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THC/THCCachingAllocator.cpp:231)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x45 (0x7fe1d82abcf5 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1239bc1 (0x7fe184f71bc1 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #2: <unknown function> + 0x123a53a (0x7fe184f7253a in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #3: at::native::empty_cuda(c10::ArrayRef<long>, at::TensorOptions const&) + 0x2d6 (0x7fe1865dcdb6 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #4: at::CUDAFloatType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x161 (0x7fe184e90311 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2_gpu.so)\nframe #5: torch::autograd::VariableType::empty(c10::ArrayRef<long>, at::TensorOptions const&) const + 0x179 (0x7fe1c854e209 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #6: at::TypeDefault::copy(at::Tensor const&, bool, c10::optional<c10::Device>) const + 0x122 (0x7fe1bda5b532 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #7: <unknown function> + 0x719737 (0x7fe1bd881737 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #8: at::native::to(at::Tensor const&, at::TensorOptions const&, bool, bool) + 0x295 (0x7fe1bd8832e5 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #9: at::TypeDefault::to(at::Tensor const&, at::TensorOptions const&, bool, bool) const + 0x17 (0x7fe1bda21ce7 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libcaffe2.so)\nframe #10: torch::autograd::VariableType::to(at::Tensor const&, at::TensorOptions const&, bool, bool) const + 0x17a (0x7fe1c84f6bba in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch.so.1)\nframe #11: torch::cuda::scatter(at::Tensor const&, c10::ArrayRef<long>, c10::optional<std::vector<long, std::allocator<long> > > const&, long, c10::optional<std::vector<c10::optional<at::cuda::CUDAStream>, std::allocator<c10::optional<at::cuda::CUDAStream> > > > const&) + 0x491 (0x7fe1c934af71 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #12: <unknown function> + 0x4f0c51 (0x7fe1c9350c51 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #13: <unknown function> + 0x111826 (0x7fe1c8f71826 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #14: _PyCFunction_FastCallDict + 0x154 (0x56509c1ebb94 in /opt/conda/envs/py36/bin/python)\nframe #15: <unknown function> + 0x19e67c (0x56509c27b67c in /opt/conda/envs/py36/bin/python)\nframe #16: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #17: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #18: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #19: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #20: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #21: PyEval_EvalCodeEx + 0x329 (0x56509c276459 in /opt/conda/envs/py36/bin/python)\nframe #22: <unknown function> + 0x19a264 (0x56509c277264 in /opt/conda/envs/py36/bin/python)\nframe #23: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #24: THPFunction_apply(_object*, _object*) + 0x579 (0x7fe1c916c1d9 in /opt/conda/envs/py36/lib/python3.6/site-packages/torch/lib/libtorch_python.so)\nframe #25: _PyCFunction_FastCallDict + 0x91 (0x56509c1ebad1 in /opt/conda/envs/py36/bin/python)\nframe #26: <unknown function> + 0x19e67c (0x56509c27b67c in /opt/conda/envs/py36/bin/python)\nframe #27: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #28: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #29: _PyFunction_FastCallDict + 0x1bb (0x56509c275e1b in /opt/conda/envs/py36/bin/python)\nframe #30: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #31: <unknown function> + 0x12a552 (0x56509c207552 in /opt/conda/envs/py36/bin/python)\nframe #32: PyIter_Next + 0xe (0x56509c230c9e in /opt/conda/envs/py36/bin/python)\nframe #33: PySequence_Tuple + 0xf9 (0x56509c235ad9 in /opt/conda/envs/py36/bin/python)\nframe #34: _PyEval_EvalFrameDefault + 0x563a (0x56509c2a2ffa in /opt/conda/envs/py36/bin/python)\nframe #35: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #36: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #37: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #38: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #39: <unknown function> + 0x197dae (0x56509c274dae in /opt/conda/envs/py36/bin/python)\nframe #40: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #41: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #42: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #43: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #44: <unknown function> + 0x198941 (0x56509c275941 in /opt/conda/envs/py36/bin/python)\nframe #45: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #46: _PyEval_EvalFrameDefault + 0x10ba (0x56509c29ea7a in /opt/conda/envs/py36/bin/python)\nframe #47: <unknown function> + 0x19870b (0x56509c27570b in /opt/conda/envs/py36/bin/python)\nframe #48: <unknown function> + 0x19e755 (0x56509c27b755 in /opt/conda/envs/py36/bin/python)\nframe #49: _PyEval_EvalFrameDefault + 0x2fa (0x56509c29dcba in /opt/conda/envs/py36/bin/python)\nframe #50: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #51: _PyFunction_FastCallDict + 0x3db (0x56509c27603b in /opt/conda/envs/py36/bin/python)\nframe #52: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #53: _PyObject_Call_Prepend + 0x63 (0x56509c1f0a03 in /opt/conda/envs/py36/bin/python)\nframe #54: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #55: _PyEval_EvalFrameDefault + 0x1ab0 (0x56509c29f470 in /opt/conda/envs/py36/bin/python)\nframe #56: <unknown function> + 0x197a94 (0x56509c274a94 in /opt/conda/envs/py36/bin/python)\nframe #57: _PyFunction_FastCallDict + 0x1bb (0x56509c275e1b in /opt/conda/envs/py36/bin/python)\nframe #58: _PyObject_FastCallDict + 0x26f (0x56509c1ebf5f in /opt/conda/envs/py36/bin/python)\nframe #59: _PyObject_Call_Prepend + 0x63 (0x56509c1f0a03 in /opt/conda/envs/py36/bin/python)\nframe #60: PyObject_Call + 0x3e (0x56509c1eb99e in /opt/conda/envs/py36/bin/python)\nframe #61: <unknown function> + 0x16b9b7 (0x56509c2489b7 in /opt/conda/envs/py36/bin/python)\nframe #62: _PyObject_FastCallDict + 0x8b (0x56509c1ebd7b in /opt/conda/envs/py36/bin/python)\nframe #63: <unknown function> + 0x19e7ce (0x56509c27b7ce in /opt/conda/envs/py36/bin/python)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=200)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
