{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import fastText\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import models\n",
    "from dataset import openimages\n",
    "from utils.loss import HardNegativeContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq=1000):\n",
    "    #amp_handle = amp.init()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.train()\n",
    "    print(\"Start training\")\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps) in enumerate(train_loader):\n",
    "        if i%2 == 1:\n",
    "                print(\"%2.2f\"% (i/len(train_loader)*100), '\\%', end='\\r')\n",
    "        input_imgs, target = imgs.cuda(), caps.cuda()\n",
    "        \n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_imgs = model(input_imgs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_imgs, target)\n",
    "        \n",
    "        #with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg, batch_time.avg, data_time.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    imgs_enc = list()\n",
    "    caps_enc = list()\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "\n",
    "        input_imgs, input_caps = imgs.cuda(), caps.cuda()\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_imgs = model(input_imgs)\n",
    "            loss = criterion(output_imgs, input_caps)\n",
    "\n",
    "        imgs_enc.append(output_imgs.cpu().data.numpy())\n",
    "        caps_enc.append(output_caps.cpu().data.numpy())\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(val_loader) - 1):\n",
    "            print('Data: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    recall  = eval_recall(imgs_enc, caps_enc)\n",
    "    print(recall)\n",
    "    return losses.avg, batch_time.avg, data_time.avg, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prepro = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "prepro_val = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(models.ImageProjection().train().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.module.projection.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_embeds(data):\n",
    "    images, targets = zip(*data)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.Tensor(np.stack(targets, 0))\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3072, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HardNegativeContrastiveLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 58.837 (58.837)\tData 32.222 (32.222)\tLoss 5065.3916 (5065.3916)\t\n",
      "Epoch: [0][50/2191]\tTime 1.888 (2.689)\tData 0.115 (0.753)\tLoss 8174.1582 (9939.4797)\t\n",
      "Epoch: [0][100/2191]\tTime 1.354 (2.066)\tData 0.116 (0.443)\tLoss 7127.2090 (8879.8595)\t\n",
      "Epoch: [0][150/2191]\tTime 1.324 (1.865)\tData 0.117 (0.339)\tLoss 9998.9590 (9019.7205)\t\n",
      "Epoch: [0][200/2191]\tTime 1.328 (1.758)\tData 0.115 (0.287)\tLoss 8123.5645 (8971.5343)\t\n",
      "Epoch: [0][250/2191]\tTime 1.327 (1.692)\tData 0.116 (0.255)\tLoss 6510.5483 (8671.2556)\t\n",
      "Epoch: [0][300/2191]\tTime 1.333 (1.649)\tData 0.116 (0.233)\tLoss 6361.2222 (8354.4636)\t\n",
      "Epoch: [0][350/2191]\tTime 1.327 (1.615)\tData 0.116 (0.217)\tLoss 6979.4229 (8109.9479)\t\n",
      "Epoch: [0][400/2191]\tTime 1.858 (1.595)\tData 0.116 (0.205)\tLoss 8735.3262 (8153.7529)\t\n",
      "Epoch: [0][450/2191]\tTime 1.328 (1.577)\tData 0.116 (0.196)\tLoss 8741.9980 (8163.0154)\t\n",
      "Epoch: [0][500/2191]\tTime 1.459 (1.560)\tData 0.247 (0.189)\tLoss 7970.5630 (8180.6867)\t\n",
      "Epoch: [0][550/2191]\tTime 1.331 (1.549)\tData 0.116 (0.184)\tLoss 7093.3530 (8133.0711)\t\n",
      "Epoch: [0][600/2191]\tTime 1.332 (1.539)\tData 0.117 (0.179)\tLoss 10098.0303 (8117.1455)\t\n",
      "Epoch: [0][650/2191]\tTime 1.326 (1.530)\tData 0.116 (0.175)\tLoss 7781.2217 (8113.1772)\t\n",
      "Epoch: [0][700/2191]\tTime 1.330 (1.522)\tData 0.116 (0.172)\tLoss 7592.8354 (8129.1951)\t\n",
      "Epoch: [0][750/2191]\tTime 1.786 (1.516)\tData 0.116 (0.168)\tLoss 9610.7158 (8074.2622)\t\n",
      "Epoch: [0][800/2191]\tTime 1.331 (1.510)\tData 0.117 (0.166)\tLoss 7892.0767 (8134.2885)\t\n",
      "Epoch: [0][850/2191]\tTime 1.325 (1.505)\tData 0.116 (0.163)\tLoss 8235.4072 (8146.2536)\t\n",
      "Epoch: [0][900/2191]\tTime 1.361 (1.500)\tData 0.117 (0.161)\tLoss 9740.2344 (8091.7376)\t\n",
      "Epoch: [0][950/2191]\tTime 1.330 (1.495)\tData 0.117 (0.159)\tLoss 7965.3130 (8039.7251)\t\n",
      "Epoch: [0][1000/2191]\tTime 1.330 (1.492)\tData 0.117 (0.157)\tLoss 7266.1841 (8023.7087)\t\n",
      "Epoch: [0][1050/2191]\tTime 1.325 (1.490)\tData 0.118 (0.156)\tLoss 7685.0366 (8015.7088)\t\n",
      "Epoch: [0][1100/2191]\tTime 1.936 (1.488)\tData 0.116 (0.154)\tLoss 6690.6826 (7988.1899)\t\n",
      "Epoch: [0][1150/2191]\tTime 1.325 (1.485)\tData 0.115 (0.153)\tLoss 10163.8955 (7940.3929)\t\n",
      "Epoch: [0][1200/2191]\tTime 1.326 (1.482)\tData 0.116 (0.152)\tLoss 7333.4111 (7896.9628)\t\n",
      "Epoch: [0][1250/2191]\tTime 1.325 (1.479)\tData 0.116 (0.151)\tLoss 6177.1816 (7866.9857)\t\n",
      "Epoch: [0][1300/2191]\tTime 1.329 (1.477)\tData 0.120 (0.150)\tLoss 7335.1323 (7873.3829)\t\n",
      "Epoch: [0][1350/2191]\tTime 1.328 (1.475)\tData 0.116 (0.149)\tLoss 10366.2510 (7932.3870)\t\n",
      "Epoch: [0][1400/2191]\tTime 1.327 (1.473)\tData 0.115 (0.148)\tLoss 9487.0684 (8005.5425)\t\n",
      "Epoch: [0][1450/2191]\tTime 1.817 (1.472)\tData 0.115 (0.147)\tLoss 5454.8760 (7998.6466)\t\n",
      "Epoch: [0][1500/2191]\tTime 1.330 (1.472)\tData 0.116 (0.146)\tLoss 5598.6709 (7921.4340)\t\n",
      "Epoch: [0][1550/2191]\tTime 1.330 (1.470)\tData 0.116 (0.145)\tLoss 5261.9014 (7844.0253)\t\n",
      "Epoch: [0][1600/2191]\tTime 1.328 (1.468)\tData 0.116 (0.145)\tLoss 7652.7363 (7812.2137)\t\n",
      "Epoch: [0][1650/2191]\tTime 1.333 (1.466)\tData 0.119 (0.144)\tLoss 8616.8340 (7822.2409)\t\n",
      "Epoch: [0][1700/2191]\tTime 1.332 (1.465)\tData 0.116 (0.143)\tLoss 7353.2617 (7817.1196)\t\n",
      "Epoch: [0][1750/2191]\tTime 1.331 (1.463)\tData 0.116 (0.143)\tLoss 9606.9248 (7812.6407)\t\n",
      "Epoch: [0][1800/2191]\tTime 1.780 (1.462)\tData 0.116 (0.142)\tLoss 6855.3496 (7812.2320)\t\n",
      "Epoch: [0][1850/2191]\tTime 1.326 (1.461)\tData 0.115 (0.142)\tLoss 8153.3965 (7793.2683)\t\n",
      "Epoch: [0][1900/2191]\tTime 1.329 (1.460)\tData 0.116 (0.141)\tLoss 7648.8442 (7796.1466)\t\n",
      "Epoch: [0][1950/2191]\tTime 1.329 (1.459)\tData 0.115 (0.141)\tLoss 6071.6274 (7783.1381)\t\n",
      "Epoch: [0][2000/2191]\tTime 1.329 (1.458)\tData 0.116 (0.140)\tLoss 8214.2217 (7812.4349)\t\n",
      "Epoch: [0][2050/2191]\tTime 1.326 (1.457)\tData 0.116 (0.140)\tLoss 6318.2900 (7789.2213)\t\n",
      "Epoch: [0][2100/2191]\tTime 1.330 (1.456)\tData 0.117 (0.139)\tLoss 7038.3633 (7758.9125)\t\n",
      "Epoch: [0][2150/2191]\tTime 1.752 (1.455)\tData 0.116 (0.139)\tLoss 8031.9453 (7752.9867)\t\n",
      "Epoch: [0][2190/2191]\tTime 1.320 (1.453)\tData 0.114 (0.138)\tLoss 5919.3242 (7745.9767)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7745.976734546155, 1.4532104864995374, 0.1383018260783444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 21.584 (21.584)\tData 20.291 (20.291)\tLoss 6896.0942 (6896.0942)\t\n",
      "Epoch: [0][50/2191]\tTime 1.672 (2.120)\tData 0.117 (0.745)\tLoss 4490.7168 (5408.1094)\t\n",
      "Epoch: [0][100/2191]\tTime 1.332 (1.780)\tData 0.119 (0.440)\tLoss 4052.2847 (4848.7612)\t\n",
      "Epoch: [0][150/2191]\tTime 1.326 (1.660)\tData 0.116 (0.336)\tLoss 3058.9360 (4495.5497)\t\n",
      "Epoch: [0][200/2191]\tTime 1.331 (1.602)\tData 0.116 (0.283)\tLoss 2993.4958 (4163.4350)\t\n",
      "Epoch: [0][250/2191]\tTime 1.330 (1.565)\tData 0.117 (0.251)\tLoss 2312.2651 (3845.6544)\t\n",
      "Epoch: [0][300/2191]\tTime 1.348 (1.540)\tData 0.116 (0.229)\tLoss 2224.4983 (3577.2567)\t\n",
      "Epoch: [0][350/2191]\tTime 1.423 (1.522)\tData 0.115 (0.213)\tLoss 2083.6863 (3367.7276)\t\n",
      "Epoch: [0][400/2191]\tTime 1.754 (1.510)\tData 0.116 (0.203)\tLoss 2368.5754 (3219.6241)\t\n",
      "Epoch: [0][450/2191]\tTime 1.339 (1.500)\tData 0.120 (0.193)\tLoss 2379.7559 (3117.2281)\t\n",
      "Epoch: [0][500/2191]\tTime 1.328 (1.492)\tData 0.116 (0.186)\tLoss 3292.6516 (3059.0133)\t\n",
      "Epoch: [0][550/2191]\tTime 1.326 (1.484)\tData 0.116 (0.181)\tLoss 5615.8877 (3206.6953)\t\n",
      "Epoch: [0][600/2191]\tTime 1.332 (1.479)\tData 0.117 (0.177)\tLoss 10130.1875 (3501.6341)\t\n",
      "Epoch: [0][650/2191]\tTime 1.327 (1.474)\tData 0.116 (0.172)\tLoss 5765.2178 (3752.8872)\t\n",
      "Epoch: [0][700/2191]\tTime 1.326 (1.470)\tData 0.116 (0.169)\tLoss 5197.8242 (3927.1136)\t\n",
      "Epoch: [0][750/2191]\tTime 1.648 (1.467)\tData 0.116 (0.166)\tLoss 4629.5488 (4022.2784)\t\n",
      "Epoch: [0][800/2191]\tTime 1.332 (1.464)\tData 0.116 (0.163)\tLoss 5496.8696 (4040.6998)\t\n",
      "Epoch: [0][850/2191]\tTime 1.326 (1.461)\tData 0.115 (0.161)\tLoss 4127.2266 (4061.8649)\t\n",
      "Epoch: [0][900/2191]\tTime 1.332 (1.459)\tData 0.118 (0.159)\tLoss 4689.7773 (4111.7801)\t\n",
      "Epoch: [0][950/2191]\tTime 1.327 (1.456)\tData 0.117 (0.157)\tLoss 3339.5996 (4108.8571)\t\n",
      "Epoch: [0][1000/2191]\tTime 1.440 (1.454)\tData 0.230 (0.155)\tLoss 3360.6841 (4103.7546)\t\n",
      "Epoch: [0][1050/2191]\tTime 1.497 (1.452)\tData 0.119 (0.154)\tLoss 3535.4827 (4080.7738)\t\n",
      "Epoch: [0][1100/2191]\tTime 1.871 (1.451)\tData 0.115 (0.152)\tLoss 3493.0063 (4064.2616)\t\n",
      "Epoch: [0][1150/2191]\tTime 1.328 (1.452)\tData 0.116 (0.151)\tLoss 2509.4917 (4017.2363)\t\n",
      "Epoch: [0][1200/2191]\tTime 1.329 (1.450)\tData 0.116 (0.150)\tLoss 2550.7954 (3959.7180)\t\n",
      "Epoch: [0][1250/2191]\tTime 1.328 (1.448)\tData 0.115 (0.149)\tLoss 2824.0913 (3913.2248)\t\n",
      "Epoch: [0][1300/2191]\tTime 1.330 (1.447)\tData 0.117 (0.148)\tLoss 2944.9697 (3886.1350)\t\n",
      "Epoch: [0][1350/2191]\tTime 1.328 (1.446)\tData 0.117 (0.147)\tLoss 3976.2422 (3901.1202)\t\n",
      "Epoch: [0][1400/2191]\tTime 1.329 (1.445)\tData 0.117 (0.146)\tLoss 4245.9180 (3915.4754)\t\n",
      "Epoch: [0][1450/2191]\tTime 1.627 (1.444)\tData 0.116 (0.145)\tLoss 5807.8345 (3961.1995)\t\n",
      "Epoch: [0][1500/2191]\tTime 1.330 (1.443)\tData 0.118 (0.145)\tLoss 5172.8208 (3999.5448)\t\n",
      "Epoch: [0][1550/2191]\tTime 1.326 (1.442)\tData 0.115 (0.144)\tLoss 4178.9028 (4014.7268)\t\n",
      "Epoch: [0][1600/2191]\tTime 1.332 (1.441)\tData 0.116 (0.143)\tLoss 2986.3052 (3996.1604)\t\n",
      "Epoch: [0][1650/2191]\tTime 1.334 (1.440)\tData 0.120 (0.143)\tLoss 3197.8267 (3968.8770)\t\n",
      "Epoch: [0][1700/2191]\tTime 1.328 (1.439)\tData 0.117 (0.142)\tLoss 3431.8765 (3960.7155)\t\n",
      "Epoch: [0][1750/2191]\tTime 1.327 (1.438)\tData 0.118 (0.141)\tLoss 6647.5581 (3983.4155)\t\n",
      "Epoch: [0][1800/2191]\tTime 1.795 (1.437)\tData 0.116 (0.141)\tLoss 3556.6626 (3988.3962)\t\n",
      "Epoch: [0][1850/2191]\tTime 1.327 (1.436)\tData 0.118 (0.140)\tLoss 4111.8223 (3989.9083)\t\n",
      "Epoch: [0][1900/2191]\tTime 1.326 (1.436)\tData 0.116 (0.140)\tLoss 3497.5498 (3992.7759)\t\n",
      "Epoch: [0][1950/2191]\tTime 1.391 (1.435)\tData 0.116 (0.139)\tLoss 3406.4653 (3983.5757)\t\n",
      "Epoch: [0][2000/2191]\tTime 1.326 (1.435)\tData 0.116 (0.139)\tLoss 2997.6611 (3954.3728)\t\n",
      "Epoch: [0][2050/2191]\tTime 1.326 (1.434)\tData 0.116 (0.139)\tLoss 2847.7644 (3924.8066)\t\n",
      "Epoch: [0][2100/2191]\tTime 1.329 (1.434)\tData 0.116 (0.138)\tLoss 3158.9941 (3896.4973)\t\n",
      "Epoch: [0][2150/2191]\tTime 1.885 (1.434)\tData 0.117 (0.138)\tLoss 3373.8035 (3885.2718)\t\n",
      "Epoch: [0][2190/2191]\tTime 1.319 (1.432)\tData 0.114 (0.137)\tLoss 4295.3047 (3886.8747)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3886.87468471205, 1.4323339348022168, 0.13734619381328741)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Keep the first layer of resnet frozen\n",
    "for i in range(0, 6):\n",
    "    for param in m.module.base_layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [8][0/10208]\tTime 15.876 (15.876)\tData 14.522 (14.522)\tLoss 249.2530 (249.2530)\t\n",
      "Epoch: [8][100/10208]\tTime 0.724 (0.927)\tData 0.026 (0.171)\tLoss 226.3943 (239.8907)\t\n",
      "Epoch: [8][200/10208]\tTime 0.724 (0.868)\tData 0.026 (0.099)\tLoss 228.6726 (235.6185)\t\n",
      "Epoch: [8][300/10208]\tTime 0.725 (0.838)\tData 0.026 (0.075)\tLoss 230.6595 (233.0092)\t\n",
      "Epoch: [8][400/10208]\tTime 0.725 (0.822)\tData 0.026 (0.063)\tLoss 225.4995 (231.3337)\t\n",
      "Epoch: [8][500/10208]\tTime 0.945 (0.813)\tData 0.026 (0.056)\tLoss 217.3611 (229.5482)\t\n",
      "Epoch: [8][600/10208]\tTime 0.730 (0.809)\tData 0.026 (0.051)\tLoss 215.5688 (228.3176)\t\n",
      "Epoch: [8][700/10208]\tTime 0.731 (0.803)\tData 0.026 (0.047)\tLoss 227.7986 (227.4418)\t\n",
      "Epoch: [8][800/10208]\tTime 0.763 (0.801)\tData 0.025 (0.045)\tLoss 213.1459 (226.4875)\t\n",
      "Epoch: [8][900/10208]\tTime 0.735 (0.798)\tData 0.026 (0.043)\tLoss 219.0038 (225.6315)\t\n",
      "Epoch: [8][1000/10208]\tTime 0.828 (0.797)\tData 0.027 (0.041)\tLoss 214.3507 (224.8640)\t\n",
      "Epoch: [8][1100/10208]\tTime 0.764 (0.795)\tData 0.026 (0.040)\tLoss 216.9480 (224.1786)\t\n",
      "Epoch: [8][1200/10208]\tTime 0.730 (0.794)\tData 0.026 (0.038)\tLoss 214.9810 (223.5560)\t\n",
      "Epoch: [8][1300/10208]\tTime 0.731 (0.793)\tData 0.026 (0.038)\tLoss 215.0019 (223.0380)\t\n",
      "Epoch: [8][1400/10208]\tTime 0.723 (0.792)\tData 0.026 (0.037)\tLoss 214.1169 (222.5656)\t\n",
      "Epoch: [8][1500/10208]\tTime 0.732 (0.791)\tData 0.031 (0.036)\tLoss 213.9513 (222.0694)\t\n",
      "Epoch: [8][1600/10208]\tTime 0.721 (0.791)\tData 0.025 (0.036)\tLoss 214.2951 (221.6406)\t\n",
      "Epoch: [8][1700/10208]\tTime 0.719 (0.789)\tData 0.025 (0.035)\tLoss 213.2403 (221.1817)\t\n",
      "Epoch: [8][1800/10208]\tTime 0.741 (0.789)\tData 0.025 (0.035)\tLoss 211.6469 (220.7740)\t\n",
      "Epoch: [8][1900/10208]\tTime 0.726 (0.790)\tData 0.026 (0.034)\tLoss 212.4401 (220.3683)\t\n",
      "Epoch: [8][2000/10208]\tTime 0.724 (0.789)\tData 0.026 (0.034)\tLoss 210.8373 (220.0111)\t\n",
      "Epoch: [8][2100/10208]\tTime 0.775 (0.789)\tData 0.026 (0.033)\tLoss 207.4935 (219.6337)\t\n",
      "Epoch: [8][2200/10208]\tTime 0.722 (0.788)\tData 0.026 (0.033)\tLoss 226.6856 (219.2375)\t\n",
      "Epoch: [8][2300/10208]\tTime 1.026 (0.788)\tData 0.026 (0.033)\tLoss 216.6130 (218.8646)\t\n",
      "Epoch: [8][2400/10208]\tTime 0.732 (0.787)\tData 0.026 (0.032)\tLoss 206.9584 (218.4892)\t\n",
      "Epoch: [8][2500/10208]\tTime 0.719 (0.787)\tData 0.026 (0.032)\tLoss 208.6935 (218.1409)\t\n",
      "Epoch: [8][2600/10208]\tTime 0.728 (0.787)\tData 0.026 (0.032)\tLoss 215.2119 (217.8056)\t\n",
      "Epoch: [8][2700/10208]\tTime 0.722 (0.787)\tData 0.026 (0.032)\tLoss 215.3140 (217.4571)\t\n",
      "Epoch: [8][2800/10208]\tTime 0.958 (0.786)\tData 0.026 (0.032)\tLoss 205.1694 (217.1159)\t\n",
      "Epoch: [8][2900/10208]\tTime 0.726 (0.786)\tData 0.026 (0.031)\tLoss 204.4731 (216.8068)\t\n",
      "Epoch: [8][3000/10208]\tTime 0.743 (0.786)\tData 0.026 (0.031)\tLoss 203.3296 (216.4730)\t\n",
      "Epoch: [8][3100/10208]\tTime 0.741 (0.786)\tData 0.026 (0.031)\tLoss 208.0750 (216.1520)\t\n",
      "Epoch: [8][3200/10208]\tTime 0.725 (0.786)\tData 0.026 (0.031)\tLoss 203.6534 (215.8418)\t\n",
      "Epoch: [8][3300/10208]\tTime 1.075 (0.785)\tData 0.025 (0.031)\tLoss 204.4516 (215.5240)\t\n",
      "Epoch: [8][3400/10208]\tTime 0.742 (0.785)\tData 0.026 (0.031)\tLoss 202.6559 (215.2260)\t\n",
      "Epoch: [8][3500/10208]\tTime 0.721 (0.785)\tData 0.026 (0.030)\tLoss 205.6062 (214.9209)\t\n",
      "Epoch: [8][3600/10208]\tTime 0.735 (0.785)\tData 0.026 (0.030)\tLoss 203.6159 (214.6293)\t\n",
      "Epoch: [8][3700/10208]\tTime 0.740 (0.785)\tData 0.026 (0.030)\tLoss 204.2769 (214.3432)\t\n",
      "Epoch: [8][3800/10208]\tTime 0.998 (0.785)\tData 0.026 (0.030)\tLoss 203.6842 (214.0739)\t\n",
      "Epoch: [8][3900/10208]\tTime 0.739 (0.786)\tData 0.025 (0.030)\tLoss 200.8877 (213.7986)\t\n",
      "Epoch: [8][4000/10208]\tTime 0.719 (0.786)\tData 0.026 (0.030)\tLoss 202.2376 (213.5388)\t\n",
      "Epoch: [8][4100/10208]\tTime 0.721 (0.786)\tData 0.026 (0.030)\tLoss 202.1030 (213.2834)\t\n",
      "Epoch: [8][4200/10208]\tTime 0.741 (0.785)\tData 0.026 (0.030)\tLoss 199.0893 (213.0399)\t\n",
      "Epoch: [8][4300/10208]\tTime 0.948 (0.785)\tData 0.026 (0.030)\tLoss 202.6512 (212.7943)\t\n",
      "Epoch: [8][4400/10208]\tTime 0.745 (0.785)\tData 0.025 (0.030)\tLoss 204.2480 (212.5468)\t\n",
      "Epoch: [8][4500/10208]\tTime 0.724 (0.785)\tData 0.026 (0.030)\tLoss 199.0702 (212.3100)\t\n",
      "Epoch: [8][4600/10208]\tTime 0.726 (0.785)\tData 0.025 (0.029)\tLoss 198.6762 (212.0734)\t\n",
      "Epoch: [8][4700/10208]\tTime 0.738 (0.785)\tData 0.026 (0.029)\tLoss 201.5613 (211.8396)\t\n",
      "Epoch: [8][4800/10208]\tTime 0.728 (0.785)\tData 0.026 (0.029)\tLoss 199.9654 (211.6088)\t\n",
      "Epoch: [8][4900/10208]\tTime 0.768 (0.785)\tData 0.026 (0.029)\tLoss 202.9591 (211.3728)\t\n",
      "Epoch: [8][5000/10208]\tTime 0.723 (0.785)\tData 0.026 (0.029)\tLoss 199.9518 (211.1494)\t\n",
      "Epoch: [8][5100/10208]\tTime 0.718 (0.785)\tData 0.025 (0.029)\tLoss 195.8548 (210.9264)\t\n",
      "Epoch: [8][5200/10208]\tTime 0.729 (0.785)\tData 0.027 (0.029)\tLoss 199.8792 (210.7144)\t\n",
      "Epoch: [8][5300/10208]\tTime 0.735 (0.785)\tData 0.026 (0.029)\tLoss 201.1843 (210.5080)\t\n",
      "Epoch: [8][5400/10208]\tTime 0.743 (0.785)\tData 0.026 (0.029)\tLoss 197.9231 (210.2965)\t\n",
      "Epoch: [8][5500/10208]\tTime 0.743 (0.784)\tData 0.026 (0.029)\tLoss 200.9580 (210.0926)\t\n",
      "Epoch: [8][5600/10208]\tTime 1.112 (0.785)\tData 0.025 (0.029)\tLoss 197.1993 (209.8899)\t\n",
      "Epoch: [8][5700/10208]\tTime 0.757 (0.784)\tData 0.026 (0.029)\tLoss 200.4429 (209.6931)\t\n",
      "Epoch: [8][5800/10208]\tTime 0.739 (0.784)\tData 0.026 (0.029)\tLoss 196.4659 (209.5111)\t\n",
      "Epoch: [8][5900/10208]\tTime 0.729 (0.784)\tData 0.026 (0.029)\tLoss 196.7360 (209.3135)\t\n",
      "Epoch: [8][6000/10208]\tTime 0.737 (0.784)\tData 0.026 (0.029)\tLoss 194.4576 (209.1197)\t\n",
      "Epoch: [8][6100/10208]\tTime 1.185 (0.784)\tData 0.025 (0.029)\tLoss 198.8813 (208.9306)\t\n",
      "Epoch: [8][6200/10208]\tTime 0.738 (0.784)\tData 0.027 (0.029)\tLoss 197.5040 (208.7522)\t\n",
      "Epoch: [8][6300/10208]\tTime 0.725 (0.784)\tData 0.026 (0.029)\tLoss 199.9526 (208.5710)\t\n",
      "Epoch: [8][6400/10208]\tTime 0.791 (0.784)\tData 0.026 (0.029)\tLoss 198.5169 (208.3981)\t\n",
      "Epoch: [8][6500/10208]\tTime 0.722 (0.784)\tData 0.025 (0.029)\tLoss 197.3369 (208.2301)\t\n",
      "Epoch: [8][6600/10208]\tTime 1.075 (0.784)\tData 0.026 (0.029)\tLoss 200.0426 (208.0551)\t\n",
      "Epoch: [8][6700/10208]\tTime 0.722 (0.784)\tData 0.025 (0.028)\tLoss 193.7620 (207.8877)\t\n",
      "Epoch: [8][6800/10208]\tTime 0.721 (0.784)\tData 0.026 (0.028)\tLoss 198.2970 (207.7243)\t\n",
      "Epoch: [8][6900/10208]\tTime 0.723 (0.784)\tData 0.026 (0.028)\tLoss 196.0794 (207.5642)\t\n",
      "Epoch: [8][7000/10208]\tTime 0.720 (0.784)\tData 0.026 (0.028)\tLoss 196.3806 (207.4045)\t\n",
      "Epoch: [8][7100/10208]\tTime 0.997 (0.784)\tData 0.026 (0.028)\tLoss 196.0526 (207.2433)\t\n",
      "Epoch: [8][7200/10208]\tTime 0.720 (0.784)\tData 0.025 (0.028)\tLoss 196.6785 (207.0830)\t\n",
      "Epoch: [8][7300/10208]\tTime 0.742 (0.784)\tData 0.026 (0.028)\tLoss 199.0551 (206.9274)\t\n",
      "Epoch: [8][7400/10208]\tTime 0.794 (0.784)\tData 0.025 (0.028)\tLoss 194.5904 (206.7733)\t\n",
      "Epoch: [8][7500/10208]\tTime 0.750 (0.784)\tData 0.025 (0.028)\tLoss 196.7428 (206.6183)\t\n",
      "Epoch: [8][7600/10208]\tTime 1.006 (0.784)\tData 0.025 (0.028)\tLoss 196.4235 (206.4667)\t\n",
      "Epoch: [8][7700/10208]\tTime 0.717 (0.784)\tData 0.025 (0.028)\tLoss 194.4672 (206.3144)\t\n",
      "Epoch: [8][7800/10208]\tTime 0.723 (0.784)\tData 0.025 (0.028)\tLoss 195.2974 (206.1684)\t\n",
      "Epoch: [8][7900/10208]\tTime 0.726 (0.784)\tData 0.026 (0.028)\tLoss 196.0379 (206.0219)\t\n",
      "Epoch: [8][8000/10208]\tTime 0.725 (0.784)\tData 0.026 (0.028)\tLoss 193.4372 (205.8809)\t\n",
      "Epoch: [8][8100/10208]\tTime 0.723 (0.783)\tData 0.026 (0.028)\tLoss 194.7960 (205.7425)\t\n",
      "Epoch: [8][8200/10208]\tTime 0.731 (0.783)\tData 0.025 (0.028)\tLoss 195.0406 (205.5983)\t\n",
      "Epoch: [8][8300/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 192.9784 (205.4587)\t\n",
      "Epoch: [8][8400/10208]\tTime 0.719 (0.783)\tData 0.025 (0.028)\tLoss 192.4614 (205.3225)\t\n",
      "Epoch: [8][8500/10208]\tTime 0.735 (0.783)\tData 0.030 (0.028)\tLoss 193.3683 (205.1923)\t\n",
      "Epoch: [8][8600/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 195.6608 (205.0626)\t\n",
      "Epoch: [8][8700/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 193.5585 (204.9336)\t\n",
      "Epoch: [8][8800/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 195.0495 (204.8023)\t\n",
      "Epoch: [8][8900/10208]\tTime 0.947 (0.783)\tData 0.026 (0.028)\tLoss 193.0100 (204.6713)\t\n",
      "Epoch: [8][9000/10208]\tTime 0.723 (0.783)\tData 0.026 (0.028)\tLoss 190.6499 (204.5414)\t\n",
      "Epoch: [8][9100/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 190.7654 (204.4097)\t\n",
      "Epoch: [8][9200/10208]\tTime 0.722 (0.783)\tData 0.026 (0.028)\tLoss 194.2304 (204.2829)\t\n",
      "Epoch: [8][9300/10208]\tTime 0.720 (0.783)\tData 0.026 (0.028)\tLoss 192.4631 (204.1625)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8][9400/10208]\tTime 1.091 (0.783)\tData 0.026 (0.028)\tLoss 192.3820 (204.0396)\t\n",
      "Epoch: [8][9500/10208]\tTime 0.723 (0.783)\tData 0.025 (0.028)\tLoss 191.7169 (203.9180)\t\n",
      "Epoch: [8][9600/10208]\tTime 0.725 (0.783)\tData 0.025 (0.028)\tLoss 193.7698 (203.7985)\t\n",
      "Epoch: [8][9700/10208]\tTime 0.752 (0.782)\tData 0.025 (0.028)\tLoss 190.5399 (203.6787)\t\n",
      "Epoch: [8][9800/10208]\tTime 0.734 (0.782)\tData 0.028 (0.028)\tLoss 190.5349 (203.5628)\t\n",
      "Epoch: [8][9900/10208]\tTime 0.976 (0.782)\tData 0.026 (0.028)\tLoss 192.0345 (203.4484)\t\n",
      "Epoch: [8][10000/10208]\tTime 0.724 (0.782)\tData 0.025 (0.028)\tLoss 192.9536 (203.3327)\t\n",
      "Epoch: [8][10100/10208]\tTime 0.722 (0.782)\tData 0.025 (0.028)\tLoss 193.9974 (203.2246)\t\n",
      "Epoch: [8][10200/10208]\tTime 0.728 (0.782)\tData 0.025 (0.028)\tLoss 192.5016 (203.1189)\t\n",
      "Epoch: [8][10207/10208]\tTime 0.719 (0.782)\tData 0.025 (0.028)\tLoss 193.5979 (203.1113)\t\n",
      "Start training\n",
      "Epoch: [9][0/10208]\tTime 14.806 (14.806)\tData 14.031 (14.031)\tLoss 191.3703 (191.3703)\t\n",
      "Epoch: [9][100/10208]\tTime 0.752 (0.914)\tData 0.026 (0.165)\tLoss 197.3606 (191.3204)\t\n",
      "Epoch: [9][200/10208]\tTime 0.724 (0.846)\tData 0.026 (0.096)\tLoss 189.6293 (191.4722)\t\n",
      "Epoch: [9][300/10208]\tTime 0.722 (0.821)\tData 0.025 (0.073)\tLoss 195.5923 (192.0064)\t\n",
      "Epoch: [9][400/10208]\tTime 0.724 (0.812)\tData 0.026 (0.061)\tLoss 192.1631 (192.4756)\t\n",
      "Epoch: [9][500/10208]\tTime 0.728 (0.805)\tData 0.025 (0.054)\tLoss 191.9819 (192.7251)\t\n",
      "Epoch: [9][600/10208]\tTime 0.747 (0.801)\tData 0.026 (0.049)\tLoss 192.3547 (192.8084)\t\n",
      "Epoch: [9][700/10208]\tTime 0.726 (0.797)\tData 0.026 (0.046)\tLoss 191.5167 (192.7563)\t\n",
      "Epoch: [9][800/10208]\tTime 0.716 (0.796)\tData 0.025 (0.044)\tLoss 192.0018 (192.7055)\t\n",
      "Epoch: [9][900/10208]\tTime 0.721 (0.793)\tData 0.026 (0.042)\tLoss 193.6330 (192.6947)\t\n",
      "Epoch: [9][1000/10208]\tTime 0.719 (0.792)\tData 0.025 (0.040)\tLoss 193.2007 (192.7520)\t\n",
      "Epoch: [9][1100/10208]\tTime 0.735 (0.790)\tData 0.025 (0.039)\tLoss 191.2812 (192.7475)\t\n",
      "Epoch: [9][1200/10208]\tTime 1.104 (0.790)\tData 0.025 (0.038)\tLoss 190.9961 (192.7149)\t\n",
      "Epoch: [9][1300/10208]\tTime 0.729 (0.789)\tData 0.025 (0.037)\tLoss 195.4513 (192.6988)\t\n",
      "Epoch: [9][1400/10208]\tTime 0.724 (0.788)\tData 0.026 (0.036)\tLoss 192.2104 (192.7220)\t\n",
      "Epoch: [9][1500/10208]\tTime 0.728 (0.787)\tData 0.025 (0.036)\tLoss 190.2453 (192.6897)\t\n",
      "Epoch: [9][1600/10208]\tTime 0.736 (0.787)\tData 0.026 (0.035)\tLoss 193.7014 (192.6801)\t\n",
      "Epoch: [9][1700/10208]\tTime 1.103 (0.786)\tData 0.025 (0.034)\tLoss 192.1089 (192.6517)\t\n",
      "Epoch: [9][1800/10208]\tTime 0.747 (0.786)\tData 0.026 (0.034)\tLoss 191.6646 (192.6103)\t\n",
      "Epoch: [9][1900/10208]\tTime 0.717 (0.785)\tData 0.025 (0.034)\tLoss 192.7479 (192.5670)\t\n",
      "Epoch: [9][2000/10208]\tTime 0.729 (0.785)\tData 0.025 (0.033)\tLoss 190.3953 (192.5027)\t\n",
      "Epoch: [9][2100/10208]\tTime 0.741 (0.785)\tData 0.026 (0.033)\tLoss 188.4005 (192.4505)\t\n",
      "Epoch: [9][2200/10208]\tTime 0.965 (0.785)\tData 0.025 (0.033)\tLoss 190.8894 (192.4095)\t\n",
      "Epoch: [9][2300/10208]\tTime 0.728 (0.784)\tData 0.025 (0.032)\tLoss 190.2460 (192.3379)\t\n",
      "Epoch: [9][2400/10208]\tTime 0.726 (0.784)\tData 0.026 (0.032)\tLoss 190.4787 (192.2769)\t\n",
      "Epoch: [9][2500/10208]\tTime 0.751 (0.784)\tData 0.026 (0.032)\tLoss 189.9164 (192.2108)\t\n",
      "Epoch: [9][2600/10208]\tTime 0.724 (0.784)\tData 0.025 (0.032)\tLoss 190.7844 (192.1410)\t\n",
      "Epoch: [9][2700/10208]\tTime 1.165 (0.784)\tData 0.026 (0.031)\tLoss 188.3305 (192.0728)\t\n",
      "Epoch: [9][2800/10208]\tTime 0.718 (0.783)\tData 0.026 (0.031)\tLoss 189.0480 (192.0081)\t\n",
      "Epoch: [9][2900/10208]\tTime 0.719 (0.783)\tData 0.026 (0.031)\tLoss 190.1492 (191.9414)\t\n",
      "Epoch: [9][3000/10208]\tTime 0.718 (0.783)\tData 0.026 (0.031)\tLoss 191.0855 (191.8937)\t\n",
      "Epoch: [9][3100/10208]\tTime 0.716 (0.783)\tData 0.025 (0.031)\tLoss 191.8468 (191.8282)\t\n",
      "Epoch: [9][3200/10208]\tTime 0.803 (0.783)\tData 0.026 (0.031)\tLoss 189.2101 (191.7652)\t\n",
      "Epoch: [9][3300/10208]\tTime 0.747 (0.783)\tData 0.025 (0.030)\tLoss 188.6721 (191.6947)\t\n",
      "Epoch: [9][3400/10208]\tTime 0.725 (0.782)\tData 0.025 (0.030)\tLoss 189.7319 (191.6282)\t\n",
      "Epoch: [9][3500/10208]\tTime 0.720 (0.782)\tData 0.025 (0.030)\tLoss 190.8549 (191.5757)\t\n",
      "Epoch: [9][3600/10208]\tTime 0.731 (0.782)\tData 0.026 (0.030)\tLoss 192.0099 (191.5080)\t\n",
      "Epoch: [9][3700/10208]\tTime 0.723 (0.782)\tData 0.025 (0.030)\tLoss 188.7705 (191.4393)\t\n",
      "Epoch: [9][3800/10208]\tTime 0.751 (0.781)\tData 0.026 (0.030)\tLoss 187.8372 (191.3817)\t\n",
      "Epoch: [9][3900/10208]\tTime 0.726 (0.781)\tData 0.026 (0.030)\tLoss 189.9795 (191.3220)\t\n",
      "Epoch: [9][4000/10208]\tTime 0.780 (0.781)\tData 0.047 (0.030)\tLoss 190.1209 (191.2614)\t\n",
      "Epoch: [9][4100/10208]\tTime 0.719 (0.781)\tData 0.025 (0.030)\tLoss 190.5730 (191.1972)\t\n",
      "Epoch: [9][4200/10208]\tTime 0.755 (0.781)\tData 0.026 (0.030)\tLoss 193.1637 (191.1391)\t\n",
      "Epoch: [9][4300/10208]\tTime 0.723 (0.781)\tData 0.025 (0.029)\tLoss 190.0203 (191.0863)\t\n",
      "Epoch: [9][4400/10208]\tTime 0.729 (0.781)\tData 0.026 (0.029)\tLoss 187.2817 (191.0246)\t\n",
      "Epoch: [9][4500/10208]\tTime 1.418 (0.781)\tData 0.027 (0.029)\tLoss 190.9694 (190.9629)\t\n",
      "Epoch: [9][4600/10208]\tTime 0.736 (0.781)\tData 0.026 (0.029)\tLoss 188.7581 (190.9031)\t\n",
      "Epoch: [9][4700/10208]\tTime 0.728 (0.781)\tData 0.026 (0.029)\tLoss 187.0585 (190.8490)\t\n",
      "Epoch: [9][4800/10208]\tTime 0.719 (0.781)\tData 0.025 (0.029)\tLoss 189.8124 (190.8048)\t\n",
      "Epoch: [9][4900/10208]\tTime 0.721 (0.780)\tData 0.025 (0.029)\tLoss 188.1334 (190.7546)\t\n",
      "Epoch: [9][5000/10208]\tTime 1.167 (0.780)\tData 0.026 (0.029)\tLoss 188.3632 (190.7120)\t\n",
      "Epoch: [9][5100/10208]\tTime 0.744 (0.780)\tData 0.026 (0.029)\tLoss 187.9663 (190.6637)\t\n",
      "Epoch: [9][5200/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 186.6773 (190.6248)\t\n",
      "Epoch: [9][5300/10208]\tTime 0.717 (0.780)\tData 0.025 (0.029)\tLoss 187.5900 (190.5728)\t\n",
      "Epoch: [9][5400/10208]\tTime 0.722 (0.780)\tData 0.025 (0.029)\tLoss 190.7677 (190.5214)\t\n",
      "Epoch: [9][5500/10208]\tTime 0.992 (0.780)\tData 0.025 (0.029)\tLoss 187.7137 (190.4771)\t\n",
      "Epoch: [9][5600/10208]\tTime 0.727 (0.779)\tData 0.025 (0.029)\tLoss 187.7787 (190.4302)\t\n",
      "Epoch: [9][5700/10208]\tTime 0.722 (0.779)\tData 0.025 (0.029)\tLoss 188.3557 (190.3819)\t\n",
      "Epoch: [9][5800/10208]\tTime 0.801 (0.779)\tData 0.057 (0.029)\tLoss 188.3476 (190.3347)\t\n",
      "Epoch: [9][5900/10208]\tTime 0.725 (0.779)\tData 0.025 (0.029)\tLoss 188.6592 (190.2871)\t\n",
      "Epoch: [9][6000/10208]\tTime 1.095 (0.779)\tData 0.032 (0.029)\tLoss 187.7624 (190.2402)\t\n",
      "Epoch: [9][6100/10208]\tTime 0.718 (0.779)\tData 0.025 (0.029)\tLoss 188.3970 (190.1914)\t\n",
      "Epoch: [9][6200/10208]\tTime 0.721 (0.779)\tData 0.025 (0.028)\tLoss 185.7036 (190.1466)\t\n",
      "Epoch: [9][6300/10208]\tTime 0.754 (0.779)\tData 0.057 (0.028)\tLoss 187.1297 (190.1000)\t\n",
      "Epoch: [9][6400/10208]\tTime 0.731 (0.779)\tData 0.026 (0.028)\tLoss 189.3005 (190.0574)\t\n",
      "Epoch: [9][6500/10208]\tTime 0.894 (0.778)\tData 0.025 (0.028)\tLoss 187.0931 (190.0087)\t\n",
      "Epoch: [9][6600/10208]\tTime 0.742 (0.778)\tData 0.044 (0.028)\tLoss 187.1138 (189.9613)\t\n",
      "Epoch: [9][6700/10208]\tTime 0.722 (0.778)\tData 0.026 (0.028)\tLoss 187.8537 (189.9127)\t\n",
      "Epoch: [9][6800/10208]\tTime 0.724 (0.778)\tData 0.026 (0.028)\tLoss 185.6829 (189.8663)\t\n",
      "Epoch: [9][6900/10208]\tTime 0.723 (0.778)\tData 0.025 (0.028)\tLoss 186.6569 (189.8200)\t\n",
      "Epoch: [9][7000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 185.2814 (189.7750)\t\n",
      "Epoch: [9][7100/10208]\tTime 0.726 (0.778)\tData 0.025 (0.028)\tLoss 183.1530 (189.7302)\t\n",
      "Epoch: [9][7200/10208]\tTime 0.723 (0.778)\tData 0.025 (0.028)\tLoss 188.5643 (189.6838)\t\n",
      "Epoch: [9][7300/10208]\tTime 0.727 (0.778)\tData 0.027 (0.028)\tLoss 186.7599 (189.6357)\t\n",
      "Epoch: [9][7400/10208]\tTime 0.741 (0.778)\tData 0.025 (0.028)\tLoss 187.2076 (189.5865)\t\n",
      "Epoch: [9][7500/10208]\tTime 0.725 (0.778)\tData 0.026 (0.028)\tLoss 185.8221 (189.5370)\t\n",
      "Epoch: [9][7600/10208]\tTime 0.726 (0.778)\tData 0.026 (0.028)\tLoss 186.4512 (189.4895)\t\n",
      "Epoch: [9][7700/10208]\tTime 0.717 (0.778)\tData 0.026 (0.028)\tLoss 185.1730 (189.4391)\t\n",
      "Epoch: [9][7800/10208]\tTime 1.095 (0.778)\tData 0.026 (0.028)\tLoss 186.5482 (189.3890)\t\n",
      "Epoch: [9][7900/10208]\tTime 0.727 (0.778)\tData 0.026 (0.028)\tLoss 184.2109 (189.3411)\t\n",
      "Epoch: [9][8000/10208]\tTime 0.721 (0.778)\tData 0.026 (0.028)\tLoss 183.5361 (189.2937)\t\n",
      "Epoch: [9][8100/10208]\tTime 0.741 (0.778)\tData 0.025 (0.028)\tLoss 184.2634 (189.2430)\t\n",
      "Epoch: [9][8200/10208]\tTime 0.725 (0.778)\tData 0.025 (0.028)\tLoss 183.2551 (189.1973)\t\n",
      "Epoch: [9][8300/10208]\tTime 1.058 (0.778)\tData 0.025 (0.028)\tLoss 185.1745 (189.1476)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][8400/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 186.1743 (189.0974)\t\n",
      "Epoch: [9][8500/10208]\tTime 0.737 (0.778)\tData 0.025 (0.028)\tLoss 185.1117 (189.0482)\t\n",
      "Epoch: [9][8600/10208]\tTime 0.739 (0.778)\tData 0.025 (0.028)\tLoss 183.8793 (189.0015)\t\n",
      "Epoch: [9][8700/10208]\tTime 0.757 (0.778)\tData 0.026 (0.028)\tLoss 186.3570 (188.9567)\t\n",
      "Epoch: [9][8800/10208]\tTime 1.146 (0.778)\tData 0.026 (0.028)\tLoss 184.0963 (188.9085)\t\n",
      "Epoch: [9][8900/10208]\tTime 0.730 (0.778)\tData 0.025 (0.028)\tLoss 187.3147 (188.8627)\t\n",
      "Epoch: [9][9000/10208]\tTime 0.758 (0.778)\tData 0.026 (0.028)\tLoss 184.9234 (188.8192)\t\n",
      "Epoch: [9][9100/10208]\tTime 0.776 (0.778)\tData 0.050 (0.028)\tLoss 185.4924 (188.7735)\t\n",
      "Epoch: [9][9200/10208]\tTime 0.747 (0.778)\tData 0.025 (0.028)\tLoss 184.0836 (188.7268)\t\n",
      "Epoch: [9][9300/10208]\tTime 1.078 (0.778)\tData 0.025 (0.028)\tLoss 183.1010 (188.6787)\t\n",
      "Epoch: [9][9400/10208]\tTime 0.727 (0.778)\tData 0.026 (0.028)\tLoss 182.8998 (188.6328)\t\n",
      "Epoch: [9][9500/10208]\tTime 0.722 (0.778)\tData 0.025 (0.028)\tLoss 185.6563 (188.5859)\t\n",
      "Epoch: [9][9600/10208]\tTime 0.762 (0.778)\tData 0.025 (0.028)\tLoss 184.2025 (188.5407)\t\n",
      "Epoch: [9][9700/10208]\tTime 0.729 (0.778)\tData 0.025 (0.028)\tLoss 183.3493 (188.4933)\t\n",
      "Epoch: [9][9800/10208]\tTime 0.889 (0.778)\tData 0.026 (0.028)\tLoss 184.4734 (188.4455)\t\n",
      "Epoch: [9][9900/10208]\tTime 0.719 (0.778)\tData 0.026 (0.028)\tLoss 183.9424 (188.3998)\t\n",
      "Epoch: [9][10000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 185.2249 (188.3562)\t\n",
      "Epoch: [9][10100/10208]\tTime 0.740 (0.778)\tData 0.025 (0.028)\tLoss 184.9535 (188.3111)\t\n",
      "Epoch: [9][10200/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 183.5963 (188.2687)\t\n",
      "Epoch: [9][10207/10208]\tTime 0.722 (0.778)\tData 0.025 (0.028)\tLoss 181.9144 (188.2650)\t\n",
      "Start training\n",
      "Epoch: [10][0/10208]\tTime 13.177 (13.177)\tData 12.249 (12.249)\tLoss 181.1674 (181.1674)\t\n",
      "Epoch: [10][100/10208]\tTime 0.730 (0.921)\tData 0.025 (0.165)\tLoss 184.0956 (183.6157)\t\n",
      "Epoch: [10][200/10208]\tTime 0.725 (0.851)\tData 0.026 (0.096)\tLoss 183.6035 (183.5457)\t\n",
      "Epoch: [10][300/10208]\tTime 0.729 (0.826)\tData 0.025 (0.073)\tLoss 181.6922 (183.5554)\t\n",
      "Epoch: [10][400/10208]\tTime 0.725 (0.813)\tData 0.026 (0.061)\tLoss 181.7043 (183.5550)\t\n",
      "Epoch: [10][500/10208]\tTime 0.733 (0.807)\tData 0.026 (0.054)\tLoss 184.1122 (183.5313)\t\n",
      "Epoch: [10][600/10208]\tTime 0.961 (0.803)\tData 0.025 (0.050)\tLoss 183.5566 (183.5123)\t\n",
      "Epoch: [10][700/10208]\tTime 0.715 (0.799)\tData 0.026 (0.046)\tLoss 181.3202 (183.4931)\t\n",
      "Epoch: [10][800/10208]\tTime 0.754 (0.796)\tData 0.026 (0.044)\tLoss 183.0740 (183.4806)\t\n",
      "Epoch: [10][900/10208]\tTime 0.718 (0.795)\tData 0.025 (0.042)\tLoss 182.4442 (183.4615)\t\n",
      "Epoch: [10][1000/10208]\tTime 0.733 (0.794)\tData 0.026 (0.040)\tLoss 183.7027 (183.4211)\t\n",
      "Epoch: [10][1100/10208]\tTime 1.123 (0.792)\tData 0.026 (0.039)\tLoss 184.2478 (183.3769)\t\n",
      "Epoch: [10][1200/10208]\tTime 0.728 (0.791)\tData 0.026 (0.038)\tLoss 183.1911 (183.3269)\t\n",
      "Epoch: [10][1300/10208]\tTime 0.736 (0.789)\tData 0.026 (0.037)\tLoss 183.6220 (183.3069)\t\n",
      "Epoch: [10][1400/10208]\tTime 0.763 (0.790)\tData 0.026 (0.036)\tLoss 184.1052 (183.2612)\t\n",
      "Epoch: [10][1500/10208]\tTime 0.726 (0.789)\tData 0.026 (0.036)\tLoss 182.5737 (183.2397)\t\n",
      "Epoch: [10][1600/10208]\tTime 1.110 (0.788)\tData 0.026 (0.035)\tLoss 180.1198 (183.1972)\t\n",
      "Epoch: [10][1700/10208]\tTime 0.739 (0.788)\tData 0.025 (0.035)\tLoss 182.7039 (183.1662)\t\n",
      "Epoch: [10][1800/10208]\tTime 0.726 (0.787)\tData 0.026 (0.034)\tLoss 180.9950 (183.1268)\t\n",
      "Epoch: [10][1900/10208]\tTime 0.730 (0.787)\tData 0.026 (0.034)\tLoss 182.8964 (183.1073)\t\n",
      "Epoch: [10][2000/10208]\tTime 0.735 (0.787)\tData 0.026 (0.033)\tLoss 182.1076 (183.0721)\t\n",
      "Epoch: [10][2100/10208]\tTime 1.128 (0.787)\tData 0.025 (0.033)\tLoss 183.5224 (183.0378)\t\n",
      "Epoch: [10][2200/10208]\tTime 0.719 (0.787)\tData 0.025 (0.033)\tLoss 182.4821 (183.0090)\t\n",
      "Epoch: [10][2300/10208]\tTime 0.726 (0.787)\tData 0.025 (0.032)\tLoss 183.0321 (182.9844)\t\n",
      "Epoch: [10][2400/10208]\tTime 0.730 (0.786)\tData 0.025 (0.032)\tLoss 182.7594 (182.9550)\t\n",
      "Epoch: [10][2500/10208]\tTime 0.726 (0.786)\tData 0.026 (0.032)\tLoss 181.7401 (182.9271)\t\n",
      "Epoch: [10][2600/10208]\tTime 0.841 (0.786)\tData 0.026 (0.032)\tLoss 181.4953 (182.8972)\t\n",
      "Epoch: [10][2700/10208]\tTime 0.736 (0.785)\tData 0.026 (0.032)\tLoss 179.8018 (182.8680)\t\n",
      "Epoch: [10][2800/10208]\tTime 0.729 (0.785)\tData 0.026 (0.031)\tLoss 182.9146 (182.8355)\t\n",
      "Epoch: [10][2900/10208]\tTime 0.726 (0.784)\tData 0.026 (0.031)\tLoss 182.7044 (182.8020)\t\n",
      "Epoch: [10][3000/10208]\tTime 0.726 (0.784)\tData 0.025 (0.031)\tLoss 182.2262 (182.7653)\t\n",
      "Epoch: [10][3100/10208]\tTime 0.801 (0.784)\tData 0.026 (0.031)\tLoss 182.9261 (182.7286)\t\n",
      "Epoch: [10][3200/10208]\tTime 0.726 (0.783)\tData 0.026 (0.031)\tLoss 182.7259 (182.6912)\t\n",
      "Epoch: [10][3300/10208]\tTime 0.727 (0.783)\tData 0.026 (0.031)\tLoss 181.5580 (182.6573)\t\n",
      "Epoch: [10][3400/10208]\tTime 0.716 (0.783)\tData 0.025 (0.030)\tLoss 181.0339 (182.6220)\t\n",
      "Epoch: [10][3500/10208]\tTime 0.717 (0.782)\tData 0.026 (0.030)\tLoss 182.0908 (182.5803)\t\n",
      "Epoch: [10][3600/10208]\tTime 0.731 (0.782)\tData 0.026 (0.030)\tLoss 182.6575 (182.5480)\t\n",
      "Epoch: [10][3700/10208]\tTime 0.725 (0.782)\tData 0.026 (0.030)\tLoss 180.6142 (182.5072)\t\n",
      "Epoch: [10][3800/10208]\tTime 0.748 (0.781)\tData 0.026 (0.030)\tLoss 181.5370 (182.4714)\t\n",
      "Epoch: [10][3900/10208]\tTime 1.186 (0.781)\tData 0.026 (0.030)\tLoss 179.2042 (182.4356)\t\n",
      "Epoch: [10][4000/10208]\tTime 0.739 (0.781)\tData 0.026 (0.030)\tLoss 180.6732 (182.3988)\t\n",
      "Epoch: [10][4100/10208]\tTime 0.737 (0.781)\tData 0.026 (0.030)\tLoss 179.7942 (182.3627)\t\n",
      "Epoch: [10][4200/10208]\tTime 0.746 (0.781)\tData 0.026 (0.030)\tLoss 180.5851 (182.3233)\t\n",
      "Epoch: [10][4300/10208]\tTime 0.728 (0.781)\tData 0.026 (0.030)\tLoss 180.2126 (182.2864)\t\n",
      "Epoch: [10][4400/10208]\tTime 1.053 (0.781)\tData 0.026 (0.029)\tLoss 182.6833 (182.2514)\t\n",
      "Epoch: [10][4500/10208]\tTime 0.720 (0.780)\tData 0.025 (0.029)\tLoss 180.7846 (182.2193)\t\n",
      "Epoch: [10][4600/10208]\tTime 0.724 (0.780)\tData 0.026 (0.029)\tLoss 179.9304 (182.1824)\t\n",
      "Epoch: [10][4700/10208]\tTime 0.725 (0.780)\tData 0.026 (0.029)\tLoss 180.0168 (182.1450)\t\n",
      "Epoch: [10][4800/10208]\tTime 0.722 (0.780)\tData 0.026 (0.029)\tLoss 181.8445 (182.1073)\t\n",
      "Epoch: [10][4900/10208]\tTime 1.123 (0.780)\tData 0.026 (0.029)\tLoss 178.5078 (182.0734)\t\n",
      "Epoch: [10][5000/10208]\tTime 0.731 (0.780)\tData 0.026 (0.029)\tLoss 180.4199 (182.0392)\t\n",
      "Epoch: [10][5100/10208]\tTime 0.744 (0.780)\tData 0.026 (0.029)\tLoss 178.9027 (182.0042)\t\n",
      "Epoch: [10][5200/10208]\tTime 0.722 (0.780)\tData 0.026 (0.029)\tLoss 180.0319 (181.9679)\t\n",
      "Epoch: [10][5300/10208]\tTime 0.732 (0.780)\tData 0.026 (0.029)\tLoss 177.4579 (181.9346)\t\n",
      "Epoch: [10][5400/10208]\tTime 1.080 (0.780)\tData 0.026 (0.029)\tLoss 179.1831 (181.8997)\t\n",
      "Epoch: [10][5500/10208]\tTime 0.748 (0.780)\tData 0.026 (0.029)\tLoss 180.7704 (181.8640)\t\n",
      "Epoch: [10][5600/10208]\tTime 0.724 (0.779)\tData 0.026 (0.029)\tLoss 179.0858 (181.8294)\t\n",
      "Epoch: [10][5700/10208]\tTime 0.745 (0.779)\tData 0.026 (0.029)\tLoss 179.0836 (181.7949)\t\n",
      "Epoch: [10][5800/10208]\tTime 0.734 (0.779)\tData 0.026 (0.029)\tLoss 182.2687 (181.7612)\t\n",
      "Epoch: [10][5900/10208]\tTime 0.787 (0.779)\tData 0.026 (0.029)\tLoss 179.0274 (181.7285)\t\n",
      "Epoch: [10][6000/10208]\tTime 0.747 (0.779)\tData 0.026 (0.029)\tLoss 180.3345 (181.6946)\t\n",
      "Epoch: [10][6100/10208]\tTime 0.720 (0.779)\tData 0.026 (0.029)\tLoss 180.8109 (181.6642)\t\n",
      "Epoch: [10][6200/10208]\tTime 0.734 (0.779)\tData 0.026 (0.029)\tLoss 176.6908 (181.6326)\t\n",
      "Epoch: [10][6300/10208]\tTime 0.726 (0.779)\tData 0.026 (0.028)\tLoss 179.2183 (181.6002)\t\n",
      "Epoch: [10][6400/10208]\tTime 0.741 (0.779)\tData 0.026 (0.028)\tLoss 179.4719 (181.5703)\t\n",
      "Epoch: [10][6500/10208]\tTime 0.741 (0.779)\tData 0.033 (0.028)\tLoss 179.7327 (181.5372)\t\n",
      "Epoch: [10][6600/10208]\tTime 0.734 (0.779)\tData 0.025 (0.028)\tLoss 178.7526 (181.5047)\t\n",
      "Epoch: [10][6700/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 179.6098 (181.4786)\t\n",
      "Epoch: [10][6800/10208]\tTime 0.732 (0.779)\tData 0.026 (0.028)\tLoss 179.7640 (181.4520)\t\n",
      "Epoch: [10][6900/10208]\tTime 0.751 (0.779)\tData 0.026 (0.028)\tLoss 178.4709 (181.4255)\t\n",
      "Epoch: [10][7000/10208]\tTime 0.720 (0.779)\tData 0.026 (0.028)\tLoss 179.7753 (181.3951)\t\n",
      "Epoch: [10][7100/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 179.4198 (181.3661)\t\n",
      "Epoch: [10][7200/10208]\tTime 1.054 (0.779)\tData 0.026 (0.028)\tLoss 179.2332 (181.3390)\t\n",
      "Epoch: [10][7300/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 178.4638 (181.3088)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10][7400/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 179.0836 (181.2811)\t\n",
      "Epoch: [10][7500/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 181.0837 (181.2523)\t\n",
      "Epoch: [10][7600/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 177.7071 (181.2237)\t\n",
      "Epoch: [10][7700/10208]\tTime 1.115 (0.779)\tData 0.026 (0.028)\tLoss 177.9585 (181.1977)\t\n",
      "Epoch: [10][7800/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 177.7560 (181.1708)\t\n",
      "Epoch: [10][7900/10208]\tTime 0.722 (0.779)\tData 0.027 (0.028)\tLoss 176.2551 (181.1457)\t\n",
      "Epoch: [10][8000/10208]\tTime 0.730 (0.779)\tData 0.025 (0.028)\tLoss 179.4148 (181.1177)\t\n",
      "Epoch: [10][8100/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 181.2314 (181.0873)\t\n",
      "Epoch: [10][8200/10208]\tTime 1.095 (0.779)\tData 0.030 (0.028)\tLoss 178.5480 (181.0590)\t\n",
      "Epoch: [10][8300/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 178.9069 (181.0326)\t\n",
      "Epoch: [10][8400/10208]\tTime 0.740 (0.779)\tData 0.026 (0.028)\tLoss 181.1436 (181.0055)\t\n",
      "Epoch: [10][8500/10208]\tTime 0.736 (0.779)\tData 0.026 (0.028)\tLoss 177.9182 (180.9779)\t\n",
      "Epoch: [10][8600/10208]\tTime 0.734 (0.779)\tData 0.025 (0.028)\tLoss 179.2167 (180.9532)\t\n",
      "Epoch: [10][8700/10208]\tTime 1.001 (0.779)\tData 0.026 (0.028)\tLoss 178.0180 (180.9288)\t\n",
      "Epoch: [10][8800/10208]\tTime 0.783 (0.779)\tData 0.026 (0.028)\tLoss 179.7997 (180.9036)\t\n",
      "Epoch: [10][8900/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 178.4758 (180.8756)\t\n",
      "Epoch: [10][9000/10208]\tTime 0.768 (0.779)\tData 0.026 (0.028)\tLoss 179.1135 (180.8512)\t\n",
      "Epoch: [10][9100/10208]\tTime 0.728 (0.779)\tData 0.026 (0.028)\tLoss 176.3337 (180.8295)\t\n",
      "Epoch: [10][9200/10208]\tTime 0.829 (0.779)\tData 0.026 (0.028)\tLoss 179.0314 (180.8047)\t\n",
      "Epoch: [10][9300/10208]\tTime 0.766 (0.779)\tData 0.026 (0.028)\tLoss 176.4290 (180.7806)\t\n",
      "Epoch: [10][9400/10208]\tTime 0.719 (0.779)\tData 0.026 (0.028)\tLoss 180.8043 (180.7563)\t\n",
      "Epoch: [10][9500/10208]\tTime 0.729 (0.779)\tData 0.026 (0.028)\tLoss 179.7935 (180.7331)\t\n",
      "Epoch: [10][9600/10208]\tTime 0.725 (0.779)\tData 0.026 (0.028)\tLoss 177.4514 (180.7129)\t\n",
      "Epoch: [10][9700/10208]\tTime 0.714 (0.779)\tData 0.025 (0.028)\tLoss 179.0110 (180.6890)\t\n",
      "Epoch: [10][9800/10208]\tTime 0.745 (0.779)\tData 0.026 (0.028)\tLoss 176.7977 (180.6673)\t\n",
      "Epoch: [10][9900/10208]\tTime 0.735 (0.779)\tData 0.026 (0.028)\tLoss 178.3997 (180.6445)\t\n",
      "Epoch: [10][10000/10208]\tTime 0.737 (0.779)\tData 0.025 (0.028)\tLoss 178.7107 (180.6224)\t\n",
      "Epoch: [10][10100/10208]\tTime 0.726 (0.779)\tData 0.026 (0.028)\tLoss 179.0269 (180.6033)\t\n",
      "Epoch: [10][10200/10208]\tTime 0.731 (0.778)\tData 0.025 (0.028)\tLoss 179.6954 (180.5846)\t\n",
      "Epoch: [10][10207/10208]\tTime 0.725 (0.778)\tData 0.028 (0.028)\tLoss 180.0465 (180.5831)\t\n",
      "Start training\n",
      "Epoch: [11][0/10208]\tTime 14.143 (14.143)\tData 12.906 (12.906)\tLoss 177.3957 (177.3957)\t\n",
      "Epoch: [11][100/10208]\tTime 0.717 (0.972)\tData 0.026 (0.203)\tLoss 177.6429 (178.4888)\t\n",
      "Epoch: [11][200/10208]\tTime 0.720 (0.873)\tData 0.025 (0.115)\tLoss 179.0472 (178.4501)\t\n",
      "Epoch: [11][300/10208]\tTime 0.755 (0.843)\tData 0.026 (0.086)\tLoss 178.3889 (178.3673)\t\n",
      "Epoch: [11][400/10208]\tTime 0.730 (0.825)\tData 0.026 (0.071)\tLoss 177.2247 (178.3527)\t\n",
      "Epoch: [11][500/10208]\tTime 1.085 (0.815)\tData 0.026 (0.062)\tLoss 178.3912 (178.3285)\t\n",
      "Epoch: [11][600/10208]\tTime 0.730 (0.807)\tData 0.026 (0.056)\tLoss 177.2269 (178.3055)\t\n",
      "Epoch: [11][700/10208]\tTime 0.722 (0.803)\tData 0.025 (0.052)\tLoss 177.0680 (178.3010)\t\n",
      "Epoch: [11][800/10208]\tTime 0.772 (0.800)\tData 0.026 (0.048)\tLoss 178.6147 (178.3193)\t\n",
      "Epoch: [11][900/10208]\tTime 0.728 (0.797)\tData 0.026 (0.046)\tLoss 178.4197 (178.2795)\t\n",
      "Epoch: [11][1000/10208]\tTime 1.203 (0.795)\tData 0.025 (0.044)\tLoss 179.5814 (178.2646)\t\n",
      "Epoch: [11][1100/10208]\tTime 0.715 (0.793)\tData 0.025 (0.042)\tLoss 176.3120 (178.2681)\t\n",
      "Epoch: [11][1200/10208]\tTime 0.728 (0.791)\tData 0.025 (0.041)\tLoss 177.0054 (178.2604)\t\n",
      "Epoch: [11][1300/10208]\tTime 0.735 (0.790)\tData 0.026 (0.040)\tLoss 178.4621 (178.2543)\t\n",
      "Epoch: [11][1400/10208]\tTime 0.723 (0.789)\tData 0.026 (0.039)\tLoss 179.3091 (178.2548)\t\n",
      "Epoch: [11][1500/10208]\tTime 0.784 (0.789)\tData 0.025 (0.038)\tLoss 180.5613 (178.2461)\t\n",
      "Epoch: [11][1600/10208]\tTime 0.720 (0.788)\tData 0.026 (0.037)\tLoss 177.1686 (178.2256)\t\n",
      "Epoch: [11][1700/10208]\tTime 0.741 (0.787)\tData 0.026 (0.037)\tLoss 177.9539 (178.2113)\t\n",
      "Epoch: [11][1800/10208]\tTime 0.723 (0.786)\tData 0.026 (0.036)\tLoss 179.4633 (178.2117)\t\n",
      "Epoch: [11][1900/10208]\tTime 0.726 (0.786)\tData 0.025 (0.036)\tLoss 177.8961 (178.2221)\t\n",
      "Epoch: [11][2000/10208]\tTime 0.724 (0.785)\tData 0.026 (0.035)\tLoss 180.7272 (178.2135)\t\n",
      "Epoch: [11][2100/10208]\tTime 0.755 (0.785)\tData 0.026 (0.035)\tLoss 176.2382 (178.2077)\t\n",
      "Epoch: [11][2200/10208]\tTime 0.724 (0.784)\tData 0.025 (0.034)\tLoss 178.1056 (178.1992)\t\n",
      "Epoch: [11][2300/10208]\tTime 0.724 (0.784)\tData 0.026 (0.034)\tLoss 178.4286 (178.2008)\t\n",
      "Epoch: [11][2400/10208]\tTime 0.722 (0.784)\tData 0.025 (0.034)\tLoss 177.5340 (178.2002)\t\n",
      "Epoch: [11][2500/10208]\tTime 0.722 (0.783)\tData 0.026 (0.033)\tLoss 177.1775 (178.1937)\t\n",
      "Epoch: [11][2600/10208]\tTime 0.750 (0.783)\tData 0.055 (0.033)\tLoss 176.6911 (178.1825)\t\n",
      "Epoch: [11][2700/10208]\tTime 0.720 (0.783)\tData 0.026 (0.033)\tLoss 179.1633 (178.1886)\t\n",
      "Epoch: [11][2800/10208]\tTime 1.096 (0.783)\tData 0.026 (0.033)\tLoss 179.7262 (178.1806)\t\n",
      "Epoch: [11][2900/10208]\tTime 0.720 (0.783)\tData 0.025 (0.032)\tLoss 179.1172 (178.1788)\t\n",
      "Epoch: [11][3000/10208]\tTime 0.722 (0.782)\tData 0.025 (0.032)\tLoss 177.8023 (178.1670)\t\n",
      "Epoch: [11][3100/10208]\tTime 0.749 (0.782)\tData 0.026 (0.032)\tLoss 176.3862 (178.1551)\t\n",
      "Epoch: [11][3200/10208]\tTime 0.720 (0.782)\tData 0.025 (0.032)\tLoss 178.9493 (178.1478)\t\n",
      "Epoch: [11][3300/10208]\tTime 1.073 (0.782)\tData 0.026 (0.032)\tLoss 176.8415 (178.1381)\t\n",
      "Epoch: [11][3400/10208]\tTime 0.723 (0.782)\tData 0.026 (0.032)\tLoss 175.3427 (178.1374)\t\n",
      "Epoch: [11][3500/10208]\tTime 0.722 (0.782)\tData 0.025 (0.031)\tLoss 178.8408 (178.1350)\t\n",
      "Epoch: [11][3600/10208]\tTime 0.738 (0.782)\tData 0.026 (0.031)\tLoss 177.9599 (178.1300)\t\n",
      "Epoch: [11][3700/10208]\tTime 0.728 (0.782)\tData 0.025 (0.031)\tLoss 179.2062 (178.1239)\t\n",
      "Epoch: [11][3800/10208]\tTime 1.087 (0.781)\tData 0.026 (0.031)\tLoss 177.5734 (178.1166)\t\n",
      "Epoch: [11][3900/10208]\tTime 0.719 (0.781)\tData 0.025 (0.031)\tLoss 176.6380 (178.1096)\t\n",
      "Epoch: [11][4000/10208]\tTime 0.717 (0.781)\tData 0.025 (0.031)\tLoss 175.9109 (178.1033)\t\n",
      "Epoch: [11][4100/10208]\tTime 0.755 (0.781)\tData 0.025 (0.031)\tLoss 178.2328 (178.1012)\t\n",
      "Epoch: [11][4200/10208]\tTime 0.738 (0.781)\tData 0.026 (0.031)\tLoss 176.2520 (178.0944)\t\n",
      "Epoch: [11][4300/10208]\tTime 1.133 (0.781)\tData 0.025 (0.030)\tLoss 177.7106 (178.0796)\t\n",
      "Epoch: [11][4400/10208]\tTime 0.721 (0.781)\tData 0.025 (0.030)\tLoss 179.1619 (178.0775)\t\n",
      "Epoch: [11][4500/10208]\tTime 0.714 (0.781)\tData 0.025 (0.030)\tLoss 175.0047 (178.0713)\t\n",
      "Epoch: [11][4600/10208]\tTime 0.731 (0.781)\tData 0.026 (0.030)\tLoss 177.7371 (178.0679)\t\n",
      "Epoch: [11][4700/10208]\tTime 0.722 (0.780)\tData 0.025 (0.030)\tLoss 178.7379 (178.0604)\t\n",
      "Epoch: [11][4800/10208]\tTime 0.864 (0.780)\tData 0.026 (0.030)\tLoss 176.9563 (178.0609)\t\n",
      "Epoch: [11][4900/10208]\tTime 0.719 (0.780)\tData 0.026 (0.030)\tLoss 181.6282 (178.0588)\t\n",
      "Epoch: [11][5000/10208]\tTime 0.724 (0.780)\tData 0.026 (0.030)\tLoss 176.3625 (178.0524)\t\n",
      "Epoch: [11][5100/10208]\tTime 0.733 (0.780)\tData 0.025 (0.030)\tLoss 177.0044 (178.0440)\t\n",
      "Epoch: [11][5200/10208]\tTime 0.725 (0.780)\tData 0.025 (0.030)\tLoss 181.9641 (178.0416)\t\n",
      "Epoch: [11][5300/10208]\tTime 0.727 (0.780)\tData 0.026 (0.030)\tLoss 176.1372 (178.0376)\t\n",
      "Epoch: [11][5400/10208]\tTime 0.738 (0.780)\tData 0.025 (0.030)\tLoss 178.3992 (178.0384)\t\n",
      "Epoch: [11][5500/10208]\tTime 0.719 (0.780)\tData 0.026 (0.030)\tLoss 174.7311 (178.0339)\t\n",
      "Epoch: [11][5600/10208]\tTime 0.749 (0.780)\tData 0.025 (0.029)\tLoss 178.4245 (178.0264)\t\n",
      "Epoch: [11][5700/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 179.3984 (178.0210)\t\n",
      "Epoch: [11][5800/10208]\tTime 0.750 (0.780)\tData 0.025 (0.029)\tLoss 179.1574 (178.0186)\t\n",
      "Epoch: [11][5900/10208]\tTime 0.731 (0.780)\tData 0.026 (0.029)\tLoss 178.7827 (178.0109)\t\n",
      "Epoch: [11][6000/10208]\tTime 0.738 (0.780)\tData 0.025 (0.029)\tLoss 178.1980 (178.0066)\t\n",
      "Epoch: [11][6100/10208]\tTime 1.003 (0.780)\tData 0.025 (0.029)\tLoss 174.8147 (177.9988)\t\n",
      "Epoch: [11][6200/10208]\tTime 0.718 (0.780)\tData 0.025 (0.029)\tLoss 177.1895 (177.9933)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [11][6300/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 177.9902 (177.9877)\t\n",
      "Epoch: [11][6400/10208]\tTime 0.758 (0.780)\tData 0.025 (0.029)\tLoss 178.8732 (177.9820)\t\n",
      "Epoch: [11][6500/10208]\tTime 0.725 (0.780)\tData 0.026 (0.029)\tLoss 175.0977 (177.9756)\t\n",
      "Epoch: [11][6600/10208]\tTime 1.238 (0.780)\tData 0.025 (0.029)\tLoss 179.1657 (177.9703)\t\n",
      "Epoch: [11][6700/10208]\tTime 0.724 (0.780)\tData 0.025 (0.029)\tLoss 178.7919 (177.9649)\t\n",
      "Epoch: [11][6800/10208]\tTime 0.721 (0.779)\tData 0.026 (0.029)\tLoss 177.0470 (177.9617)\t\n",
      "Epoch: [11][6900/10208]\tTime 0.728 (0.780)\tData 0.026 (0.029)\tLoss 177.3727 (177.9559)\t\n",
      "Epoch: [11][7000/10208]\tTime 0.723 (0.779)\tData 0.025 (0.029)\tLoss 181.3313 (177.9536)\t\n",
      "Epoch: [11][7100/10208]\tTime 1.149 (0.779)\tData 0.026 (0.029)\tLoss 179.8049 (177.9482)\t\n",
      "Epoch: [11][7200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.029)\tLoss 179.0040 (177.9407)\t\n",
      "Epoch: [11][7300/10208]\tTime 0.721 (0.779)\tData 0.025 (0.029)\tLoss 176.4835 (177.9369)\t\n",
      "Epoch: [11][7400/10208]\tTime 0.783 (0.779)\tData 0.026 (0.029)\tLoss 177.4356 (177.9315)\t\n",
      "Epoch: [11][7500/10208]\tTime 0.715 (0.779)\tData 0.025 (0.029)\tLoss 177.8332 (177.9263)\t\n",
      "Epoch: [11][7600/10208]\tTime 1.029 (0.779)\tData 0.026 (0.029)\tLoss 177.3530 (177.9234)\t\n",
      "Epoch: [11][7700/10208]\tTime 0.724 (0.779)\tData 0.026 (0.029)\tLoss 178.0682 (177.9196)\t\n",
      "Epoch: [11][7800/10208]\tTime 0.717 (0.779)\tData 0.025 (0.029)\tLoss 174.7979 (177.9166)\t\n",
      "Epoch: [11][7900/10208]\tTime 0.739 (0.779)\tData 0.026 (0.028)\tLoss 177.3286 (177.9122)\t\n",
      "Epoch: [11][8000/10208]\tTime 0.731 (0.779)\tData 0.026 (0.028)\tLoss 179.4130 (177.9052)\t\n",
      "Epoch: [11][8100/10208]\tTime 0.758 (0.779)\tData 0.025 (0.028)\tLoss 181.4639 (177.9018)\t\n",
      "Epoch: [11][8200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 180.0743 (177.8965)\t\n",
      "Epoch: [11][8300/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 176.6648 (177.8909)\t\n",
      "Epoch: [11][8400/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 177.0685 (177.8853)\t\n",
      "Epoch: [11][8500/10208]\tTime 0.721 (0.779)\tData 0.026 (0.028)\tLoss 176.7854 (177.8802)\t\n",
      "Epoch: [11][8600/10208]\tTime 0.725 (0.779)\tData 0.025 (0.028)\tLoss 178.1489 (177.8772)\t\n",
      "Epoch: [11][8700/10208]\tTime 0.737 (0.779)\tData 0.026 (0.028)\tLoss 176.6179 (177.8733)\t\n",
      "Epoch: [11][8800/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 179.6938 (177.8708)\t\n",
      "Epoch: [11][8900/10208]\tTime 0.725 (0.779)\tData 0.025 (0.028)\tLoss 177.9869 (177.8700)\t\n",
      "Epoch: [11][9000/10208]\tTime 0.730 (0.779)\tData 0.026 (0.028)\tLoss 177.2191 (177.8643)\t\n",
      "Epoch: [11][9100/10208]\tTime 0.730 (0.778)\tData 0.025 (0.028)\tLoss 177.7699 (177.8599)\t\n",
      "Epoch: [11][9200/10208]\tTime 0.745 (0.778)\tData 0.027 (0.028)\tLoss 178.5836 (177.8562)\t\n",
      "Epoch: [11][9300/10208]\tTime 0.746 (0.778)\tData 0.026 (0.028)\tLoss 178.8197 (177.8518)\t\n",
      "Epoch: [11][9400/10208]\tTime 1.198 (0.778)\tData 0.026 (0.028)\tLoss 175.8962 (177.8474)\t\n",
      "Epoch: [11][9500/10208]\tTime 0.720 (0.778)\tData 0.025 (0.028)\tLoss 178.7277 (177.8450)\t\n",
      "Epoch: [11][9600/10208]\tTime 0.729 (0.778)\tData 0.026 (0.028)\tLoss 177.1797 (177.8429)\t\n",
      "Epoch: [11][9700/10208]\tTime 0.754 (0.778)\tData 0.026 (0.028)\tLoss 177.1552 (177.8417)\t\n",
      "Epoch: [11][9800/10208]\tTime 0.725 (0.778)\tData 0.026 (0.028)\tLoss 178.8535 (177.8385)\t\n",
      "Epoch: [11][9900/10208]\tTime 1.053 (0.778)\tData 0.026 (0.028)\tLoss 176.1941 (177.8350)\t\n",
      "Epoch: [11][10000/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 177.6458 (177.8297)\t\n",
      "Epoch: [11][10100/10208]\tTime 0.723 (0.778)\tData 0.026 (0.028)\tLoss 177.2932 (177.8267)\t\n",
      "Epoch: [11][10200/10208]\tTime 0.731 (0.778)\tData 0.026 (0.028)\tLoss 177.4220 (177.8246)\t\n",
      "Epoch: [11][10207/10208]\tTime 0.716 (0.778)\tData 0.025 (0.028)\tLoss 176.3455 (177.8242)\t\n",
      "Start training\n",
      "Epoch: [12][0/10208]\tTime 16.642 (16.642)\tData 15.784 (15.784)\tLoss 176.1775 (176.1775)\t\n",
      "Epoch: [12][100/10208]\tTime 0.724 (0.940)\tData 0.026 (0.182)\tLoss 176.8107 (177.1997)\t\n",
      "Epoch: [12][200/10208]\tTime 0.804 (0.858)\tData 0.025 (0.105)\tLoss 176.6131 (177.0994)\t\n",
      "Epoch: [12][300/10208]\tTime 0.729 (0.829)\tData 0.026 (0.079)\tLoss 177.4353 (177.1525)\t\n",
      "Epoch: [12][400/10208]\tTime 1.242 (0.816)\tData 0.026 (0.066)\tLoss 177.5895 (177.2298)\t\n",
      "Epoch: [12][500/10208]\tTime 0.726 (0.808)\tData 0.025 (0.058)\tLoss 175.8879 (177.2147)\t\n",
      "Epoch: [12][600/10208]\tTime 0.736 (0.802)\tData 0.026 (0.053)\tLoss 174.4875 (177.1789)\t\n",
      "Epoch: [12][700/10208]\tTime 0.725 (0.798)\tData 0.025 (0.049)\tLoss 177.0463 (177.1858)\t\n",
      "Epoch: [12][800/10208]\tTime 0.726 (0.795)\tData 0.026 (0.046)\tLoss 177.0124 (177.1984)\t\n",
      "Epoch: [12][900/10208]\tTime 0.728 (0.794)\tData 0.025 (0.044)\tLoss 177.4775 (177.1903)\t\n",
      "Epoch: [12][1000/10208]\tTime 0.728 (0.792)\tData 0.026 (0.042)\tLoss 178.3105 (177.1934)\t\n",
      "Epoch: [12][1100/10208]\tTime 0.725 (0.790)\tData 0.025 (0.041)\tLoss 177.6661 (177.2058)\t\n",
      "Epoch: [12][1200/10208]\tTime 0.719 (0.789)\tData 0.025 (0.039)\tLoss 175.9021 (177.1994)\t\n",
      "Epoch: [12][1300/10208]\tTime 0.744 (0.789)\tData 0.025 (0.038)\tLoss 177.6297 (177.2006)\t\n",
      "Epoch: [12][1400/10208]\tTime 0.724 (0.788)\tData 0.026 (0.038)\tLoss 176.9998 (177.1897)\t\n",
      "Epoch: [12][1500/10208]\tTime 0.718 (0.787)\tData 0.026 (0.037)\tLoss 175.0891 (177.1903)\t\n",
      "Epoch: [12][1600/10208]\tTime 0.718 (0.786)\tData 0.025 (0.036)\tLoss 178.4246 (177.1820)\t\n",
      "Epoch: [12][1700/10208]\tTime 0.721 (0.786)\tData 0.025 (0.036)\tLoss 179.3082 (177.1748)\t\n",
      "Epoch: [12][1800/10208]\tTime 0.719 (0.786)\tData 0.025 (0.035)\tLoss 178.3895 (177.1860)\t\n",
      "Epoch: [12][1900/10208]\tTime 0.720 (0.785)\tData 0.026 (0.035)\tLoss 178.1146 (177.1730)\t\n",
      "Epoch: [12][2000/10208]\tTime 0.723 (0.785)\tData 0.026 (0.034)\tLoss 177.7157 (177.1783)\t\n",
      "Epoch: [12][2100/10208]\tTime 0.725 (0.784)\tData 0.025 (0.034)\tLoss 176.5471 (177.1822)\t\n",
      "Epoch: [12][2200/10208]\tTime 0.994 (0.784)\tData 0.026 (0.034)\tLoss 179.1093 (177.1773)\t\n",
      "Epoch: [12][2300/10208]\tTime 0.713 (0.784)\tData 0.025 (0.033)\tLoss 178.0879 (177.1717)\t\n",
      "Epoch: [12][2400/10208]\tTime 0.741 (0.783)\tData 0.025 (0.033)\tLoss 176.4159 (177.1671)\t\n",
      "Epoch: [12][2500/10208]\tTime 0.727 (0.783)\tData 0.026 (0.033)\tLoss 175.3392 (177.1676)\t\n",
      "Epoch: [12][2600/10208]\tTime 0.724 (0.783)\tData 0.026 (0.032)\tLoss 177.3682 (177.1692)\t\n",
      "Epoch: [12][2700/10208]\tTime 1.104 (0.783)\tData 0.026 (0.032)\tLoss 177.1241 (177.1730)\t\n",
      "Epoch: [12][2800/10208]\tTime 0.739 (0.782)\tData 0.025 (0.032)\tLoss 176.6089 (177.1689)\t\n",
      "Epoch: [12][2900/10208]\tTime 0.724 (0.782)\tData 0.026 (0.032)\tLoss 179.8631 (177.1626)\t\n",
      "Epoch: [12][3000/10208]\tTime 0.766 (0.782)\tData 0.026 (0.032)\tLoss 176.0494 (177.1628)\t\n",
      "Epoch: [12][3100/10208]\tTime 0.724 (0.782)\tData 0.026 (0.031)\tLoss 177.6678 (177.1550)\t\n",
      "Epoch: [12][3200/10208]\tTime 1.117 (0.782)\tData 0.025 (0.031)\tLoss 178.4796 (177.1484)\t\n",
      "Epoch: [12][3300/10208]\tTime 0.742 (0.782)\tData 0.025 (0.031)\tLoss 177.7986 (177.1422)\t\n",
      "Epoch: [12][3400/10208]\tTime 0.734 (0.782)\tData 0.025 (0.031)\tLoss 179.3295 (177.1428)\t\n",
      "Epoch: [12][3500/10208]\tTime 0.717 (0.782)\tData 0.025 (0.031)\tLoss 178.1232 (177.1325)\t\n",
      "Epoch: [12][3600/10208]\tTime 0.714 (0.782)\tData 0.026 (0.031)\tLoss 176.2278 (177.1331)\t\n",
      "Epoch: [12][3700/10208]\tTime 1.083 (0.782)\tData 0.026 (0.031)\tLoss 174.5928 (177.1304)\t\n",
      "Epoch: [12][3800/10208]\tTime 0.757 (0.782)\tData 0.025 (0.030)\tLoss 173.7665 (177.1179)\t\n",
      "Epoch: [12][3900/10208]\tTime 0.722 (0.781)\tData 0.026 (0.030)\tLoss 176.4837 (177.1186)\t\n",
      "Epoch: [12][4000/10208]\tTime 0.796 (0.781)\tData 0.026 (0.030)\tLoss 174.6463 (177.1175)\t\n",
      "Epoch: [12][4100/10208]\tTime 0.726 (0.781)\tData 0.026 (0.030)\tLoss 178.1025 (177.1119)\t\n",
      "Epoch: [12][4200/10208]\tTime 0.734 (0.781)\tData 0.026 (0.030)\tLoss 176.3253 (177.1128)\t\n",
      "Epoch: [12][4300/10208]\tTime 0.732 (0.781)\tData 0.026 (0.030)\tLoss 175.3808 (177.1119)\t\n",
      "Epoch: [12][4400/10208]\tTime 0.717 (0.781)\tData 0.025 (0.030)\tLoss 176.9144 (177.1107)\t\n",
      "Epoch: [12][4500/10208]\tTime 0.735 (0.780)\tData 0.026 (0.030)\tLoss 177.7232 (177.1023)\t\n",
      "Epoch: [12][4600/10208]\tTime 0.730 (0.780)\tData 0.025 (0.030)\tLoss 178.5244 (177.1058)\t\n",
      "Epoch: [12][4700/10208]\tTime 0.744 (0.780)\tData 0.025 (0.030)\tLoss 177.1851 (177.1088)\t\n",
      "Epoch: [12][4800/10208]\tTime 0.731 (0.780)\tData 0.026 (0.030)\tLoss 180.0346 (177.1082)\t\n",
      "Epoch: [12][4900/10208]\tTime 0.737 (0.780)\tData 0.025 (0.029)\tLoss 175.8465 (177.1045)\t\n",
      "Epoch: [12][5000/10208]\tTime 0.727 (0.780)\tData 0.025 (0.029)\tLoss 176.7862 (177.1094)\t\n",
      "Epoch: [12][5100/10208]\tTime 0.723 (0.780)\tData 0.025 (0.029)\tLoss 178.5712 (177.1086)\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12][5200/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 175.7195 (177.1066)\t\n",
      "Epoch: [12][5300/10208]\tTime 0.730 (0.780)\tData 0.026 (0.029)\tLoss 177.7201 (177.1062)\t\n",
      "Epoch: [12][5400/10208]\tTime 0.725 (0.780)\tData 0.025 (0.029)\tLoss 178.3834 (177.1069)\t\n",
      "Epoch: [12][5500/10208]\tTime 1.104 (0.780)\tData 0.026 (0.029)\tLoss 177.8806 (177.1075)\t\n",
      "Epoch: [12][5600/10208]\tTime 0.744 (0.780)\tData 0.025 (0.029)\tLoss 175.8921 (177.1048)\t\n",
      "Epoch: [12][5700/10208]\tTime 0.717 (0.780)\tData 0.026 (0.029)\tLoss 174.6758 (177.0996)\t\n",
      "Epoch: [12][5800/10208]\tTime 0.728 (0.780)\tData 0.026 (0.029)\tLoss 176.9340 (177.0971)\t\n",
      "Epoch: [12][5900/10208]\tTime 0.761 (0.780)\tData 0.026 (0.029)\tLoss 176.7609 (177.0936)\t\n",
      "Epoch: [12][6000/10208]\tTime 1.108 (0.780)\tData 0.026 (0.029)\tLoss 176.2689 (177.0906)\t\n",
      "Epoch: [12][6100/10208]\tTime 0.738 (0.780)\tData 0.026 (0.029)\tLoss 177.6653 (177.0885)\t\n",
      "Epoch: [12][6200/10208]\tTime 0.724 (0.780)\tData 0.026 (0.029)\tLoss 178.6955 (177.0817)\t\n",
      "Epoch: [12][6300/10208]\tTime 0.719 (0.780)\tData 0.026 (0.029)\tLoss 176.1335 (177.0808)\t\n",
      "Epoch: [12][6400/10208]\tTime 0.726 (0.780)\tData 0.026 (0.029)\tLoss 175.9761 (177.0828)\t\n",
      "Epoch: [12][6500/10208]\tTime 1.236 (0.780)\tData 0.025 (0.029)\tLoss 177.5702 (177.0834)\t\n",
      "Epoch: [12][6600/10208]\tTime 0.745 (0.779)\tData 0.026 (0.029)\tLoss 179.5081 (177.0832)\t\n",
      "Epoch: [12][6700/10208]\tTime 0.724 (0.779)\tData 0.025 (0.029)\tLoss 174.9330 (177.0793)\t\n",
      "Epoch: [12][6800/10208]\tTime 0.757 (0.779)\tData 0.055 (0.029)\tLoss 177.6154 (177.0754)\t\n",
      "Epoch: [12][6900/10208]\tTime 0.725 (0.779)\tData 0.026 (0.029)\tLoss 177.5286 (177.0758)\t\n",
      "Epoch: [12][7000/10208]\tTime 1.045 (0.779)\tData 0.025 (0.028)\tLoss 177.9499 (177.0748)\t\n",
      "Epoch: [12][7100/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 177.1022 (177.0725)\t\n",
      "Epoch: [12][7200/10208]\tTime 0.743 (0.779)\tData 0.026 (0.028)\tLoss 177.7712 (177.0755)\t\n",
      "Epoch: [12][7300/10208]\tTime 0.749 (0.779)\tData 0.025 (0.028)\tLoss 175.3375 (177.0744)\t\n",
      "Epoch: [12][7400/10208]\tTime 0.735 (0.779)\tData 0.025 (0.028)\tLoss 177.7493 (177.0694)\t\n",
      "Epoch: [12][7500/10208]\tTime 0.743 (0.779)\tData 0.026 (0.028)\tLoss 176.0572 (177.0673)\t\n",
      "Epoch: [12][7600/10208]\tTime 0.744 (0.779)\tData 0.026 (0.028)\tLoss 176.0353 (177.0666)\t\n",
      "Epoch: [12][7700/10208]\tTime 0.726 (0.779)\tData 0.025 (0.028)\tLoss 178.5662 (177.0674)\t\n",
      "Epoch: [12][7800/10208]\tTime 0.765 (0.779)\tData 0.025 (0.028)\tLoss 175.9695 (177.0669)\t\n",
      "Epoch: [12][7900/10208]\tTime 0.716 (0.779)\tData 0.025 (0.028)\tLoss 179.3540 (177.0663)\t\n",
      "Epoch: [12][8000/10208]\tTime 0.720 (0.779)\tData 0.025 (0.028)\tLoss 173.9558 (177.0623)\t\n",
      "Epoch: [12][8100/10208]\tTime 0.727 (0.779)\tData 0.026 (0.028)\tLoss 175.1781 (177.0609)\t\n",
      "Epoch: [12][8200/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 176.8918 (177.0559)\t\n",
      "Epoch: [12][8300/10208]\tTime 0.735 (0.779)\tData 0.028 (0.028)\tLoss 176.9554 (177.0522)\t\n",
      "Epoch: [12][8400/10208]\tTime 0.738 (0.779)\tData 0.026 (0.028)\tLoss 180.2310 (177.0527)\t\n",
      "Epoch: [12][8500/10208]\tTime 0.717 (0.779)\tData 0.026 (0.028)\tLoss 177.7447 (177.0497)\t\n",
      "Epoch: [12][8600/10208]\tTime 0.718 (0.779)\tData 0.025 (0.028)\tLoss 177.7164 (177.0504)\t\n",
      "Epoch: [12][8700/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 177.1464 (177.0472)\t\n",
      "Epoch: [12][8800/10208]\tTime 1.198 (0.779)\tData 0.026 (0.028)\tLoss 175.6965 (177.0473)\t\n",
      "Epoch: [12][8900/10208]\tTime 0.729 (0.779)\tData 0.025 (0.028)\tLoss 177.1092 (177.0459)\t\n",
      "Epoch: [12][9000/10208]\tTime 0.730 (0.779)\tData 0.025 (0.028)\tLoss 175.4188 (177.0442)\t\n",
      "Epoch: [12][9100/10208]\tTime 0.723 (0.779)\tData 0.025 (0.028)\tLoss 177.9956 (177.0437)\t\n",
      "Epoch: [12][9200/10208]\tTime 0.714 (0.779)\tData 0.025 (0.028)\tLoss 176.3535 (177.0438)\t\n",
      "Epoch: [12][9300/10208]\tTime 1.129 (0.779)\tData 0.025 (0.028)\tLoss 176.0349 (177.0425)\t\n",
      "Epoch: [12][9400/10208]\tTime 0.746 (0.779)\tData 0.025 (0.028)\tLoss 176.7353 (177.0413)\t\n",
      "Epoch: [12][9500/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 177.5867 (177.0404)\t\n",
      "Epoch: [12][9600/10208]\tTime 0.717 (0.779)\tData 0.025 (0.028)\tLoss 177.3074 (177.0393)\t\n",
      "Epoch: [12][9700/10208]\tTime 0.724 (0.779)\tData 0.025 (0.028)\tLoss 174.7474 (177.0346)\t\n",
      "Epoch: [12][9800/10208]\tTime 1.173 (0.779)\tData 0.026 (0.028)\tLoss 177.6812 (177.0348)\t\n",
      "Epoch: [12][9900/10208]\tTime 0.719 (0.779)\tData 0.025 (0.028)\tLoss 174.8907 (177.0343)\t\n",
      "Epoch: [12][10000/10208]\tTime 0.718 (0.779)\tData 0.025 (0.028)\tLoss 175.5930 (177.0311)\t\n",
      "Epoch: [12][10100/10208]\tTime 0.724 (0.779)\tData 0.026 (0.028)\tLoss 176.2129 (177.0309)\t\n",
      "Epoch: [12][10200/10208]\tTime 0.742 (0.779)\tData 0.025 (0.028)\tLoss 178.2044 (177.0288)\t\n",
      "Epoch: [12][10207/10208]\tTime 0.723 (0.779)\tData 0.025 (0.028)\tLoss 178.0735 (177.0289)\t\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.parameters()), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [13][0/10208]\tTime 14.640 (14.640)\tData 13.272 (13.272)\tLoss 179.9438 (179.9438)\t\n",
      "Epoch: [13][100/10208]\tTime 0.725 (0.919)\tData 0.025 (0.169)\tLoss 177.1551 (176.5815)\t\n",
      "Epoch: [13][200/10208]\tTime 0.724 (0.845)\tData 0.026 (0.098)\tLoss 179.4290 (176.6449)\t\n",
      "Epoch: [13][300/10208]\tTime 0.723 (0.821)\tData 0.026 (0.074)\tLoss 174.8461 (176.5989)\t\n",
      "Epoch: [13][400/10208]\tTime 0.720 (0.808)\tData 0.025 (0.062)\tLoss 176.3250 (176.5975)\t\n",
      "Epoch: [13][500/10208]\tTime 1.215 (0.800)\tData 0.025 (0.055)\tLoss 178.4466 (176.6352)\t\n",
      "Epoch: [13][600/10208]\tTime 0.727 (0.794)\tData 0.025 (0.050)\tLoss 176.8209 (176.6587)\t\n",
      "Epoch: [13][700/10208]\tTime 0.722 (0.791)\tData 0.026 (0.047)\tLoss 176.2284 (176.6738)\t\n",
      "Epoch: [13][800/10208]\tTime 0.748 (0.789)\tData 0.026 (0.044)\tLoss 175.8517 (176.6621)\t\n",
      "Epoch: [13][900/10208]\tTime 0.746 (0.787)\tData 0.026 (0.042)\tLoss 175.1473 (176.6811)\t\n",
      "Epoch: [13][1000/10208]\tTime 1.241 (0.786)\tData 0.026 (0.041)\tLoss 174.4275 (176.6806)\t\n",
      "Epoch: [13][1100/10208]\tTime 0.723 (0.786)\tData 0.026 (0.039)\tLoss 177.1640 (176.6813)\t\n",
      "Epoch: [13][1200/10208]\tTime 0.727 (0.785)\tData 0.025 (0.038)\tLoss 176.9545 (176.7000)\t\n",
      "Epoch: [13][1300/10208]\tTime 0.747 (0.786)\tData 0.026 (0.037)\tLoss 177.0587 (176.6983)\t\n",
      "Epoch: [13][1400/10208]\tTime 0.723 (0.787)\tData 0.026 (0.036)\tLoss 176.2668 (176.7122)\t\n",
      "Epoch: [13][1500/10208]\tTime 0.728 (0.786)\tData 0.026 (0.036)\tLoss 178.5937 (176.7231)\t\n",
      "Epoch: [13][1600/10208]\tTime 0.720 (0.786)\tData 0.026 (0.035)\tLoss 174.1200 (176.6999)\t\n",
      "Epoch: [13][1700/10208]\tTime 0.721 (0.784)\tData 0.026 (0.035)\tLoss 176.1440 (176.6956)\t\n",
      "Epoch: [13][1800/10208]\tTime 0.746 (0.784)\tData 0.025 (0.034)\tLoss 177.4644 (176.6960)\t\n",
      "Epoch: [13][1900/10208]\tTime 0.720 (0.784)\tData 0.025 (0.034)\tLoss 176.5097 (176.6996)\t\n",
      "Epoch: [13][2000/10208]\tTime 0.717 (0.783)\tData 0.025 (0.033)\tLoss 175.4138 (176.6929)\t\n",
      "Epoch: [13][2100/10208]\tTime 0.736 (0.782)\tData 0.026 (0.033)\tLoss 178.9263 (176.6957)\t\n",
      "Epoch: [13][2200/10208]\tTime 0.752 (0.782)\tData 0.026 (0.033)\tLoss 176.9816 (176.6892)\t\n",
      "Epoch: [13][2300/10208]\tTime 0.731 (0.782)\tData 0.025 (0.032)\tLoss 177.3034 (176.6857)\t\n",
      "Epoch: [13][2400/10208]\tTime 0.745 (0.781)\tData 0.025 (0.032)\tLoss 176.7432 (176.6763)\t\n",
      "Epoch: [13][2500/10208]\tTime 0.724 (0.781)\tData 0.026 (0.032)\tLoss 177.3383 (176.6680)\t\n",
      "Epoch: [13][2600/10208]\tTime 0.733 (0.780)\tData 0.026 (0.032)\tLoss 176.7031 (176.6769)\t\n",
      "Epoch: [13][2700/10208]\tTime 0.723 (0.780)\tData 0.025 (0.031)\tLoss 175.7937 (176.6696)\t\n",
      "Epoch: [13][2800/10208]\tTime 1.162 (0.780)\tData 0.025 (0.031)\tLoss 175.0468 (176.6635)\t\n",
      "Epoch: [13][2900/10208]\tTime 0.721 (0.780)\tData 0.026 (0.031)\tLoss 176.7185 (176.6639)\t\n",
      "Epoch: [13][3000/10208]\tTime 0.732 (0.780)\tData 0.025 (0.031)\tLoss 177.2299 (176.6684)\t\n",
      "Epoch: [13][3100/10208]\tTime 0.755 (0.780)\tData 0.025 (0.031)\tLoss 178.1888 (176.6656)\t\n",
      "Epoch: [13][3200/10208]\tTime 0.724 (0.779)\tData 0.026 (0.031)\tLoss 174.4604 (176.6638)\t\n",
      "Epoch: [13][3300/10208]\tTime 0.948 (0.779)\tData 0.026 (0.031)\tLoss 176.8585 (176.6586)\t\n",
      "Epoch: [13][3400/10208]\tTime 0.741 (0.779)\tData 0.025 (0.030)\tLoss 176.9598 (176.6558)\t\n",
      "Epoch: [13][3500/10208]\tTime 0.728 (0.779)\tData 0.026 (0.030)\tLoss 175.6608 (176.6538)\t\n",
      "Epoch: [13][3600/10208]\tTime 0.724 (0.779)\tData 0.026 (0.030)\tLoss 177.3817 (176.6546)\t\n",
      "Epoch: [13][3700/10208]\tTime 0.732 (0.778)\tData 0.026 (0.030)\tLoss 176.2620 (176.6552)\t\n",
      "Epoch: [13][3800/10208]\tTime 1.427 (0.779)\tData 0.026 (0.030)\tLoss 177.9053 (176.6530)\t\n",
      "Epoch: [13][3900/10208]\tTime 0.725 (0.779)\tData 0.026 (0.030)\tLoss 178.2003 (176.6455)\t\n",
      "Epoch: [13][4000/10208]\tTime 0.727 (0.779)\tData 0.026 (0.030)\tLoss 177.1675 (176.6411)\t\n",
      "Epoch: [13][4100/10208]\tTime 0.742 (0.779)\tData 0.025 (0.030)\tLoss 176.7914 (176.6379)\t\n",
      "Epoch: [13][4200/10208]\tTime 0.719 (0.779)\tData 0.025 (0.030)\tLoss 175.7822 (176.6385)\t\n",
      "Epoch: [13][4300/10208]\tTime 1.014 (0.779)\tData 0.026 (0.030)\tLoss 175.0293 (176.6376)\t\n",
      "Epoch: [13][4400/10208]\tTime 0.730 (0.779)\tData 0.026 (0.030)\tLoss 177.6784 (176.6390)\t\n",
      "Epoch: [13][4500/10208]\tTime 0.721 (0.779)\tData 0.026 (0.029)\tLoss 176.7597 (176.6438)\t\n",
      "44.41 \\%\r"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
