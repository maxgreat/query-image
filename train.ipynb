{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import fastText\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import models\n",
    "from dataset import openimages\n",
    "from utils.loss import HardNegativeContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, print_freq=1000):\n",
    "    #amp_handle = amp.init()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.train()\n",
    "    print(\"Start training\")\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps) in enumerate(train_loader):\n",
    "        if i%2 == 1:\n",
    "                print(\"%2.2f\"% (i/len(train_loader)*100), '\\%', end='\\r')\n",
    "        input_imgs, target = imgs.cuda(), caps.cuda()\n",
    "        \n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_imgs = model(input_imgs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(output_imgs, target)\n",
    "        \n",
    "        #with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        #    scaled_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg, batch_time.avg, data_time.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=1000):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model = model.eval()\n",
    "\n",
    "    imgs_enc = list()\n",
    "    caps_enc = list()\n",
    "    end = time.time()\n",
    "    for i, (imgs, caps, lengths) in enumerate(val_loader):\n",
    "\n",
    "        input_imgs, input_caps = imgs.cuda(), caps.cuda()\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_imgs = model(input_imgs)\n",
    "            loss = criterion(output_imgs, input_caps)\n",
    "\n",
    "        imgs_enc.append(output_imgs.cpu().data.numpy())\n",
    "        caps_enc.append(output_caps.cpu().data.numpy())\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0 or i == (len(val_loader) - 1):\n",
    "            print('Data: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      i, len(val_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses))\n",
    "\n",
    "    recall  = eval_recall(imgs_enc, caps_enc)\n",
    "    print(recall)\n",
    "    return losses.avg, batch_time.avg, data_time.avg, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "prepro = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "prepro_val = transforms.Compose([\n",
    "    transforms.Resize((350, 350)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.DataParallel(models.ImageProjection().train().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.parameters():\n",
    "    params.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in m.module.projection.parameters():\n",
    "    params.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_embeds(data):\n",
    "    images, targets = zip(*data)\n",
    "    images = torch.stack(images, 0)\n",
    "    targets = torch.Tensor(np.stack(targets, 0))\n",
    "\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset file\n",
      "Done reading  4593616  lines.\n"
     ]
    }
   ],
   "source": [
    "embed = fastText.load_model(\"/data/m.portaz/wiki.en.bin\")\n",
    "train_dataset = openimages.OpenImagesText(image_dir=\"/data/datasets/openimages/images/train/\", \n",
    "                          dataset_file=\"/data/datasets/openimages/train-words.csv\",\n",
    "                          embeddings=embed, \n",
    "                          transform=prepro, random=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=3072, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = HardNegativeContrastiveLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 58.837 (58.837)\tData 32.222 (32.222)\tLoss 5065.3916 (5065.3916)\t\n",
      "Epoch: [0][50/2191]\tTime 1.888 (2.689)\tData 0.115 (0.753)\tLoss 8174.1582 (9939.4797)\t\n",
      "Epoch: [0][100/2191]\tTime 1.354 (2.066)\tData 0.116 (0.443)\tLoss 7127.2090 (8879.8595)\t\n",
      "Epoch: [0][150/2191]\tTime 1.324 (1.865)\tData 0.117 (0.339)\tLoss 9998.9590 (9019.7205)\t\n",
      "Epoch: [0][200/2191]\tTime 1.328 (1.758)\tData 0.115 (0.287)\tLoss 8123.5645 (8971.5343)\t\n",
      "Epoch: [0][250/2191]\tTime 1.327 (1.692)\tData 0.116 (0.255)\tLoss 6510.5483 (8671.2556)\t\n",
      "Epoch: [0][300/2191]\tTime 1.333 (1.649)\tData 0.116 (0.233)\tLoss 6361.2222 (8354.4636)\t\n",
      "Epoch: [0][350/2191]\tTime 1.327 (1.615)\tData 0.116 (0.217)\tLoss 6979.4229 (8109.9479)\t\n",
      "Epoch: [0][400/2191]\tTime 1.858 (1.595)\tData 0.116 (0.205)\tLoss 8735.3262 (8153.7529)\t\n",
      "Epoch: [0][450/2191]\tTime 1.328 (1.577)\tData 0.116 (0.196)\tLoss 8741.9980 (8163.0154)\t\n",
      "Epoch: [0][500/2191]\tTime 1.459 (1.560)\tData 0.247 (0.189)\tLoss 7970.5630 (8180.6867)\t\n",
      "Epoch: [0][550/2191]\tTime 1.331 (1.549)\tData 0.116 (0.184)\tLoss 7093.3530 (8133.0711)\t\n",
      "Epoch: [0][600/2191]\tTime 1.332 (1.539)\tData 0.117 (0.179)\tLoss 10098.0303 (8117.1455)\t\n",
      "Epoch: [0][650/2191]\tTime 1.326 (1.530)\tData 0.116 (0.175)\tLoss 7781.2217 (8113.1772)\t\n",
      "Epoch: [0][700/2191]\tTime 1.330 (1.522)\tData 0.116 (0.172)\tLoss 7592.8354 (8129.1951)\t\n",
      "Epoch: [0][750/2191]\tTime 1.786 (1.516)\tData 0.116 (0.168)\tLoss 9610.7158 (8074.2622)\t\n",
      "Epoch: [0][800/2191]\tTime 1.331 (1.510)\tData 0.117 (0.166)\tLoss 7892.0767 (8134.2885)\t\n",
      "Epoch: [0][850/2191]\tTime 1.325 (1.505)\tData 0.116 (0.163)\tLoss 8235.4072 (8146.2536)\t\n",
      "Epoch: [0][900/2191]\tTime 1.361 (1.500)\tData 0.117 (0.161)\tLoss 9740.2344 (8091.7376)\t\n",
      "Epoch: [0][950/2191]\tTime 1.330 (1.495)\tData 0.117 (0.159)\tLoss 7965.3130 (8039.7251)\t\n",
      "Epoch: [0][1000/2191]\tTime 1.330 (1.492)\tData 0.117 (0.157)\tLoss 7266.1841 (8023.7087)\t\n",
      "Epoch: [0][1050/2191]\tTime 1.325 (1.490)\tData 0.118 (0.156)\tLoss 7685.0366 (8015.7088)\t\n",
      "Epoch: [0][1100/2191]\tTime 1.936 (1.488)\tData 0.116 (0.154)\tLoss 6690.6826 (7988.1899)\t\n",
      "Epoch: [0][1150/2191]\tTime 1.325 (1.485)\tData 0.115 (0.153)\tLoss 10163.8955 (7940.3929)\t\n",
      "Epoch: [0][1200/2191]\tTime 1.326 (1.482)\tData 0.116 (0.152)\tLoss 7333.4111 (7896.9628)\t\n",
      "Epoch: [0][1250/2191]\tTime 1.325 (1.479)\tData 0.116 (0.151)\tLoss 6177.1816 (7866.9857)\t\n",
      "Epoch: [0][1300/2191]\tTime 1.329 (1.477)\tData 0.120 (0.150)\tLoss 7335.1323 (7873.3829)\t\n",
      "Epoch: [0][1350/2191]\tTime 1.328 (1.475)\tData 0.116 (0.149)\tLoss 10366.2510 (7932.3870)\t\n",
      "Epoch: [0][1400/2191]\tTime 1.327 (1.473)\tData 0.115 (0.148)\tLoss 9487.0684 (8005.5425)\t\n",
      "Epoch: [0][1450/2191]\tTime 1.817 (1.472)\tData 0.115 (0.147)\tLoss 5454.8760 (7998.6466)\t\n",
      "Epoch: [0][1500/2191]\tTime 1.330 (1.472)\tData 0.116 (0.146)\tLoss 5598.6709 (7921.4340)\t\n",
      "Epoch: [0][1550/2191]\tTime 1.330 (1.470)\tData 0.116 (0.145)\tLoss 5261.9014 (7844.0253)\t\n",
      "Epoch: [0][1600/2191]\tTime 1.328 (1.468)\tData 0.116 (0.145)\tLoss 7652.7363 (7812.2137)\t\n",
      "Epoch: [0][1650/2191]\tTime 1.333 (1.466)\tData 0.119 (0.144)\tLoss 8616.8340 (7822.2409)\t\n",
      "Epoch: [0][1700/2191]\tTime 1.332 (1.465)\tData 0.116 (0.143)\tLoss 7353.2617 (7817.1196)\t\n",
      "Epoch: [0][1750/2191]\tTime 1.331 (1.463)\tData 0.116 (0.143)\tLoss 9606.9248 (7812.6407)\t\n",
      "Epoch: [0][1800/2191]\tTime 1.780 (1.462)\tData 0.116 (0.142)\tLoss 6855.3496 (7812.2320)\t\n",
      "Epoch: [0][1850/2191]\tTime 1.326 (1.461)\tData 0.115 (0.142)\tLoss 8153.3965 (7793.2683)\t\n",
      "Epoch: [0][1900/2191]\tTime 1.329 (1.460)\tData 0.116 (0.141)\tLoss 7648.8442 (7796.1466)\t\n",
      "Epoch: [0][1950/2191]\tTime 1.329 (1.459)\tData 0.115 (0.141)\tLoss 6071.6274 (7783.1381)\t\n",
      "Epoch: [0][2000/2191]\tTime 1.329 (1.458)\tData 0.116 (0.140)\tLoss 8214.2217 (7812.4349)\t\n",
      "Epoch: [0][2050/2191]\tTime 1.326 (1.457)\tData 0.116 (0.140)\tLoss 6318.2900 (7789.2213)\t\n",
      "Epoch: [0][2100/2191]\tTime 1.330 (1.456)\tData 0.117 (0.139)\tLoss 7038.3633 (7758.9125)\t\n",
      "Epoch: [0][2150/2191]\tTime 1.752 (1.455)\tData 0.116 (0.139)\tLoss 8031.9453 (7752.9867)\t\n",
      "Epoch: [0][2190/2191]\tTime 1.320 (1.453)\tData 0.114 (0.138)\tLoss 5919.3242 (7745.9767)\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7745.976734546155, 1.4532104864995374, 0.1383018260783444)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.parameters()), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Epoch: [0][0/2191]\tTime 21.584 (21.584)\tData 20.291 (20.291)\tLoss 6896.0942 (6896.0942)\t\n",
      "Epoch: [0][50/2191]\tTime 1.672 (2.120)\tData 0.117 (0.745)\tLoss 4490.7168 (5408.1094)\t\n",
      "Epoch: [0][100/2191]\tTime 1.332 (1.780)\tData 0.119 (0.440)\tLoss 4052.2847 (4848.7612)\t\n",
      "Epoch: [0][150/2191]\tTime 1.326 (1.660)\tData 0.116 (0.336)\tLoss 3058.9360 (4495.5497)\t\n",
      "Epoch: [0][200/2191]\tTime 1.331 (1.602)\tData 0.116 (0.283)\tLoss 2993.4958 (4163.4350)\t\n",
      "Epoch: [0][250/2191]\tTime 1.330 (1.565)\tData 0.117 (0.251)\tLoss 2312.2651 (3845.6544)\t\n",
      "Epoch: [0][300/2191]\tTime 1.348 (1.540)\tData 0.116 (0.229)\tLoss 2224.4983 (3577.2567)\t\n",
      "Epoch: [0][350/2191]\tTime 1.423 (1.522)\tData 0.115 (0.213)\tLoss 2083.6863 (3367.7276)\t\n",
      "Epoch: [0][400/2191]\tTime 1.754 (1.510)\tData 0.116 (0.203)\tLoss 2368.5754 (3219.6241)\t\n",
      "Epoch: [0][450/2191]\tTime 1.339 (1.500)\tData 0.120 (0.193)\tLoss 2379.7559 (3117.2281)\t\n",
      "21.31 \\%\r"
     ]
    }
   ],
   "source": [
    "train(train_loader, m, criterion, opti, 0, print_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Keep the first layer of resnet frozen\n",
    "for i in range(0, 6):\n",
    "    for param in m.module.base_layer[i].parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=450, shuffle=True, drop_last=True,\n",
    "                            num_workers=20, collate_fn=collate_embeds, pin_memory=True)\n",
    "opti = optim.Adam(filter(lambda p: p.requires_grad, m.module.base_layer.parameters()), lr=0.00025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    train(train_loader, m, criterion, opti, i, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
